                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-16 04:32:51.313 | INFO     | prover.proof_search_all_sorries:__init__:456 - Loading indexed corpus from /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_mathematics_in_lean_source_5297e0fb
051367c48c0a084411853a576389ecf5/corpus.jsonl
2024-09-16 04:32:51.313 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/data
sets_PT_single_repo_no_ewc_curriculum/merged_with_new_mathematics_in_lean_source_5297e0fb051367c48c0a084411853a576389
ecf5/corpus.jsonl
2024-09-16 04:32:58.544 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: True
2024-09-16 04:32:58.545 | INFO     | prover.proof_search_all_sorries:__init__:458 - Loaded indexed corpus from /data/
yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_mathematics_in_lean_source_5297e0fb0
51367c48c0a084411853a576389ecf5/corpus.jsonl
2024-09-16 04:32:58.545 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
 15%|██████████████████████████████▏
                                                                     15%|██████████████████████████████▎

                    15%|██████████████████████████████▎
                                                                                        15%|█████████████████████████
█████▍
                                       16%|██████████████████████████████▌
                                                                                                           16%|██████
████████████████████████▋
                                                          16%|██████████████████████████████▊

         16%|██████████████████████████████▉
                                                                             16%|███████████████████████████████

                            16%|███████████████████████████████
                                                                                                16%|█████████████████
██████████████▏
                                               16%|███████████████████████████████▍
                                                                                                                   16
%|███████████████████████████████▍
                                                                  16%|███████████████████████████████▌

                 16%|███████████████████████████████▋
                                                                                     16%|████████████████████████████
███▊
                                    16%|███████████████████████████████▉
                                                                                                        16%|█████████
██████████████████████▉
                                                       16%|████████████████████████████████

      16%|████████████████████████████████▏
                                                                          16%|████████████████████████████████▏

                         16%|████████████████████████████████▎
                                                                                             16%|████████████████████
████████████▍
                                            17%|████████████████████████████████▌
                                                                                                                17%|█
███████████████████████████████▋
                                                               17%|████████████████████████████████▊
                                                            100%|████████████████████████████████████████████████████
█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████
███████████████████████████| 3679/3679 [05:38<00:00, 10.88it/s]
2024-09-16 04:38:36.840 | INFO     | prover.proof_search_all_sorries:__init__:460 - Finished reindexing!
2024-09-16 04:38:36.841 | INFO     | prover.proof_search_all_sorries:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-16 04:38:40,521 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8265
(pid=1563743) [2024-09-16 04:39:18,666] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1563743) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1563743)   return torch.load(io.BytesIO(b))
(pid=1563992) [2024-09-16 04:39:29,402] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1563992) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1563992)   return torch.load(io.BytesIO(b))
(pid=1564171) [2024-09-16 04:39:41,256] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
2024-09-16 04:39:44.782 | INFO     | __main__:prove_sorry_theorems:852 - Found 15 sorry theorems to prove
Processing theorems from avigad/mathematics_in_lean_source:   0%|
                                                                                            | 0/15 [00:00<?, ?theorem
/s]2024-09-16 04:39:44.783 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for cauchySeq_of_le_g
eometric_two'
2024-09-16 04:39:44.784 | INFO     | __main__:prove_sorry_theorems:876 - Position: (423, 1)
2024-09-16 04:39:44.784 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S06.convergesTo_m
ul_const
2024-09-16 04:39:44.784 | INFO     | __main__:prove_sorry_theorems:876 - Position: (199, 1)
2024-09-16 04:39:44.784 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S06.convergesTo_a
dd
2024-09-16 04:39:44.784 | INFO     | __main__:prove_sorry_theorems:876 - Position: (143, 1)
2024-09-16 04:39:44.784 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S05.MyAbs.abs_lt
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:876 - Position: (196, 1)
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for Cantor
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:876 - Position: (673, 1)
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S06.exists_abs_le
_of_convergesTo
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:876 - Position: (239, 1)
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S05.MyAbs.le_abs_
self
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:876 - Position: (157, 1)
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for MyRing.two_mul
2024-09-16 04:39:44.785 | INFO     | __main__:prove_sorry_theorems:876 - Position: (407, 1)
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S04.aux
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:876 - Position: (246, 1)
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for MyRing.self_sub
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:876 - Position: (382, 1)
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S01.Subset.trans
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:876 - Position: (506, 1)
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:875 - Searching for proof for C03S01.my_lemma3
2024-09-16 04:39:44.786 | INFO     | __main__:prove_sorry_theorems:876 - Position: (99, 1)
2024-09-16 04:39:44.786 | INFO     | prover.proof_search_all_sorries:search_unordered:514 - Distributed
(ProverActor pid=1563743) 2024-09-16 04:39:44.798 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.abs_lt')
(ProverActor pid=1564171) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1564171)   return torch.load(io.BytesIO(b))
(pid=1564335) [2024-09-16 04:39:52,487] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1564171) 2024-09-16 04:39:55.414 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C03S06.converge
sTo_mul_const') [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log d
eduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplica
tion for more options.)
(ProverActor pid=1564335) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1564335)   return torch.load(io.BytesIO(b))
(ProverActor pid=1564335) 2024-09-16 04:40:08.540 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C09_Topology/S02_Metric_Spaces.lean'), full_name="cauchySeq_of_le_geometri
c_two'")
(ProverActor pid=1563992) 2024-09-16 04:50:42.592 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1563743) 2024-09-16 04:50:46.296 | INFO     | prover.proof_search_all_sorries:_best_first_search:149
 - 3124216.716973097
(ProverActor pid=1563743) 2024-09-16 04:50:46.296 | INFO     | prover.proof_search_all_sorries:_best_first_search:150
 - 3123616.71928993
(ProverActor pid=1563743) 2024-09-16 04:50:46.296 | INFO     | prover.proof_search_all_sorries:_best_first_search:151
 - 599.9982323399745
(ProverActor pid=1563743) 2024-09-16 04:50:46.296 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600
(ProverActor pid=1564335) 2024-09-16 04:50:52.282 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions). [repeated 3x across cluster]
(ProverActor pid=1564335) 2024-09-16 04:50:52.282 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600 [repeated 4x across cluster]
(ProverActor pid=1563992) 2024-09-16 04:50:52.530 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C
03S06.convergesTo_add'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=332.55647324351594, environment_time=26
6.825130012352, total_time=600.6861254111864, num_total_nodes=5566, num_searched_nodes=162)
(ProverActor pid=1563992) 2024-09-16 04:50:52.536 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C03S06.exists_a
bs_le_of_convergesTo')
(ProverActor pid=1564171) 2024-09-16 04:50:52.484 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C04_Sets_and_Functions/S02_Functions.lean'), full_name='Cantor')
(ProverActor pid=1564335) 2024-09-16 04:51:04.647 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C09_Topology/S02_Metric_Spaces.lean'), full_name="cauchySeq_
of_le_geometric_two'"), status=<Status.OPEN: 'Open'>, proof=None, actor_time=121.425405127462, environment_time=448.9
309307835065, total_time=600.9954073932022, num_total_nodes=1187, num_searched_nodes=36)
(ProverActor pid=1564335) 2024-09-16 04:51:04.653 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_nam
e='MyRing.two_mul')
(ProverActor pid=1563743) 2024-09-16 04:50:57.089 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.ab
s_lt'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=56.39344293856993, environment_time=489.8185450513847, t
otal_time=600.9984962567687, num_total_nodes=895, num_searched_nodes=21) [repeated 2x across cluster]
(ProverActor pid=1563743) 2024-09-16 04:50:57.094 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.le_abs_self')
(ProverActor pid=1563743) 2024-09-16 04:51:50.377 | INFO     | prover.proof_search_all_sorries:_best_first_search:171
 - Found a proof!
(ProverActor pid=1563743) 2024-09-16 04:52:04.121 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.le
_abs_self'), status=<Status.PROVED: 'Proved'>, proof=['rw [le_abs]', 'simp'], actor_time=6.54887854680419, environmen
t_time=2.6455204146914184, total_time=10.197789669036865, num_total_nodes=87, num_searched_nodes=3)
(ProverActor pid=1563743) 2024-09-16 04:52:04.126 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S04_Conjunction_and_Iff.lean'), full_name='C03S04.aux')
(ProverActor pid=1564335) 2024-09-16 04:52:07.128 | INFO     | prover.proof_search_all_sorries:_best_first_search:171
 - Found a proof!
(ProverActor pid=1564335) 2024-09-16 04:52:19.918 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.le
an'), full_name='MyRing.two_mul'), status=<Status.PROVED: 'Proved'>, proof=['nontriviality R', 'abel', 'simp'], actor
_time=11.65486250212416, environment_time=5.192544385325164, total_time=17.857804200146347, num_total_nodes=166, num_
searched_nodes=6)
(ProverActor pid=1564335) 2024-09-16 04:52:19.924 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_nam
e='MyRing.self_sub')
(ProverActor pid=1563743) 2024-09-16 04:52:59.375 | INFO     | prover.proof_search_all_sorries:_best_first_search:171
 - Found a proof!
(ProverActor pid=1563743) 2024-09-16 04:53:12.248 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S04_Conjunction_and_Iff.lean'), full_name='C03S04.
aux'), status=<Status.PROVED: 'Proved'>, proof=['contrapose! h', 'positivity'], actor_time=4.30783975450322, environm
ent_time=0.8833575276657939, total_time=6.193362078163773, num_total_nodes=45, num_searched_nodes=2)
(ProverActor pid=1563743) 2024-09-16 04:53:12.253 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S01_Implication_and_the_Universal_Quantifier.lean'), full_name='
C03S01.Subset.trans')
(ProverActor pid=1564335) 2024-09-16 04:53:14.468 | INFO     | prover.proof_search_all_sorries:_best_first_search:171
 - Found a proof!
(ProverActor pid=1564335) 2024-09-16 04:53:27.411 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.le
an'), full_name='MyRing.self_sub'), status=<Status.PROVED: 'Proved'>, proof=['simp [sub_eq_add_neg]'], actor_time=1.9
208393399603665, environment_time=0.012737595941871405, total_time=2.9339742166921496, num_total_nodes=2, num_searche
d_nodes=1)
(ProverActor pid=1564335) 2024-09-16 04:53:27.417 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S01_Implication_and_the_Universal_Quantifier.lean'), full_name='
C03S01.my_lemma3')
(ProverActor pid=1563743) 2024-09-16 04:54:04.413 | INFO     | prover.proof_search_all_sorries:_best_first_search:171
 - Found a proof!
(ProverActor pid=1563743) 2024-09-16 04:54:18.610 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S01_Implication_and_the_Universal_Quantifier.lean'
), full_name='C03S01.Subset.trans'), status=<Status.PROVED: 'Proved'>, proof=['exact Set.Subset.trans'], actor_time=2
.2226747502572834, environment_time=0.0048689208924770355, total_time=3.2278334479779005, num_total_nodes=2, num_sear
ched_nodes=1)
(ProverActor pid=1564335) 2024-09-16 04:54:20.811 | INFO     | prover.proof_search_all_sorries:_best_first_search:171
 - Found a proof!
(ProverActor pid=1564335) 2024-09-16 04:54:32.158 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S01_Implication_and_the_Universal_Quantifier.lean'
), full_name='C03S01.my_lemma3'), status=<Status.PROVED: 'Proved'>, proof=['apply C03S01.my_lemma'], actor_time=1.676
7351171001792, environment_time=0.0061746141873300076, total_time=2.683324590791017, num_total_nodes=2, num_searched_
nodes=1)
(ProverActor pid=1563992) 2024-09-16 05:01:39.048 | INFO     | prover.proof_search_all_sorries:_best_first_search:149
 - 3124869.469399355
(ProverActor pid=1563992) 2024-09-16 05:01:39.049 | INFO     | prover.proof_search_all_sorries:_best_first_search:150
 - 3124269.472419336
(ProverActor pid=1563992) 2024-09-16 05:01:39.049 | INFO     | prover.proof_search_all_sorries:_best_first_search:151
 - 599.9974572020583
(ProverActor pid=1563992) 2024-09-16 05:01:39.049 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600
(ProverActor pid=1563992) 2024-09-16 05:01:39.049 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1564171) 2024-09-16 05:01:52.600 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C04_Sets_and_Functions/S02_Functions.lean'), full_name='Cant
or'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=501.6368091846816, environment_time=96.72416117461398, tot
al_time=600.996142742224, num_total_nodes=8642, num_searched_nodes=358)
(ProverActor pid=1564171) 2024-09-16 05:01:42.675 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600 [repeated 4x across cluster]
(ProverActor pid=1564171) 2024-09-16 05:01:42.676 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
2024-09-16 05:01:54.042 | INFO     | __main__:process_theorem_batch:798 - No proof found for C03S06.convergesTo_mul_c
onst
2024-09-16 05:01:54.042 | INFO     | __main__:process_theorem_batch:798 - No proof found for C03S06.convergesTo_add
2024-09-16 05:01:54.042 | INFO     | __main__:process_theorem_batch:798 - No proof found for C03S05.MyAbs.abs_lt
2024-09-16 05:01:54.042 | INFO     | __main__:process_theorem_batch:798 - No proof found for cauchySeq_of_le_geometri
c_two'
2024-09-16 05:01:54.042 | INFO     | __main__:process_theorem_batch:784 - Proof found for C03S05.MyAbs.le_abs_self
2024-09-16 05:01:54.045 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https:
//github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.045 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/
avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.045 | INFO     | __main__:process_theorem_batch:796 - Updated theorem C03S05.MyAbs.le_abs_self in
 the database
2024-09-16 05:01:54.045 | INFO     | __main__:process_theorem_batch:784 - Proof found for MyRing.two_mul
2024-09-16 05:01:54.046 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https:
//github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.046 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/
avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.046 | INFO     | __main__:process_theorem_batch:796 - Updated theorem MyRing.two_mul in the datab
ase
2024-09-16 05:01:54.046 | INFO     | __main__:process_theorem_batch:784 - Proof found for C03S04.aux
2024-09-16 05:01:54.047 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https:
//github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.047 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/
avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.047 | INFO     | __main__:process_theorem_batch:796 - Updated theorem C03S04.aux in the database
2024-09-16 05:01:54.047 | INFO     | __main__:process_theorem_batch:784 - Proof found for MyRing.self_sub
2024-09-16 05:01:54.048 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https:
//github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.048 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/
avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.048 | INFO     | __main__:process_theorem_batch:796 - Updated theorem MyRing.self_sub in the data
base
2024-09-16 05:01:54.048 | INFO     | __main__:process_theorem_batch:784 - Proof found for C03S01.Subset.trans
2024-09-16 05:01:54.049 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https:
//github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.049 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/
avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.049 | INFO     | __main__:process_theorem_batch:796 - Updated theorem C03S01.Subset.trans in the
database
2024-09-16 05:01:54.049 | INFO     | __main__:process_theorem_batch:784 - Proof found for C03S01.my_lemma3
2024-09-16 05:01:54.050 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https:
//github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.050 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/
avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:01:54.050 | INFO     | __main__:process_theorem_batch:796 - Updated theorem C03S01.my_lemma3 in the dat
abase
2024-09-16 05:01:54.050 | INFO     | __main__:process_theorem_batch:798 - No proof found for Cantor
2024-09-16 05:01:54.050 | INFO     | __main__:process_theorem_batch:798 - No proof found for C03S06.exists_abs_le_of_
convergesTo
Processing theorems from avigad/mathematics_in_lean_source:  80%|████████████████████████████████████████████████████
███████████████████████████████████████████████████████▏                          | 12/15 [22:09<05:32, 110.77s/theor
em]
2024-09-16 05:01:54.051 | INFO     | __main__:save_progress:807 - Saving encountered theorems...
2024-09-16 05:01:54.053 | INFO     | __main__:prove_sorry_theorems:903 - Finished attempting to prove sorry theorems
(ProverActor pid=1563992) 2024-09-16 05:01:54.040 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C
03S06.exists_abs_le_of_convergesTo'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=389.7761033056304, environ
ment_time=150.49608738115057, total_time=600.9976941682398, num_total_nodes=6144, num_searched_nodes=193)
2024-09-16 05:03:56.788 | INFO     | __main__:main:1661 - Finished searching for proofs of sorry theorems
2024-09-16 05:03:56.790 | INFO     | __main__:main:1664 - Shutting down Ray after proving
2024-09-16 05:03:59.250 | INFO     | __main__:main:1684 - Finished processing the repository
2024-09-16 05:03:59.250 | INFO     | __main__:main:1686 - current epoch: 2
2024-09-16 05:03:59.250 | INFO     | __main__:main:1356 - length of lean_git_repos: 14
2024-09-16 05:03:59.251 | INFO     | __main__:main:1357 - i: 2
2024-09-16 05:03:59.251 | INFO     | __main__:main:1363 - Main process
2024-09-16 05:03:59.251 | INFO     | __main__:main:1364 - Using lambda = 0.0
2024-09-16 05:03:59.251 | INFO     | __main__:main:1365 - Processing https://github.com/AlexKontorovich/PrimeNumberTh
eoremAnd
2024-09-16 05:03:59.251 | INFO     | __main__:main:1372 - Adding repo to repos_for_merged_dataset
2024-09-16 05:03:59.251 | INFO     | __main__:main:1384 - All GPUs
2024-09-16 05:03:59.251 | INFO     | __main__:main:1622 - Starting the prover
2024-09-16 05:03:59.251 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-16 05:03:59.251 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-16 05:03:59.251 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files per
manently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-16 05:03:59.666 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma/lean_p
roject/ReProver/retriever_random.ckpt
2024-09-16 05:03:59.667 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma/lean_p
roject/ReProver/retriever_random.ckpt
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files per
manently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint retriever_random.ckpt`
2024-09-16 05:04:01.046 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-16 05:04:01.404 | INFO     | prover.proof_search_all_sorries:__init__:452 - Loaded model from /data/yingzi_ma
/lean_project/model_lightning.ckpt
2024-09-16 05:04:01.405 | INFO     | prover.proof_search_all_sorries:__init__:453 - Using retriever: PremiseRetriever
(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-16 05:04:01.405 | INFO     | prover.proof_search_all_sorries:__init__:456 - Loading indexed corpus from /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_PrimeNumberTheoremAnd_89bf7b5e3a226
525e8580bae21ef543604f99b21/corpus.jsonl
2024-09-16 05:04:01.405 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/data
sets_PT_single_repo_no_ewc_curriculum/merged_with_new_PrimeNumberTheoremAnd_89bf7b5e3a226525e8580bae21ef543604f99b21/
corpus.jsonl
2024-09-16 05:04:01.406 | INFO     | __main__:main:2066 - An error occurred: [Errno 2] No such file or directory: '/d
ata/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_PrimeNumberTheoremAnd_89bf7b5e3a
226525e8580bae21ef543604f99b21/corpus.jsonl'
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_all_sorries.py", line 1640, in main
    prover = DistributedProver(
  File "/data/yingzi_ma/lean_project/ReProver/prover/proof_search_all_sorries.py", line 457, in __init__
    tac_gen.retriever.load_corpus(indexed_corpus_path)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 156, in load_corpus
    self.corpus = Corpus(path)
  File "/data/yingzi_ma/lean_project/ReProver/common.py", line 214, in __init__
    for line in open(jsonl_path):
FileNotFoundError: [Errno 2] No such file or directory: '/data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_
curriculum/merged_with_new_PrimeNumberTheoremAnd_89bf7b5e3a226525e8580bae21ef543604f99b21/corpus.jsonl'
(base) yingzi_ma@compute-permanent-node-845:~/lean_project/ReProver$ bash run_code6noretrieval.sh


Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554726.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555540.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554723.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554719.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554720.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555544.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554727.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554730.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554722.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554721.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555541.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554724.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_GCS.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555546.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554715.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555547.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555542.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_RAYLET.log': Permission denie
d
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554729.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554725.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555543.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554718.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554716.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_AUTOSCALER.log': Permission d
enied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554717.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555545.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554728.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554593.log': Perm
ission denied
Stopping ray
^Xç^CTraceback (most recent call last):
  File "/data/yingzi_ma/miniconda3/envs/ReProver/bin/ray", line 5, in <module>
    from ray.scripts.scripts import main
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/ray/scripts/scripts.py", line 2607, in
<module>
    from ray.serve.scripts import serve_cli
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/ray/serve/__init__.py", line 4, in <mod
ule>
    from ray.serve.api import (
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/ray/serve/api.py", line 14, in <module>
    from ray.serve._private.config import (
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/ray/serve/_private/config.py", line 29,
 in <module>
    from ray.serve._private.utils import DEFAULT, DeploymentOptionUpdateType
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/ray/serve/_private/utils.py", line 34,
in <module>
    import pandas as pd
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <modul
e>
    from pandas.core.api import (
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pandas/core/api.py", line 28, in <modul
e>
    from pandas.core.arrays import Categorical
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pandas/core/arrays/__init__.py", line 1
, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pandas/core/arrays/arrow/__init__.py",
line 1, in <module>
    from pandas.core.arrays.arrow.accessors import (
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pandas/core/arrays/arrow/accessors.py",
 line 23, in <module>
    import pyarrow.compute as pc
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pyarrow/compute.py", line 18, in <modul
e>
    from pyarrow._compute import (  # noqa
  File "<frozen importlib._bootstrap>", line 404, in parent
KeyboardInterrupt

(base) yingzi_ma@compute-permanent-node-845:~/lean_project/ReProver$ nvidia-smi
Mon Sep 16 05:11:13 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:15:00.0 Off |                    0 |
| N/A   37C    P0             83W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   39C    P0             87W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:91:00.0 Off |                    0 |
| N/A   36C    P0             87W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   38C    P0             88W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
(base) yingzi_ma@compute-permanent-node-845:~/lean_project/ReProver$ bash run_code3_all_sorries.sh


Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554726.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555540.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554723.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554719.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554720.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555544.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554727.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554730.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554722.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554721.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555541.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554724.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_GCS.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555546.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554715.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555547.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555542.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_RAYLET.log': Permission denie
d
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554729.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554725.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555543.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554718.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554716.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_AUTOSCALER.log': Permission d
enied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554717.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_555545.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554728.log': Perm
ission denied
rm: cannot remove '/tmp/ray/session_2024-08-15_18-46-05_429391_554139/logs/events/event_CORE_WORKER_554593.log': Perm
ission denied
Stopping ray
Could not terminate `/usr/bin/python3 /usr/local/bin/user_traffic_monitor.py` due to (pid=4060727, name='python3')
Did not find any active Ray processes.
Running main3_all_sorries.py
[2024-09-16 05:11:24,058] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detec
t)
2024-09-16 05:11:27.556 | INFO     | __main__:main:1242 - Running retrieval baseline
2024-09-16 05:11:27.557 | INFO     | __main__:main:1245 - Configuring LeanDojo...
2024-09-16 05:11:27.559 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /da
ta/yingzi_ma/lean_project/ReProver
2024-09-16 05:11:27.560 | INFO     | __main__:main:1247 - LeanDojo configured
2024-09-16 05:11:27.560 | INFO     | __main__:main:1252 - Starting the main process
2024-09-16 05:11:27.560 | INFO     | __main__:main:1260 - Loading database from /data/yingzi_ma/lean_project/dynamic_
database_PT_single_repo_no_ewc_curriculum_full.json
2024-09-16 05:12:33.572 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-16 05:12:33.572 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/l
ecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-16 05:12:41.320 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-16 05:12:41.320 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/I
mperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-16 05:12:50.239 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-16 05:12:50.239 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/t
eorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-16 05:12:52.294 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-16 05:12:52.294 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/A
lexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-16 05:13:03.752 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-16 05:13:03.752 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/d
wrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-16 05:13:14.536 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/google-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-16 05:13:14.536 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/g
oogle-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-16 05:13:16.524 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:13:16.525 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/a
vigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-16 05:13:16.666 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/digama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-16 05:13:16.666 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/d
igama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-16 05:13:28.922 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/eric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-16 05:13:28.922 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/e
ric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-16 05:13:30.820 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-16 05:13:30.821 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/y
uma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-16 05:13:31.182 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/loganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-16 05:13:31.183 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/l
oganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-16 05:13:31.802 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/FormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-16 05:13:31.802 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/F
ormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-16 05:13:31.946 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/leanprover-community/lean-auto (commit: 0f5f39a0336e36ae4ba8ab45b27865ebd9f8f025)
2024-09-16 05:13:31.947 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/l
eanprover-community/lean-auto (commit: 0f5f39a0336e36ae4ba8ab45b27865ebd9f8f025)
2024-09-16 05:13:32.033 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/nomeata/loogle (commit: 387ab85308ce817bb95cc99730025eb44cb8a9ab)
2024-09-16 05:13:32.033 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/n
omeata/loogle (commit: 387ab85308ce817bb95cc99730025eb44cb8a9ab)
2024-09-16 05:13:32.760 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/leanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-16 05:13:32.760 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/l
eanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-16 05:13:33.054 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/siddhartha-gadgil/Saturn (commit: 3811a9dd46cdfd5fa0c0c1896720c28d2ec4a42a)
2024-09-16 05:13:33.054 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/s
iddhartha-gadgil/Saturn (commit: 3811a9dd46cdfd5fa0c0c1896720c28d2ec4a42a)
2024-09-16 05:13:49.197 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/leanprover-community/flt-regular (commit: 359ab563c7ba5d775c1878ac7b3d0c4095b37ec4)
2024-09-16 05:13:49.197 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/l
eanprover-community/flt-regular (commit: 359ab563c7ba5d775c1878ac7b3d0c4095b37ec4)
2024-09-16 05:13:50.978 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://gith
ub.com/rami3l/plfl (commit: 1a25fc310d8fb0c6e21ab9e385cc7dac0c31f77a)
2024-09-16 05:13:50.978 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/r
ami3l/plfl (commit: 1a25fc310d8fb0c6e21ab9e385cc7dac0c31f77a)
2024-09-16 05:13:52.495 | INFO     | __main__:main:1262 - Loaded database from /data/yingzi_ma/lean_project/dynamic_d
atabase_PT_single_repo_no_ewc_curriculum_full.json
2024-09-16 05:13:52.497 | INFO     | __main__:main:1269 - Found 14 repositories
2024-09-16 05:13:52.497 | INFO     | __main__:main:1272 - Starting curriculum learning
2024-09-16 05:13:52.751 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for
 lean4 v4.8.0
2024-09-16 05:14:09.471 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for
 lean4 v4.8.0-rc2
2024-09-16 05:14:27.675 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for
 lean4 v4.8.0-rc1
2024-09-16 05:14:44.427 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for
 lean4 v4.7.0
2024-09-16 05:15:02.308 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for
 lean4 v4.7.0-rc2
2024-09-16 05:15:20.189 | INFO     | __main__:main:1357 - length of lean_git_repos: 14
2024-09-16 05:15:20.189 | INFO     | __main__:main:1358 - i: 0
2024-09-16 05:15:20.189 | INFO     | __main__:main:1364 - Main process
2024-09-16 05:15:20.189 | INFO     | __main__:main:1365 - Using lambda = 0.0
2024-09-16 05:15:20.190 | INFO     | __main__:main:1366 - Processing https://github.com/dwrensha/compfiles
2024-09-16 05:15:20.190 | INFO     | __main__:main:1373 - Adding repo to repos_for_merged_dataset
2024-09-16 05:15:20.190 | INFO     | __main__:main:1385 - All GPUs
2024-09-16 05:15:20.190 | INFO     | __main__:main:1623 - Starting the prover
2024-09-16 05:15:20.190 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-16 05:15:20.190 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-16 05:15:20.190 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You
are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module im
plicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See
https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the
 default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during
unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowli
sted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for a
ny use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues relat
ed to this experimental feature.
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files per
manently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-16 05:15:20.811 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma/lean_p
roject/ReProver/retriever_random.ckpt
2024-09-16 05:15:20.812 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma/lean_p
roject/ReProver/retriever_random.ckpt
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files per
manently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint retriever_random.ckpt`
2024-09-16 05:15:22.226 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Found key
s that are in the model state dict but not in the checkpoint: ['retriever.encoder.shared.weight', 'retriever.encoder.
encoder.embed_tokens.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.q.weight', 'retriever.encoder.
encoder.block.0.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.v.weight',
'retriever.encoder.encoder.block.0.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAt
tention.relative_attention_bias.weight', 'retriever.encoder.encoder.block.0.layer.0.layer_norm.weight', 'retriever.en
coder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.
wi_1.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.
0.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.q.weight', 'retriever.encoder.
encoder.block.1.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.v.weight',
'retriever.encoder.encoder.block.1.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.1.layer.0.layer_
norm.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.bloc
k.1.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'retri
ever.encoder.encoder.block.1.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.q.w
eight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.2.layer.
0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.o.weight', 'retriever.encoder.enc
oder.block.2.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 'ret
riever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseR
eluDense.wo.weight', 'retriever.encoder.encoder.block.2.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.
3.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.k.weight', 'retriever.enc
oder.encoder.block.3.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.o.weig
ht', 'retriever.encoder.encoder.block.3.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseR
eluDense.wi_0.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.enc
oder.block.3.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.3.layer.1.layer_norm.weight', 'retri
ever.encoder.encoder.block.4.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttentio
n.k.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.4.l
ayer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.4.layer.0.layer_norm.weight', 'retriever.encoder.enc
oder.block.4.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weig
ht', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.4.layer.1
.layer_norm.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.b
lock.5.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.v.weight', 'retrieve
r.encoder.encoder.block.5.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.5.layer.0.layer_norm.weig
ht', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.5.layer
.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'retriever.enco
der.encoder.block.5.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.q.weight', '
retriever.encoder.encoder.block.6.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAtt
ention.v.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.bloc
k.6.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight', 'retriever.en
coder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.
wo.weight', 'retriever.encoder.encoder.block.6.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.0
.SelfAttention.q.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.k.weight', 'retriever.encoder.enco
der.block.7.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.o.weight', 'ret
riever.encoder.encoder.block.7.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.
wi_0.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.bloc
k.7.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.7.layer.1.layer_norm.weight', 'retriever.enco
der.encoder.block.8.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.k.weigh
t', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.8.layer.0.Se
lfAttention.o.weight', 'retriever.encoder.encoder.block.8.layer.0.layer_norm.weight', 'retriever.encoder.encoder.bloc
k.8.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 'ret
riever.encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.8.layer.1.layer_no
rm.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.9.la
yer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.v.weight', 'retriever.encoder
.encoder.block.9.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.9.layer.0.layer_norm.weight', 'ret
riever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseR
eluDense.wi_1.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encod
er.block.9.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.q.weight', 'retrieve
r.encoder.encoder.block.10.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention
.v.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.10.
layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'retriever.encod
er.encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.w
o.weight', 'retriever.encoder.encoder.block.10.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.
0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.k.weight', 'retriever.encoder.en
coder.block.11.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.o.weight',
'retriever.encoder.encoder.block.11.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseRelu
Dense.wi_0.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encod
er.block.11.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.11.layer.1.layer_norm.weight', 'retri
ever.encoder.encoder.final_layer_norm.weight']
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Found key
s that are not in the model state dict but in the checkpoint: ['pytorch-lightning_version', 'global_step', 'epoch', '
state_dict', 'callbacks', 'loops', 'legacy_pytorch-lightning_version', 'hyper_parameters']
2024-09-16 05:15:22.732 | INFO     | prover.proof_search_all_sorries:__init__:452 - Loaded model from /data/yingzi_ma
/lean_project/model_lightning.ckpt
2024-09-16 05:15:22.733 | INFO     | prover.proof_search_all_sorries:__init__:453 - Using retriever: PremiseRetriever
(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-16 05:15:22.733 | INFO     | prover.proof_search_all_sorries:__init__:456 - Loading indexed corpus from /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_compfiles_f99bf6f2928d47dd1a445b414
b3a723c2665f091/corpus.jsonl
2024-09-16 05:15:22.734 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/data
sets_PT_single_repo_no_ewc_curriculum/merged_with_new_compfiles_f99bf6f2928d47dd1a445b414b3a723c2665f091/corpus.jsonl
2024-09-16 05:15:41.308 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: True
2024-09-16 05:15:41.309 | INFO     | prover.proof_search_all_sorries:__init__:458 - Loaded indexed corpus from /data/
yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_compfiles_f99bf6f2928d47dd1a445b414b
3a723c2665f091/corpus.jsonl
2024-09-16 05:15:41.309 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
 54%|████████████████████████████████████████▋                                   | 2983/5566 [04:29< 54%|████████████
████████████████████████████▊                                   | 2985/5566 [04:30< 54%|█████████████████████████████
███████████▊                                   | 2987/5566 [04:30< 54%|████████████████████████████████████████▊
 54%|█████████████████████████████████████████▏                                  | 3015/5566 [04:32 54%|█████████████
████████████████████████████▏                                  | 3017/5566 [04:33< 54%|██████████████████████████████
███████████▏                                  | 3019/5566 [04:33<04:25,  9. 54%|█████████████████████████████████████
████▏                                  | 3021/ 54%|█████████████████████████████████████████▎
          | 3023/ 54%|█████████████████████████████████████████▎                                  | 3024/ 54%|███████
██████████████████████████████████▎                                  | 3026/ 54%|████████████████████████████████████
█████▎                                  | 3028/ 54%|█████████████████████████████████████████▎
           | 3030/5566 [04:34< 54%|█████████████████████████████████████████▍                                  | 3032
/5566 [04:34< 55%|█████████████████████████████████████████▍                                  | 3034/5566 [04:34< 55%
100%|████████████████████████████████████████████████████████████████████████████| 5566/5566 [09:01<00:00, 10.28it/s]
2024-09-16 05:24:42.663 | INFO     | prover.proof_search_all_sorries:__init__:460 - Finished reindexing!
2024-09-16 05:24:42.663 | INFO     | prover.proof_search_all_sorries:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-16 05:24:46,499 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8265
(pid=1623141) [2024-09-16 05:25:39,277] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1623141) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1623141)   return torch.load(io.BytesIO(b))
(pid=1623342) [2024-09-16 05:26:07,963] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1623342) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1623342)   return torch.load(io.BytesIO(b))
(pid=1623943) [2024-09-16 05:26:37,710] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1623943) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1623943)   return torch.load(io.BytesIO(b))
2024-09-16 05:27:02.054 | INFO     | __main__:load_encountered_theorems:827 - The file encountered_theorems_PT_single
_repo_no_ewc_curriculum_full_new.pkl does not exist. Starting with an empty set.
2024-09-16 05:27:02.055 | INFO     | __main__:prove_sorry_theorems:853 - Found 5 sorry theorems to prove
Processing theorems from dwrensha/compfiles:   0%|                                        | 0/5 [00:00<?, ?theorem/s]
2024-09-16 05:27:02.056 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for Imo2008P5.even_subse
ts_card
2024-09-16 05:27:02.056 | INFO     | __main__:prove_sorry_theorems:877 - Position: (114, 1)
2024-09-16 05:27:02.056 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for Bulgaria1998P6.lemma
_1'
2024-09-16 05:27:02.056 | INFO     | __main__:prove_sorry_theorems:877 - Position: (29, 1)
2024-09-16 05:27:02.056 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for Imo2009P6.imo2009_p6
_aux1
2024-09-16 05:27:02.056 | INFO     | __main__:prove_sorry_theorems:877 - Position: (73, 1)
2024-09-16 05:27:02.057 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for Imo2001P1.lemma1
2024-09-16 05:27:02.057 | INFO     | __main__:prove_sorry_theorems:877 - Position: (41, 1)
2024-09-16 05:27:02.057 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for Imo2008P5.claim
2024-09-16 05:27:02.057 | INFO     | __main__:prove_sorry_theorems:877 - Position: (118, 1)
Processing theorems from dwrensha/compfiles: 100%|██████████████████████████████| 5/5 [00:00<00:00, 4046.99theorem/s]
2024-09-16 05:27:02.057 | INFO     | prover.proof_search_all_sorries:search_unordered:514 - Distributed
(ProverActor pid=1623141) 2024-09-16 05:27:02.068 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3a723c2665f091'
), file_path=PosixPath('Compfiles/Imo2001P1.lean'), full_name='Imo2001P1.lemma1')
(ProverActor pid=1623943) 2024-09-16 05:27:08.890 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3a723c2665f091'
), file_path=PosixPath('Compfiles/Bulgaria1998P6.lean'), full_name="Bulgaria1998P6.lemma_1'") [repeated 2x across clu
ster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.i
o/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)
(pid=1624158) [2024-09-16 05:27:09,191] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1624158) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1624158)   return torch.load(io.BytesIO(b))
(ProverActor pid=1624158) 2024-09-16 05:27:36.076 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3a723c2665f091'
), file_path=PosixPath('Compfiles/Imo2008P5.lean'), full_name='Imo2008P5.even_subsets_card')
(ProverActor pid=1623943) 2024-09-16 05:38:54.461 | INFO     | prover.proof_search_all_sorries:_best_first_search:149
 - 3127104.882180628
(ProverActor pid=1623943) 2024-09-16 05:38:54.461 | INFO     | prover.proof_search_all_sorries:_best_first_search:150
 - 3126504.884666622
(ProverActor pid=1623943) 2024-09-16 05:38:54.462 | INFO     | prover.proof_search_all_sorries:_best_first_search:151
 - 599.9980345587246
(ProverActor pid=1623943) 2024-09-16 05:38:54.462 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600
(ProverActor pid=1623943) 2024-09-16 05:38:54.462 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1623943) 2024-09-16 05:39:13.870 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3
a723c2665f091'), file_path=PosixPath('Compfiles/Bulgaria1998P6.lean'), full_name="Bulgaria1998P6.lemma_1'"), status=<
Status.OPEN: 'Open'>, proof=None, actor_time=226.33259714394808, environment_time=373.26233360311016, total_time=600.
9982504737563, num_total_nodes=3669, num_searched_nodes=109)
(ProverActor pid=1623943) 2024-09-16 05:39:13.876 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3a723c2665f091'
), file_path=PosixPath('Compfiles/Imo2008P5.lean'), full_name='Imo2008P5.claim')
(ProverActor pid=1624158) 2024-09-16 05:38:57.236 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600 [repeated 8x across cluster]
(ProverActor pid=1624158) 2024-09-16 05:38:57.236 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions). [repeated 2x across cluster]
(ProverActor pid=1623342) 2024-09-16 05:39:17.655 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3
a723c2665f091'), file_path=PosixPath('Compfiles/Imo2009P6.lean'), full_name='Imo2009P6.imo2009_p6_aux1'), status=<Sta
tus.OPEN: 'Open'>, proof=None, actor_time=131.22266014805064, environment_time=464.5750319105573, total_time=600.9973
437166773, num_total_nodes=1710, num_searched_nodes=58) [repeated 2x across cluster]
(ProverActor pid=1623141) 2024-09-16 05:39:46.674 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600 [repeated 4x across cluster]
(ProverActor pid=1623141) 2024-09-16 05:39:46.674 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1623141) 2024-09-16 05:40:01.289 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3
a723c2665f091'), file_path=PosixPath('Compfiles/Imo2001P1.lean'), full_name='Imo2001P1.lemma1'), status=<Status.OPEN:
 'Open'>, proof=None, actor_time=64.95514440862462, environment_time=477.9999277330935, total_time=600.9994613020681,
 num_total_nodes=503, num_searched_nodes=17)
(ProverActor pid=1623943) 2024-09-16 05:50:08.192 | INFO     | prover.proof_search_all_sorries:_best_first_search:149
 - 3127778.61288863
(ProverActor pid=1623943) 2024-09-16 05:50:08.192 | INFO     | prover.proof_search_all_sorries:_best_first_search:150
 - 3127178.6172267
(ProverActor pid=1623943) 2024-09-16 05:50:08.192 | INFO     | prover.proof_search_all_sorries:_best_first_search:151
 - 599.9961071610451
(ProverActor pid=1623943) 2024-09-16 05:50:08.192 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600
(ProverActor pid=1623943) 2024-09-16 05:50:08.192 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
2024-09-16 05:50:37.479 | INFO     | __main__:process_theorem_batch:799 - No proof found for Bulgaria1998P6.lemma_1'
2024-09-16 05:50:37.479 | INFO     | __main__:process_theorem_batch:799 - No proof found for Imo2008P5.even_subsets_c
ard
2024-09-16 05:50:37.479 | INFO     | __main__:process_theorem_batch:799 - No proof found for Imo2009P6.imo2009_p6_aux
1
2024-09-16 05:50:37.480 | INFO     | __main__:process_theorem_batch:799 - No proof found for Imo2001P1.lemma1
2024-09-16 05:50:37.480 | INFO     | __main__:process_theorem_batch:799 - No proof found for Imo2008P5.claim
2024-09-16 05:50:37.480 | INFO     | __main__:save_progress:808 - Saving encountered theorems...
2024-09-16 05:50:37.481 | INFO     | __main__:prove_sorry_theorems:904 - Finished attempting to prove sorry theorems
(ProverActor pid=1623943) 2024-09-16 05:50:37.477 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/dwrensha/compfiles', commit='f99bf6f2928d47dd1a445b414b3
a723c2665f091'), file_path=PosixPath('Compfiles/Imo2008P5.lean'), full_name='Imo2008P5.claim'), status=<Status.OPEN:
'Open'>, proof=None, actor_time=223.5190186984837, environment_time=373.0064756963402, total_time=600.9963096263818,
num_total_nodes=3969, num_searched_nodes=126)
2024-09-16 05:52:39.678 | INFO     | __main__:main:1662 - Finished searching for proofs of sorry theorems
2024-09-16 05:52:39.679 | INFO     | __main__:main:1665 - Shutting down Ray after proving
2024-09-16 05:52:43.180 | INFO     | __main__:main:1685 - Finished processing the repository
2024-09-16 05:52:43.180 | INFO     | __main__:main:1687 - current epoch: 1
2024-09-16 05:52:43.181 | INFO     | __main__:main:1357 - length of lean_git_repos: 14
2024-09-16 05:52:43.181 | INFO     | __main__:main:1358 - i: 1
2024-09-16 05:52:43.181 | INFO     | __main__:main:1364 - Main process
2024-09-16 05:52:43.181 | INFO     | __main__:main:1365 - Using lambda = 0.0
2024-09-16 05:52:43.181 | INFO     | __main__:main:1366 - Processing https://github.com/avigad/mathematics_in_lean_so
urce
2024-09-16 05:52:43.181 | INFO     | __main__:main:1373 - Adding repo to repos_for_merged_dataset
2024-09-16 05:52:43.181 | INFO     | __main__:main:1385 - All GPUs
2024-09-16 05:52:43.181 | INFO     | __main__:main:1623 - Starting the prover
2024-09-16 05:52:43.181 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-16 05:52:43.181 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-16 05:52:43.181 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You
are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module im
plicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See
https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the
 default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during
unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowli
sted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for a
ny use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues relat
ed to this experimental feature.
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files per
manently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-16 05:52:43.404 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma/lean_p
roject/ReProver/retriever_random.ckpt
2024-09-16 05:52:43.404 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma/lean_p
roject/ReProver/retriever_random.ckpt
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files per
manently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint retriever_random.ckpt`
2024-09-16 05:52:44.584 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Found key
s that are in the model state dict but not in the checkpoint: ['retriever.encoder.shared.weight', 'retriever.encoder.
encoder.embed_tokens.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.q.weight', 'retriever.encoder.
encoder.block.0.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.v.weight',
'retriever.encoder.encoder.block.0.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAt
tention.relative_attention_bias.weight', 'retriever.encoder.encoder.block.0.layer.0.layer_norm.weight', 'retriever.en
coder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.
wi_1.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.
0.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.q.weight', 'retriever.encoder.
encoder.block.1.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.v.weight',
'retriever.encoder.encoder.block.1.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.1.layer.0.layer_
norm.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.bloc
k.1.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'retri
ever.encoder.encoder.block.1.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.q.w
eight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.2.layer.
0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.o.weight', 'retriever.encoder.enc
oder.block.2.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 'ret
riever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseR
eluDense.wo.weight', 'retriever.encoder.encoder.block.2.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.
3.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.k.weight', 'retriever.enc
oder.encoder.block.3.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.o.weig
ht', 'retriever.encoder.encoder.block.3.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseR
eluDense.wi_0.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.enc
oder.block.3.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.3.layer.1.layer_norm.weight', 'retri
ever.encoder.encoder.block.4.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttentio
n.k.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.4.l
ayer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.4.layer.0.layer_norm.weight', 'retriever.encoder.enc
oder.block.4.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weig
ht', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.4.layer.1
.layer_norm.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.b
lock.5.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.v.weight', 'retrieve
r.encoder.encoder.block.5.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.5.layer.0.layer_norm.weig
ht', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.5.layer
.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'retriever.enco
der.encoder.block.5.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.q.weight', '
retriever.encoder.encoder.block.6.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAtt
ention.v.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.bloc
k.6.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight', 'retriever.en
coder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.
wo.weight', 'retriever.encoder.encoder.block.6.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.0
.SelfAttention.q.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.k.weight', 'retriever.encoder.enco
der.block.7.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.o.weight', 'ret
riever.encoder.encoder.block.7.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.
wi_0.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.bloc
k.7.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.7.layer.1.layer_norm.weight', 'retriever.enco
der.encoder.block.8.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.k.weigh
t', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.8.layer.0.Se
lfAttention.o.weight', 'retriever.encoder.encoder.block.8.layer.0.layer_norm.weight', 'retriever.encoder.encoder.bloc
k.8.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 'ret
riever.encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.8.layer.1.layer_no
rm.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.9.la
yer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.v.weight', 'retriever.encoder
.encoder.block.9.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.9.layer.0.layer_norm.weight', 'ret
riever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseR
eluDense.wi_1.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encod
er.block.9.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.q.weight', 'retrieve
r.encoder.encoder.block.10.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention
.v.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.10.
layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'retriever.encod
er.encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.w
o.weight', 'retriever.encoder.encoder.block.10.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.
0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.k.weight', 'retriever.encoder.en
coder.block.11.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.o.weight',
'retriever.encoder.encoder.block.11.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseRelu
Dense.wi_0.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encod
er.block.11.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.11.layer.1.layer_norm.weight', 'retri
ever.encoder.encoder.final_layer_norm.weight']
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Found key
s that are not in the model state dict but in the checkpoint: ['pytorch-lightning_version', 'global_step', 'epoch', '
state_dict', 'callbacks', 'loops', 'legacy_pytorch-lightning_version', 'hyper_parameters']
2024-09-16 05:52:45.025 | INFO     | prover.proof_search_all_sorries:__init__:452 - Loaded model from /data/yingzi_ma
/lean_project/model_lightning.ckpt
2024-09-16 05:52:45.026 | INFO     | prover.proof_search_all_sorries:__init__:453 - Using retriever: PremiseRetriever
(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-16 05:52:45.026 | INFO     | prover.proof_search_all_sorries:__init__:456 - Loading indexed corpus from /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_mathematics_in_lean_source_5297e0fb
051367c48c0a084411853a576389ecf5/corpus.jsonl
2024-09-16 05:52:45.026 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/data
sets_PT_single_repo_no_ewc_curriculum/merged_with_new_mathematics_in_lean_source_5297e0fb051367c48c0a084411853a576389
ecf5/corpus.jsonl
2024-09-16 05:52:52.094 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: True
2024-09-16 05:52:52.094 | INFO     | prover.proof_search_all_sorries:__init__:458 - Loaded indexed corpus from /data/
yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_mathematics_in_lean_source_5297e0fb0
51367c48c0a084411853a576389ecf5/corpus.jsonl
2024-09-16 05:52:52.094 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|████████████████████████████████████████████████████████████████████████████| 3679/3679 [05:38<00:00, 10.87it/s]
2024-09-16 05:58:30.476 | INFO     | prover.proof_search_all_sorries:__init__:460 - Finished reindexing!
2024-09-16 05:58:30.476 | INFO     | prover.proof_search_all_sorries:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-16 05:58:33,921 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8265
(pid=1675049) [2024-09-16 05:59:12,666] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1675049) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1675049)   return torch.load(io.BytesIO(b))
(pid=1675617) [2024-09-16 05:59:23,786] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1675617) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1675617)   return torch.load(io.BytesIO(b))
(pid=1675787) [2024-09-16 05:59:34,841] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
2024-09-16 05:59:38.493 | INFO     | __main__:prove_sorry_theorems:853 - Found 9 sorry theorems to prove
Processing theorems from avigad/mathematics_in_lean_source:   0%|                         | 0/9 [00:00<?, ?theorem/s]
2024-09-16 05:59:38.493 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for cauchySeq_of_le_geom
etric_two'
2024-09-16 05:59:38.493 | INFO     | __main__:prove_sorry_theorems:877 - Position: (423, 1)
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for C03S06.convergesTo_m
ul_const
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:877 - Position: (199, 1)
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for C03S06.convergesTo_a
dd
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:877 - Position: (143, 1)
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for C03S05.MyAbs.abs_lt
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:877 - Position: (196, 1)
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for Cantor
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:877 - Position: (673, 1)
2024-09-16 05:59:38.494 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for C03S06.exists_abs_le
_of_convergesTo
2024-09-16 05:59:38.495 | INFO     | __main__:prove_sorry_theorems:877 - Position: (239, 1)
2024-09-16 05:59:38.495 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for C03S06.convergesTo_u
nique
2024-09-16 05:59:38.495 | INFO     | __main__:prove_sorry_theorems:877 - Position: (332, 1)
2024-09-16 05:59:38.495 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for C03S06.aux
2024-09-16 05:59:38.495 | INFO     | __main__:prove_sorry_theorems:877 - Position: (275, 1)
2024-09-16 05:59:38.495 | INFO     | __main__:prove_sorry_theorems:876 - Searching for proof for C03S05.MyAbs.lt_abs
2024-09-16 05:59:38.495 | INFO     | __main__:prove_sorry_theorems:877 - Position: (193, 1)
Processing theorems from avigad/mathematics_in_lean_source: 100%|███████████████| 9/9 [00:00<00:00, 4654.59theorem/s]
2024-09-16 05:59:38.495 | INFO     | prover.proof_search_all_sorries:search_unordered:514 - Distributed
(ProverActor pid=1675049) 2024-09-16 05:59:38.505 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.abs_lt')
(ProverActor pid=1675787) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1675787)   return torch.load(io.BytesIO(b))
(pid=1675989) [2024-09-16 05:59:46,142] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cu
da (auto detect)
(ProverActor pid=1675787) 2024-09-16 05:59:48.805 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C03S06.converge
sTo_mul_const') [repeated 2x across cluster]
(ProverActor pid=1675989) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414:
 FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the defa
ult pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code dur
ing unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a
 future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could
 be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they ar
e explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weig
hts_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub
for any issues related to this experimental feature.
(ProverActor pid=1675989)   return torch.load(io.BytesIO(b))
(ProverActor pid=1675989) 2024-09-16 06:00:02.598 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C09_Topology/S02_Metric_Spaces.lean'), full_name="cauchySeq_of_le_geometri
c_two'")
(ProverActor pid=1675617) 2024-09-16 06:10:40.099 | INFO     | prover.proof_search_all_sorries:_best_first_search:149
 - 3129010.520273836
(ProverActor pid=1675617) 2024-09-16 06:10:40.100 | INFO     | prover.proof_search_all_sorries:_best_first_search:150
 - 3128410.523120076
(ProverActor pid=1675617) 2024-09-16 06:10:40.100 | INFO     | prover.proof_search_all_sorries:_best_first_search:151
 - 599.9978854390793
(ProverActor pid=1675617) 2024-09-16 06:10:40.100 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600
(ProverActor pid=1675617) 2024-09-16 06:10:40.102 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1675787) 2024-09-16 06:10:49.394 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C
03S06.convergesTo_mul_const'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=352.6671527964063, environment_ti
me=247.02326117642224, total_time=600.9978074380197, num_total_nodes=5718, num_searched_nodes=164)
(ProverActor pid=1675787) 2024-09-16 06:10:49.400 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C04_Sets_and_Functions/S02_Functions.lean'), full_name='Cantor')
(ProverActor pid=1675787) 2024-09-16 06:10:40.214 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600 [repeated 4x across cluster]
(ProverActor pid=1675787) 2024-09-16 06:10:40.214 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1675617) 2024-09-16 06:10:49.712 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C03S06.exists_a
bs_le_of_convergesTo')
(ProverActor pid=1675989) 2024-09-16 06:10:51.243 | INFO     | prover.proof_search_all_sorries:_best_first_search:163
 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1675989) 2024-09-16 06:11:02.695 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C09_Topology/S02_Metric_Spaces.lean'), full_name="cauchySeq_
of_le_geometric_two'"), status=<Status.OPEN: 'Open'>, proof=None, actor_time=123.70805957401171, environment_time=446
.86083763325587, total_time=600.9931714995764, num_total_nodes=1187, num_searched_nodes=36)
(ProverActor pid=1675617) 2024-09-16 06:10:49.707 | INFO     | prover.proof_search_all_sorries:search:128 - SearchRes
ult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb0513
67c48c0a084411853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C
03S06.convergesTo_add'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=331.4104758393951, environment_time=266
.947373138275, total_time=600.9999291412532, num_total_nodes=5490, num_searched_nodes=159)
(ProverActor pid=1675989) 2024-09-16 06:10:51.243 | INFO     | prover.proof_search_all_sorries:_best_first_search:152
 - 600 [repeated 4x across cluster]
(ProverActor pid=1675989) 2024-09-16 06:11:02.701 | INFO     | prover.proof_search_all_sorries:search:81 - Proving Th
eorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411
853a576389ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C03S06.converge
sTo_unique')

