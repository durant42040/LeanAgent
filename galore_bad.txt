(base) adarsh@tensorlab-DGX-Station-A100-920-23487-2531-000:~/ReProver$ bash run_compute_server.sh
Script executed from: /home/adarsh/ReProver
[2024-08-11 08:15:51,408] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda
 (auto detect)
 [WARNING]  async_io requires the dev libaio .so object and headers but these were not found.
 [WARNING]  async_io: please install the libaio-dev package with apt
 [WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS envi
ronment variables to where it can be found.
 [WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
 [WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4
 [WARNING]  using untested triton version (3.0.0), only 1.0.0 is known to be compatible
/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/deepspeed/runtime/zero/li
near.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.cust
om_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/deepspeed/runtime/zero/li
near.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.cust
om_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
2024-08-11 08:16:03.365 | INFO     | __main__:check_progress_file:586 - Checking contents of /home/adarsh
/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning/loops/progress.py
2024-08-11 08:16:03.365 | INFO     | __main__:check_progress_file:590 - Contents of progress.py:
2024-08-11 08:16:03.365 | INFO     | __main__:check_progress_file:591 - # Copyright The Lightning AI team
.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from dataclasses import asdict, dataclass, field
from typing import Type

from typing_extensions import override


@dataclass
class _BaseProgress:
    """Mixin that implements state-loading utilities for dataclasses."""

    def state_dict(self) -> dict:
        return asdict(self)

    def load_state_dict(self, state_dict: dict) -> None:
        if state_dict["completed"] == None:
            state_dict["completed"] = 0
        self.__dict__.update(state_dict)

    @classmethod
    def from_state_dict(cls, state_dict: dict) -> "_BaseProgress":
        obj = cls()
        obj.load_state_dict(state_dict)
        return obj

    def reset(self) -> None:
        """Reset the object's state."""
        raise NotImplementedError


@dataclass
class _ReadyCompletedTracker(_BaseProgress):
    """Track an event's progress.

    Args:
        ready: Intended to track the number of events ready to start.
        completed: Intended to be incremented after the event completes (e.g. after ``on_*_end`` runs).

    These attributes should be increased in order, that is, :attr:`ready` first and :attr:`completed` las
t.

    """

    ready: int = 0
    completed: int = 0

    @override
    def reset(self) -> None:
        """Reset the state."""
        self.ready = 0
        self.completed = 0

    def reset_on_restart(self) -> None:
        """Reset the progress on restart.

        If there is a failure before all attributes are increased, restore the attributes to the last ful
ly completed
        value.

        """
        self.ready = self.completed


@dataclass
class _StartedTracker(_ReadyCompletedTracker):
    """Track an event's progress.

    Args:
        ready: Intended to track the number of events ready to start.
        started: Intended to be incremented after the event is started (e.g. after ``on_*_start`` runs).
        completed: Intended to be incremented after the event completes (e.g. after ``on_*_end`` runs).

    These attributes should be increased in order, that is, :attr:`ready` first and :attr:`completed` las
t.

    """

    started: int = 0

    @override
    def reset(self) -> None:
        super().reset()
        self.started = 0

    @override
    def reset_on_restart(self) -> None:
        super().reset_on_restart()
        self.started = self.completed


@dataclass
class _ProcessedTracker(_StartedTracker):
    """Track an event's progress.

    Args:
        ready: Intended to track the number of events ready to start.
        started: Intended to be incremented after the event is started (e.g. after ``on_*_start`` runs).
        processed: Intended to be incremented after the event is processed.
        completed: Intended to be incremented after the event completes (e.g. after ``on_*_end`` runs).

    These attributes should be increased in order, that is, :attr:`ready` first and :attr:`completed` las
t.

    """

    processed: int = 0

    @override
    def reset(self) -> None:
        super().reset()
        self.processed = 0

    @override
    def reset_on_restart(self) -> None:
        super().reset_on_restart()
        self.processed = self.completed


@dataclass
class _Progress(_BaseProgress):
    """Track aggregated and current progress.

    Args:
        total: Intended to track the total progress of an event.
        current: Intended to track the current progress of an event.

    """

    total: _ReadyCompletedTracker = field(default_factory=_ProcessedTracker)
    current: _ReadyCompletedTracker = field(default_factory=_ProcessedTracker)

    def __post_init__(self) -> None:
        if self.total.__class__ is not self.current.__class__:
            raise ValueError("The `total` and `current` instances should be of the same class")

    def increment_ready(self) -> None:
        self.total.ready += 1
        self.current.ready += 1

    def increment_started(self) -> None:
        if not isinstance(self.total, _StartedTracker):
            raise TypeError(f"`{self.total.__class__.__name__}` doesn't have a `started` attribute")
        self.total.started += 1
        self.current.started += 1

    def increment_processed(self) -> None:
        if not isinstance(self.total, _ProcessedTracker):
            raise TypeError(f"`{self.total.__class__.__name__}` doesn't have a `processed` attribute")
        self.total.processed += 1
        self.current.processed += 1

    def increment_completed(self) -> None:
        self.total.completed += 1
        self.current.completed += 1

    @classmethod
    def from_defaults(cls, tracker_cls: Type[_ReadyCompletedTracker], **kwargs: int) -> "_Progress":
        """Utility function to easily create an instance from keyword arguments to both ``Tracker``s."""
        return cls(total=tracker_cls(**kwargs), current=tracker_cls(**kwargs))

    @override
    def reset(self) -> None:
        self.total.reset()
        self.current.reset()

    def reset_on_run(self) -> None:
        self.current.reset()

    def reset_on_restart(self) -> None:
        self.current.reset_on_restart()

    @override
    def load_state_dict(self, state_dict: dict) -> None:
        if state_dict["total"]["completed"] == None:
            state_dict["total"]["completed"] = 0
        self.total.load_state_dict(state_dict["total"])
        self.current.load_state_dict(state_dict["current"])


@dataclass
class _BatchProgress(_Progress):
    """Tracks batch progress.

    These counters are local to a trainer rank. By default, they are not globally synced across all ranks
.

    Args:
        total: Tracks the total batch progress.
        current: Tracks the current batch progress.
        is_last_batch: Whether the batch is the last one. This is useful for iterable datasets.

    """

    is_last_batch: bool = False

    @override
    def reset(self) -> None:
        super().reset()
        self.is_last_batch = False

    @override
    def reset_on_run(self) -> None:
        super().reset_on_run()
        self.is_last_batch = False

    @override
    def load_state_dict(self, state_dict: dict) -> None:
        if state_dict["total"]["completed"] == None:
            state_dict["total"]["completed"] = 0
        super().load_state_dict(state_dict)
        self.is_last_batch = state_dict["is_last_batch"]


@dataclass
class _SchedulerProgress(_Progress):
    """Tracks scheduler progress.

    These counters are local to a trainer rank. By default, they are not globally synced across all ranks
.

    Args:
        total: Tracks the total scheduler progress.
        current: Tracks the current scheduler progress.

    """

    total: _ReadyCompletedTracker = field(default_factory=_ReadyCompletedTracker)
    current: _ReadyCompletedTracker = field(default_factory=_ReadyCompletedTracker)


@dataclass
class _OptimizerProgress(_BaseProgress):
    """Track optimizer progress.

    Args:
        step: Tracks ``optimizer.step`` calls.
        zero_grad: Tracks ``optimizer.zero_grad`` calls.

    """

    step: _Progress = field(default_factory=lambda: _Progress.from_defaults(_ReadyCompletedTracker))
    zero_grad: _Progress = field(default_factory=lambda: _Progress.from_defaults(_StartedTracker))

    @override
    def reset(self) -> None:
        self.step.reset()
        self.zero_grad.reset()

    def reset_on_run(self) -> None:
        self.step.reset_on_run()
        self.zero_grad.reset_on_run()

    def reset_on_restart(self) -> None:
        self.step.reset_on_restart()
        self.zero_grad.reset_on_restart()

    @override
    def load_state_dict(self, state_dict: dict) -> None:
        if state_dict["step"]["total"]["completed"] == None:
            state_dict["step"]["total"]["completed"] = 0
        self.step.load_state_dict(state_dict["step"])
        self.zero_grad.load_state_dict(state_dict["zero_grad"])


@dataclass
class _OptimizationProgress(_BaseProgress):
    """Track optimization progress.

    Args:
        optimizer: Tracks optimizer progress.

    """

    optimizer: _OptimizerProgress = field(default_factory=_OptimizerProgress)

    @property
    def optimizer_steps(self) -> int:
        return self.optimizer.step.total.completed

    @override
    def reset(self) -> None:
        self.optimizer.reset()

    def reset_on_run(self) -> None:
        self.optimizer.reset_on_run()

    def reset_on_restart(self) -> None:
        self.optimizer.reset_on_restart()

    @override
    def load_state_dict(self, state_dict: dict) -> None:
        if state_dict["optimizer"]["step"]["total"]["completed"] == None:
            state_dict["optimizer"]["step"]["total"]["completed"] = 0
        self.optimizer.load_state_dict(state_dict["optimizer"])

2024-08-11 08:16:03.366 | INFO     | __main__:main:608 - Starting compute server...
2024-08-11 08:16:03.366 | INFO     | __main__:main:609 - Current working directory: /home/adarsh/ReProver
2024-08-11 08:16:03.366 | INFO     | __main__:main:617 - ROOT_DIR: /raid/adarsh
2024-08-11 08:16:03.366 | INFO     | __main__:main:618 - DATA_DIR: datasets_test
2024-08-11 08:16:03.366 | INFO     | __main__:main:622 - Configuring LeanDojo...
2024-08-11 08:16:03.370 | INFO     | generate_benchmark_lean4:configure_leandojo:294 - Current working di
rectory: /home/adarsh/ReProver
2024-08-11 08:16:03.370 | INFO     | __main__:main:624 - LeanDojo configured
2024-08-11 08:16:03.370 | INFO     | __main__:main:632 - Unique URLs: {'https://github.com/Adarsh321123/n
ew-version-test.git'}
2024-08-11 08:16:03.370 | INFO     | __main__:main:633 - About to generate datasets...
2024-08-11 08:16:03.370 | INFO     | __main__:generate_dataset:226 - Generating 1 datasets
2024-08-11 08:16:03.370 | INFO     | __main__:generate_dataset:231 - Processing https://github.com/Adarsh
321123/new-version-test.git
2024-08-11 08:16:03.578 | INFO     | __main__:get_compatible_commit:166 - Latest commit: f465306be03ced99
9caa157a85558a6c41b3e3f5
2024-08-11 08:16:03.578 | INFO     | __main__:get_compatible_commit:169 - Creating LeanGitRepo for https:
//github.com/Adarsh321123/new-version-test
2024-08-11 08:16:04.013 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:88 - Querying the com
mit hash for lean4 v4.8.0-rc1
2024-08-11 08:16:04.595 | INFO     | __main__:get_compatible_commit:171 - Getting config for https://gith
ub.com/Adarsh321123/new-version-test.git
2024-08-11 08:16:04.596 | INFO     | __main__:get_compatible_commit:175 - Latest commit compatible for ur
l https://github.com/Adarsh321123/new-version-test.git
2024-08-11 08:16:04.596 | INFO     | __main__:generate_dataset:236 - Found compatible commit f465306be03c
ed999caa157a85558a6c41b3e3f5 for https://github.com/Adarsh321123/new-version-test.git
2024-08-11 08:16:04.596 | INFO     | __main__:generate_dataset:237 - Lean version: v4.8.0-rc1
2024-08-11 08:16:04.596 | INFO     | __main__:generate_dataset:240 - Creating LeanGitRepo for https://git
hub.com/Adarsh321123/new-version-test
2024-08-11 08:16:04.596 | INFO     | __main__:generate_dataset:244 - Generating benchmark at /raid/adarsh
/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5
2024-08-11 08:16:04.596 | INFO     | generate_benchmark_lean4:main:301 - Generating dataset to go into /r
aid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:308 - lean toolchain version: {'conten
t': 'leanprover/lean4:v4.8.0-rc1\n'}
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:310 - lean version v: v4.8.0-rc1
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:311 - is supported: True
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:321 - lean path1 /home/adarsh/.elan/to
olchains/leanprover--lean4---4.8.0-rc1
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:322 - lean path2 /.elan/toolchains/lea
nprover--lean4---4.8.0-rc1
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:323 - lean path3 ~/.elan/toolchains/le
anprover--lean4---4.8.0-rc1
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:327 - Lean toolchain path 2 does not e
xist: /.elan/toolchains/leanprover--lean4---4.8.0-rc1
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:329 - Lean toolchain path 3 does not e
xist: ~/.elan/toolchains/leanprover--lean4---4.8.0-rc1
2024-08-11 08:16:04.597 | INFO     | generate_benchmark_lean4:main:332 - Switched to Lean toolchain at: /
home/adarsh/.elan/toolchains/leanprover--lean4---4.8.0-rc1
2024-08-11 08:16:04.640 | INFO     | generate_benchmark_lean4:main:334 - lean --version: Lean (version 4.
8.0-rc1, x86_64-unknown-linux-gnu, commit dcccfb73cb24, Release)

2024-08-11 08:16:04.640 | INFO     | generate_benchmark_lean4:main:335 - repo: LeanGitRepo(url='https://g
ithub.com/Adarsh321123/new-version-test', commit='f465306be03ced999caa157a85558a6c41b3e3f5')
2024-08-11 08:16:04.640 | INFO     | generate_benchmark_lean4:main:337 - Configuring LeanDojo again...
2024-08-11 08:16:04.645 | INFO     | generate_benchmark_lean4:configure_leandojo:294 - Current working di
rectory: /home/adarsh/ReProver
2024-08-11 08:16:04.645 | INFO     | generate_benchmark_lean4:main:339 - LeanDojo configured
2024-08-11 08:16:04.645 | INFO     | generate_benchmark_lean4:main:342 - Tracing the repo...
2024-08-11 08:16:04.646 | DEBUG    | lean_dojo.data_extraction.trace:get_traced_repo_path:217 - The trace
d repo is available in the cache.
2024-08-11 08:16:04.646 | INFO     | lean_dojo.data_extraction.trace:trace:246 - Loading the traced repo
from /raid/adarsh/.cache/lean_dojo/Adarsh321123-new-version-test-f465306be03ced999caa157a85558a6c41b3e3f5
/new-version-test
2024-08-11 08:16:04.649 | DEBUG    | lean_dojo.utils:execute:110 - git remote get-url origin
2024-08-11 08:16:04.652 | DEBUG    | lean_dojo.utils:execute:110 - git log -n 1
2024-08-11 08:16:04.799 | DEBUG    | lean_dojo.data_extraction.traced_data:load_from_disk:1169 - Loading
5432 traced XML files from /raid/adarsh/.cache/lean_dojo/Adarsh321123-new-version-test-f465306be03ced999c
aa157a85558a6c41b3e3f5/new-version-test with 31 workers
2024-08-11 08:16:06,444 INFO worker.py:1772 -- Started a local Ray instance. View the dashboard at 127.0.
0.1:8267
  3%|█▋                                                               | 146/5432 [00:05<02:56, 29.93it/s]
(raylet) [2024-08-11 08:16:16,335 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66918203392; capacity: 1887507697
664. Object creation will fail if spilling is required.
  6%|███▉                                                             | 328/5432 [00:18<08:51,  9.60it/s]
(raylet) [2024-08-11 08:16:26,346 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66861076480; capacity: 1887507697
664. Object creation will fail if spilling is required.
  8%|█████▎                                                           | 446/5432 [00:29<20:07,  4.13it/s]
(raylet) [2024-08-11 08:16:36,357 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66819829760; capacity: 1887507697
664. Object creation will fail if spilling is required.
 10%|██████▋                                                          | 558/5432 [00:30<01:03, 77.16it/s]
(raylet) [2024-08-11 08:16:46,364 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66784243712; capacity: 1887507697
664. Object creation will fail if spilling is required.
 13%|████████▌                                                        | 715/5432 [00:46<06:04, 12.94it/s]
(raylet) [2024-08-11 08:16:56,374 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66767446016; capacity: 1887507697
664. Object creation will fail if spilling is required.
 15%|█████████▌                                                       | 804/5432 [00:48<01:19, 58.01it/s]
(raylet) [2024-08-11 08:17:06,384 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66731474944; capacity: 1887507697
664. Object creation will fail if spilling is required.
 17%|██████████▉                                                      | 909/5432 [01:10<46:36,  1.62it/s]
(raylet) [2024-08-11 08:17:16,394 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66703200256; capacity: 1887507697
664. Object creation will fail if spilling is required.
 19%|████████████                                                    | 1023/5432 [01:28<50:23,  1.46it/s]
(raylet) [2024-08-11 08:17:26,405 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66665799680; capacity: 1887507697
664. Object creation will fail if spilling is required.
(raylet) [2024-08-11 08:17:36,413 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66639998976; capacity: 1887507697
664. Object creation will fail if spilling is required.
 22%|█████████████▉                                                  | 1178/5432 [01:54<01:36, 43.95it/s]
(raylet) [2024-08-11 08:17:46,424 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66568937472; capacity: 1887507697
664. Object creation will fail if spilling is required.
 22%|█████████████▍                                                | 1180/5432 [01:54<1:32:04,  1.30s/it]
(raylet) [2024-08-11 08:17:56,436 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66526695424; capacity: 1887507697
664. Object creation will fail if spilling is required.
 23%|██████████████▍                                               | 1270/5432 [02:23<1:32:46,  1.34s/it]
(raylet) [2024-08-11 08:18:16,458 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66462072832; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 2x across cluster] (Ray deduplicates lo
gs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ra
y-observability/user-guides/configure-logging.html#log-deduplication for more options.)
 27%|████████████████▊                                             | 1470/5432 [02:58<1:37:57,  1.48s/it]
(raylet) [2024-08-11 08:18:46,493 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66332536832; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 3x across cluster]
 31%|███████████████████▏                                          | 1681/5432 [03:45<3:04:59,  2.96s/it]
(raylet) [2024-08-11 08:19:16,534 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 66202529792; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 3x across cluster]
 37%|██████████████████████▋                                       | 1986/5432 [04:46<4:15:07,  4.44s/it]
(raylet) [2024-08-11 08:20:06,591 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 65948401664; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 5x across cluster]
 42%|██████████████████████████▋                                     | 2263/5432 [04:57<03:16, 16.12it/s]
(raylet) [2024-08-11 08:21:06,661 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 65560621056; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 6x across cluster]
 42%|██████████████████████████                                    | 2281/5432 [06:18<7:41:09,  8.78s/it]
(raylet) [2024-08-11 08:21:16,671 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 65497456640; capacity: 1887507697
664. Object creation will fail if spilling is required.
(raylet) [2024-08-11 08:21:26,683 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 65425522688; capacity: 1887507697
664. Object creation will fail if spilling is required.
 47%|██████████████████████████████                                  | 2551/5432 [06:27<01:14, 38.82it/s]
(raylet) [2024-08-11 08:22:36,781 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 65071775744; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 7x across cluster]
 49%|██████████████████████████████▏                               | 2650/5432 [07:45<3:48:10,  4.92s/it]
(raylet) [2024-08-11 08:22:46,792 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 65018658816; capacity: 1887507697
664. Object creation will fail if spilling is required.
(raylet) [2024-08-11 08:22:56,805 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 64972193792; capacity: 1887507697
664. Object creation will fail if spilling is required.
 58%|████████████████████████████████████▉                           | 3135/5432 [07:57<00:45, 50.25it/s]
(raylet) [2024-08-11 08:24:06,894 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 64682905600; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 7x across cluster]
 59%|████████████████████████████████████▋                         | 3217/5432 [09:25<3:29:42,  5.68s/it]
(raylet) [2024-08-11 08:24:16,906 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 64633643008; capacity: 1887507697
664. Object creation will fail if spilling is required.
(raylet) [2024-08-11 08:24:26,916 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 64597991424; capacity: 1887507697
664. Object creation will fail if spilling is required.
 68%|███████████████████████████████████████████▋                    | 3708/5432 [09:37<00:48, 35.41it/s]
(raylet) [2024-08-11 08:25:47,009 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 64207855616; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 8x across cluster]
 71%|████████████████████████████████████████████▏                 | 3873/5432 [11:08<2:29:34,  5.76s/it]
(raylet) [2024-08-11 08:25:57,020 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 64179019776; capacity: 1887507697
664. Object creation will fail if spilling is required.
(raylet) [2024-08-11 08:26:07,031 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 64146972672; capacity: 1887507697
664. Object creation will fail if spilling is required.
 76%|████████████████████████████████████████████████▊               | 4142/5432 [11:17<00:37, 34.44it/s]
(raylet) [2024-08-11 08:27:27,112 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 63799918592; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 8x across cluster]
 81%|███████████████████████████████████████████████████▉            | 4407/5432 [11:27<00:27, 37.79it/s]
(raylet) [2024-08-11 08:27:37,124 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 63755956224; capacity: 1887507697
664. Object creation will fail if spilling is required.
 83%|███████████████████████████████████████████████████▏          | 4484/5432 [13:29<2:29:18,  9.45s/it]
(raylet) [2024-08-11 08:27:47,137 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 63729209344; capacity: 1887507697
664. Object creation will fail if spilling is required.
 86%|██████████████████████████████████████████████████████▉         | 4665/5432 [13:37<00:29, 25.94it/s]
(raylet) [2024-08-11 08:29:47,277 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 63261863936; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 12x across cluster]
 92%|██████████████████████████████████████████████████████████▊     | 4995/5432 [13:47<00:11, 38.90it/s]
(raylet) [2024-08-11 08:29:57,288 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 63204970496; capacity: 1887507697
664. Object creation will fail if spilling is required.
 99%|███████████████████████████████████████████████████████████████▍| 5380/5432 [13:54<00:00, 57.83it/s]
(raylet) [2024-08-11 08:30:07,297 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 63186149376; capacity: 1887507697
664. Object creation will fail if spilling is required.
100%|████████████████████████████████████████████████████████████████| 5432/5432 [15:56<00:00,  5.68it/s]
(raylet) [2024-08-11 08:31:57,404 E 2882332 2882361] (raylet) file_system_monitor.cc:111: /tmp/ray/sessio
n_2024-08-11_08-16-04_927454_2879522 is over 95% full, available space: 62599471104; capacity: 1887507697
664. Object creation will fail if spilling is required. [repeated 11x across cluster]
2024-08-11 08:32:08.034 | DEBUG    | lean_dojo.data_extraction.lean:get_dependencies:489 - Querying the d
ependencies of LeanGitRepo(url='https://github.com/Adarsh321123/new-version-test', commit='f465306be03ced
999caa157a85558a6c41b3e3f5')
2024-08-11 08:32:09.030 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:88 - Querying the com
mit hash for lean4 v4.8.0-rc2
2024-08-11 08:32:10.331 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:88 - Querying the com
mit hash for lean4 v4.6.0-rc1
2024-08-11 08:32:12.611 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:88 - Querying the com
mit hash for lean4 v4.7.0
2024-08-11 08:32:13.600 | DEBUG    | lean_dojo.data_extraction.lean:url_to_repo:68 - url_to_repo("https:/
/github.com/leanprover-community/import-graph.git") failed. Retrying...
2024-08-11 08:32:14.723 | DEBUG    | lean_dojo.data_extraction.lean:url_to_repo:68 - url_to_repo("https:/
/github.com/leanprover-community/import-graph.git") failed. Retrying...
2024-08-11 08:32:18.001 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:88 - Querying the com
mit hash for lean4 v4.11.0-rc1
2024-08-11 08:32:18.591 | DEBUG    | lean_dojo.data_extraction.lean:get_dependencies:489 - Querying the d
ependencies of LeanGitRepo(url='https://github.com/leanprover-community/mathlib4', commit='0b0394f530ed45
1a7431d78fcf3832effcf080e8')
2024-08-11 08:32:19.245 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:88 - Querying the com
mit hash for lean4 v4.10.0
2024-08-11 08:32:20.498 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:88 - Querying the com
mit hash for lean4 v4.9.0
2024-08-11 08:32:59.785 | DEBUG    | lean_dojo.data_extraction.traced_data:check_sanity:1032 - Checking t
he sanity of TracedRepo(repo=LeanGitRepo(url='https://github.com/Adarsh321123/new-version-test', commit='
f465306be03ced999caa157a85558a6c41b3e3f5'), dependencies={'lean4': LeanGitRepo(url='https://github.com/le
anprover/lean4', commit='daa22187642d4cf6954c39a23eab20d8a8675416'), 'batteries': LeanGitRepo(url='https:
//github.com/leanprover-community/batteries', commit='dc167d260ff7ee9849b436037add06bed15104be'), 'Qq': L
eanGitRepo(url='https://github.com/leanprover-community/quote4', commit='71f54425e6fe0fa75f3aef33a2813a78
98392222'), 'aesop': LeanGitRepo(url='https://github.com/leanprover-community/aesop', commit='0444234b421
6e944d5be2ce42a25d7410c67876f'), 'proofwidgets': LeanGitRepo(url='https://github.com/leanprover-community
/ProofWidgets4', commit='a96aee5245720f588876021b6a0aa73efee49c76'), 'Cli': LeanGitRepo(url='https://gith
ub.com/leanprover/lean4-cli', commit='2cf1030dc2ae6b3632c84a09350b675ef3e347d0'), 'mathlib': LeanGitRepo(
url='https://github.com/leanprover-community/mathlib4', commit='0b0394f530ed451a7431d78fcf3832effcf080e8'
), 'importGraph': LeanGitRepo(url='https://github.com/leanprover-community/import-graph', commit='57bd206
5f1dbea5e9235646fb836c7cea9ab03b6')}, root_dir=PosixPath('/raid/adarsh/.cache/lean_dojo/Adarsh321123-new-
version-test-f465306be03ced999caa157a85558a6c41b3e3f5/new-version-test'))
2024-08-11 08:33:17.369 | INFO     | generate_benchmark_lean4:main:344 - Successfully traced the repo
2024-08-11 08:33:30.989 | INFO     | generate_benchmark_lean4:split_data:132 - 119751 theorems in total
2024-08-11 08:33:30.989 | INFO     | generate_benchmark_lean4:split_data:137 - 119751 theorems in total,
with 2395 for validation and 2395 for testing
2024-08-11 08:33:30.989 | INFO     | generate_benchmark_lean4:split_randomly:80 - Splitting the theorems
randomly
2024-08-11 08:33:31.045 | INFO     | generate_benchmark_lean4:split_by_premise:94 - Splitting the theorem
s by premises
2024-08-11 08:33:43.980 | INFO     | generate_benchmark_lean4:main:352 - Successfully split the data
2024-08-11 08:34:18.741 | INFO     | generate_benchmark_lean4:export_proofs:194 - 114961 theorems and 242
853 tactics saved to /raid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5
/random/train.json
2024-08-11 08:34:20.499 | INFO     | generate_benchmark_lean4:export_proofs:194 - 2395 theorems and 5113
tactics saved to /raid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/ran
dom/val.json
2024-08-11 08:34:21.324 | INFO     | generate_benchmark_lean4:export_proofs:194 - 2395 theorems and 5117
tactics saved to /raid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/ran
dom/test.json
2024-08-11 08:34:56.262 | INFO     | generate_benchmark_lean4:export_proofs:194 - 114961 theorems and 237
983 tactics saved to /raid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5
/novel_premises/train.json
2024-08-11 08:34:58.103 | INFO     | generate_benchmark_lean4:export_proofs:194 - 2395 theorems and 7151
tactics saved to /raid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/nov
el_premises/val.json
2024-08-11 08:34:59.333 | INFO     | generate_benchmark_lean4:export_proofs:194 - 2395 theorems and 7949
tactics saved to /raid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/nov
el_premises/test.json
2024-08-11 08:34:59.352 | INFO     | generate_benchmark_lean4:export_data:270 - Successfully exported the
 proofs
2024-08-11 08:35:47.036 | INFO     | generate_benchmark_lean4:export_premises:218 - 175685 theorems/defin
itions from 5432 files saved to /raid/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558
a6c41b3e3f5/corpus.jsonl
2024-08-11 08:35:47.036 | INFO     | generate_benchmark_lean4:export_data:274 - Successfully exported the
 premises
2024-08-11 08:35:47.037 | INFO     | generate_benchmark_lean4:export_data:282 - Successfully exported the
 metadata
2024-08-11 08:35:47.037 | INFO     | generate_benchmark_lean4:main:354 - Successfully exported the data
2024-08-11 08:35:47.304 | INFO     | __main__:generate_dataset:246 - Finished generating benchmark at /ra
id/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5
2024-08-11 08:35:47.305 | INFO     | __main__:generate_dataset:247 - Merging datasets
2024-08-11 08:35:47.305 | INFO     | __main__:merge_datasets:74 - Merging datasets for random
2024-08-11 08:35:47.305 | INFO     | __main__:merge_datasets:80 - Processing train split
2024-08-11 08:35:47.305 | INFO     | __main__:merge_datasets:86 - Processing new-version-test_f465306be03
ced999caa157a85558a6c41b3e3f5
2024-08-11 08:35:51.465 | INFO     | __main__:merge_datasets:98 - Deleted processed file: /raid/adarsh/da
tasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/random/train.json
2024-08-11 08:36:01.519 | INFO     | __main__:merge_datasets:104 - Finished processing train split
2024-08-11 08:36:01.519 | INFO     | __main__:merge_datasets:80 - Processing val split
2024-08-11 08:36:01.551 | INFO     | __main__:merge_datasets:86 - Processing new-version-test_f465306be03
ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:02.296 | INFO     | __main__:merge_datasets:98 - Deleted processed file: /raid/adarsh/da
tasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/random/val.json
2024-08-11 08:36:02.512 | INFO     | __main__:merge_datasets:104 - Finished processing val split
2024-08-11 08:36:02.513 | INFO     | __main__:merge_datasets:80 - Processing test split
2024-08-11 08:36:02.513 | INFO     | __main__:merge_datasets:86 - Processing new-version-test_f465306be03
ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:02.624 | INFO     | __main__:merge_datasets:98 - Deleted processed file: /raid/adarsh/da
tasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/random/test.json
2024-08-11 08:36:02.846 | INFO     | __main__:merge_datasets:104 - Finished processing test split
2024-08-11 08:36:02.847 | INFO     | __main__:merge_datasets:105 - Finished merging datasets for random
2024-08-11 08:36:02.847 | INFO     | __main__:merge_datasets:74 - Merging datasets for novel_premises
2024-08-11 08:36:02.847 | INFO     | __main__:merge_datasets:80 - Processing train split
2024-08-11 08:36:02.847 | INFO     | __main__:merge_datasets:86 - Processing new-version-test_f465306be03
ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:06.969 | INFO     | __main__:merge_datasets:98 - Deleted processed file: /raid/adarsh/da
tasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/novel_premises/train.json
2024-08-11 08:36:17.036 | INFO     | __main__:merge_datasets:104 - Finished processing train split
2024-08-11 08:36:17.037 | INFO     | __main__:merge_datasets:80 - Processing val split
2024-08-11 08:36:17.077 | INFO     | __main__:merge_datasets:86 - Processing new-version-test_f465306be03
ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:17.739 | INFO     | __main__:merge_datasets:98 - Deleted processed file: /raid/adarsh/da
tasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/novel_premises/val.json
2024-08-11 08:36:18.004 | INFO     | __main__:merge_datasets:104 - Finished processing val split
2024-08-11 08:36:18.004 | INFO     | __main__:merge_datasets:80 - Processing test split
2024-08-11 08:36:18.005 | INFO     | __main__:merge_datasets:86 - Processing new-version-test_f465306be03
ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:18.176 | INFO     | __main__:merge_datasets:98 - Deleted processed file: /raid/adarsh/da
tasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/novel_premises/test.json
2024-08-11 08:36:18.516 | INFO     | __main__:merge_datasets:104 - Finished processing test split
2024-08-11 08:36:18.516 | INFO     | __main__:merge_datasets:105 - Finished merging datasets for novel_pr
emises
2024-08-11 08:36:18.517 | INFO     | __main__:merge_datasets:107 - Merging corpus
2024-08-11 08:36:18.517 | INFO     | __main__:merge_datasets:112 - Processing new-version-test_f465306be0
3ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:19.021 | INFO     | __main__:merge_datasets:124 - Deleted processed corpus file: /raid/a
darsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/corpus.jsonl
2024-08-11 08:36:19.125 | INFO     | __main__:merge_datasets:130 - Finished merging corpus
2024-08-11 08:36:19.126 | INFO     | __main__:merge_datasets:132 - Adding metadata
2024-08-11 08:36:19.126 | INFO     | __main__:merge_datasets:137 - Checking for metadata in new-version-t
est_f465306be03ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:19.127 | INFO     | __main__:merge_datasets:145 - Deleted processed metadata file: /raid
/adarsh/datasets_test/new-version-test_f465306be03ced999caa157a85558a6c41b3e3f5/metadata.json
2024-08-11 08:36:19.127 | INFO     | __main__:merge_datasets:150 - Finished adding metadata
2024-08-11 08:36:19.127 | INFO     | __main__:merge_datasets:154 - Deleting individual datasets
2024-08-11 08:36:19.127 | INFO     | __main__:merge_datasets:158 - Deleting dataset: new-version-test_f46
5306be03ced999caa157a85558a6c41b3e3f5
2024-08-11 08:36:19.170 | INFO     | __main__:generate_dataset:249 - Finished merging datasets
2024-08-11 08:36:19.273 | INFO     | __main__:main:639 - Latest PL checkpoint found: AK123321/pl-leancopi
lot-2
2024-08-11 08:36:19.486 | INFO     | __main__:download_pl_checkpoint:274 - Checkpoint downloaded to: /hom
e/adarsh/.cache/huggingface/hub/models--AK123321--pl-leancopilot-2/snapshots/d4955ed1972ad84c03dce9189162
d03912f2d86f/model.ckpt
2024-08-11 08:36:19.486 | INFO     | __main__:main:642 - Checkpoint path: /home/adarsh/.cache/huggingface
/hub/models--AK123321--pl-leancopilot-2/snapshots/d4955ed1972ad84c03dce9189162d03912f2d86f/model.ckpt
2024-08-11 08:36:19.486 | INFO     | __main__:train:464 - Training model with checkpoint: /home/adarsh/.c
ache/huggingface/hub/models--AK123321--pl-leancopilot-2/snapshots/d4955ed1972ad84c03dce9189162d03912f2d86
f/model.ckpt
Seed set to 3407
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.4.0. To apply the upgrade to yo
ur files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../.cache/huggingface
/hub/models--AK123321--pl-leancopilot-2/snapshots/d4955ed1972ad84c03dce9189162d03912f2d86f/model.ckpt`
2024-08-11 08:36:45.889 | INFO     | __main__:train:486 - Loaded premise retriever at /home/adarsh/.cache
/huggingface/hub/models--AK123321--pl-leancopilot-2/snapshots/d4955ed1972ad84c03dce9189162d03912f2d86f/mo
del.ckpt
2024-08-11 08:36:45.890 | INFO     | __main__:train:490 - Data path: /raid/adarsh/datasets_test/merged/ra
ndom
/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/transformers/tokenization
_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True`
by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by def
ault. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-08-11 08:36:45.996 | INFO     | common:__init__:200 - Building the corpus from /raid/adarsh/datasets
_test/merged/corpus.jsonl
2024-08-11 08:37:18.745 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache
/raid/adarsh/datasets_test/merged/random/cache_train/cached_data.pkl
Training dataset size: 353052
2024-08-11 08:37:18.801 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache
/raid/adarsh/datasets_test/merged/random/cache_val/cached_data.pkl
Validation dataset size: 5403
2024-08-11 08:37:18.849 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache
/raid/adarsh/datasets_test/merged/random/cache_pred/cached_data.pkl
Testing dataset size: 5321
2024-08-11 08:37:18.850 | INFO     | __main__:train:523 - Training dataset size after load: 353052
2024-08-11 08:37:18.851 | INFO     | __main__:train:524 - Validation dataset size after load: 5403
2024-08-11 08:37:18.851 | INFO     | __main__:train:525 - Testing dataset size after load: 5321
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
2024-08-11 08:37:18.862 | INFO     | __main__:train:543 - Starting progressive training...
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

2024-08-11 08:37:33.036 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache
/raid/adarsh/datasets_test/merged/random/cache_train/cached_data.pkl
Training dataset size: 353052
2024-08-11 08:37:33.582 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache
/raid/adarsh/datasets_test/merged/random/cache_val/cached_data.pkl
Validation dataset size: 5403
2024-08-11 08:37:33.675 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache
/raid/adarsh/datasets_test/merged/random/cache_pred/cached_data.pkl
Testing dataset size: 5321
/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning/callbac
ks/model_checkpoint.py:654: Checkpoint directory /raid/adarsh/checkpoints_test exists and is not empty.
Restoring states from the checkpoint path at /home/adarsh/.cache/huggingface/hub/models--AK123321--pl-lea
ncopilot-2/snapshots/d4955ed1972ad84c03dce9189162d03912f2d86f/model.ckpt
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.4.0. To apply the upgrade to yo
ur files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../.cache/huggingface
/hub/models--AK123321--pl-leancopilot-2/snapshots/d4955ed1972ad84c03dce9189162d03912f2d86f/model.ckpt`
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
2024-08-11 08:37:37.678 | INFO     | common:get_optimizers:433 - Optimizing with GaLoreAdamW
/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/galore_torch/adamw.py:48:
 FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use t
he PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this
 warning
  warnings.warn(

  | Name    | Type           | Params | Mode
---------------------------------------------------
0 | encoder | T5EncoderModel | 217 M  | train
---------------------------------------------------
217 M     Trainable params
0         Non-trainable params
217 M     Total params
870.630   Total estimated model params size (MB)
235       Modules in train mode
0         Modules in eval mode
Restored all states from the checkpoint at /home/adarsh/.cache/huggingface/hub/models--AK123321--pl-leanc
opilot-2/snapshots/d4955ed1972ad84c03dce9189162d03912f2d86f/model.ckpt
Epoch 0:   0%|                                                                | 0/176526 [00:00<?, ?it/s]
2024-08-11 08:39:00.013 | INFO     | __main__:main:651 - An error occurred: 'correct_bias'
Traceback (most recent call last):
  File "/home/adarsh/ReProver/compute_server.py", line 645, in main
    train(model_checkpoint_path, merged_data_path, next_suffix)
  File "/home/adarsh/ReProver/compute_server.py", line 545, in train
    trainer.fit(model, datamodule=data_module, ckpt_path=model_checkpoint_path)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/loops/training_epoch_loop.py", line 250, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/loops/optimization/automatic.py", line 190, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/loops/optimization/automatic.py", line 268, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/core/module.py", line 1306, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/core/optimizer.py", line 153, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/strategies/ddp.py", line 270, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/strategies/strategy.py", line 238, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/plugins/precision/amp.py", line 75, in optimizer_step
    return super().optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/pytorch_lightning
/plugins/precision/precision.py", line 122, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/torch/optim/lr_sc
heduler.py", line 130, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/torch/optim/optim
izer.py", line 484, in wrapper
    out = func(*args, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/torch/utils/_cont
extlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/adarsh/miniconda3/envs/ReProverComputeServer/lib/python3.10/site-packages/galore_torch/adam
w.py", line 117, in step
    if group["correct_bias"]:  # No bias correction for Bert
KeyError: 'correct_bias'
Epoch 0:   0%|                                                                | 0/176526 [03:22<?, ?it/s]
(base) adarsh@tensorlab-DGX-Station-A100-920-23487-2531-000:~/ReProver$
