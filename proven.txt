(base) yingzi_ma@cais-login-0:~/lean_project/ReProver$ srun --partition=compute --gpus=4 --nodes=1 --time=2-00:00:00 --pty /bin/bash
srun: job 25118 queued and waiting for resources
srun: job 25118 has been allocated resources
(base) yingzi_ma@compute-permanent-node-345:~/lean_project/ReProver$ bash run_code.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Did not find any active Ray processes.
[2024-09-08 19:08:39,961] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-08 19:08:51.085 | INFO     | __main__:main:1195 - Running retrieval baseline
2024-09-08 19:08:51.085 | INFO     | __main__:main:1198 - Configuring LeanDojo...
2024-09-08 19:08:51.088 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-08 19:08:51.088 | INFO     | __main__:main:1200 - LeanDojo configured
2024-09-08 19:08:51.088 | INFO     | __main__:main:1205 - Starting the main process
2024-09-08 19:08:51.088 | INFO     | __main__:main:1213 - Loading database from /data/yingzi_ma/lean_project/dynamic_database_retrieval_single_repo_no_ewc_pfr.json
2024-09-08 19:09:05.259 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:09:05.259 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:09:10.365 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-08 19:09:10.365 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-08 19:09:10.578 | INFO     | __main__:main:1215 - Loaded database from /data/yingzi_ma/lean_project/dynamic_database_retrieval_single_repo_no_ewc_pfr.json
2024-09-08 19:09:10.579 | INFO     | __main__:main:1222 - Found 15 repositories
2024-09-08 19:09:10.579 | INFO     | __main__:main:1313 - Starting without curriculum learning
2024-09-08 19:09:10.804 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.11.0-rc2
2024-09-08 19:09:26.242 | INFO     | __main__:main:1342 - Finding compatible repositories...
2024-09-08 19:09:26.242 | INFO     | __main__:main:1346 - Finished finding compatible repositories
2024-09-08 19:09:26.451 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-08 19:09:42.142 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-08 19:09:57.657 | INFO     | __main__:main:1364 - length of lean_git_repos: 2
2024-09-08 19:09:57.657 | INFO     | __main__:main:1365 - i: 0
2024-09-08 19:09:57.657 | INFO     | __main__:main:1371 - Main process
2024-09-08 19:09:57.657 | INFO     | __main__:main:1372 - Using lambda = 0.0
2024-09-08 19:09:57.657 | INFO     | __main__:main:1373 - Processing https://github.com/avigad/mathematics_in_lean_source
2024-09-08 19:09:57.657 | INFO     | __main__:main:1396 - Adding repo to repos_for_merged_dataset
2024-09-08 19:09:57.657 | INFO     | __main__:main:1407 - All GPUs
2024-09-08 19:09:57.657 | INFO     | __main__:main:1640 - Starting the prover
2024-09-08 19:09:57.657 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-08 19:09:57.657 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-08 19:09:57.658 | INFO     | prover.proof_search:__init__:427 - Using RAG
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly.
It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `
weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.se
rialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../kaiyuy_leandojo-lean4-retriever-tacgen-byt5-small/mo
del_lightning.ckpt`
2024-09-08 19:09:59.206 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma/lean_project/checkpoints/mathlib4_29dcec074de168ac2bf835a77ef68bbe069194c5.ckpt
2024-09-08 19:09:59.206 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma/lean_project/checkpoints/mathlib4_29dcec074de168ac2bf835a77ef68bbe069194c5.ckpt
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../checkpoints/mathlib4_29dcec074de168ac2bf835a77ef68bb
e069194c5.ckpt`
2024-09-08 19:10:02.445 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Found keys that are in the model state dict but not in the checkpoint: ['retriever.encoder.shared.weight', 'retriever.encoder.encoder.em
bed_tokens.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.v.weight', 'retriever.encoder.e
ncoder.block.0.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'retriever.encoder.encoder.block.0.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.0.layer.1.
DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.0.layer.1.layer_norm.weight', 'retriever
.encoder.encoder.block.1.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAtt
ention.o.weight', 'retriever.encoder.encoder.block.1.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.
encoder.block.1.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.1.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.k.wei
ght', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.2.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.2.laye
r.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.2.layer.1.layer_norm.weight', 'retri
ever.encoder.encoder.block.3.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.3.layer.0.Sel
fAttention.o.weight', 'retriever.encoder.encoder.block.3.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'retriever.enco
der.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.3.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.k
.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.4.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.4.
layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.4.layer.1.layer_norm.weight', 'r
etriever.encoder.encoder.block.5.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.5.layer.0
.SelfAttention.o.weight', 'retriever.encoder.encoder.block.5.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 'retriever.
encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.5.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttenti
on.k.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.6.layer.0.layer_norm.weight', 'retriever.encoder.encoder.bloc
k.6.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.6.layer.1.layer_norm.weight'
, 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.7.lay
er.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.7.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'retrie
ver.encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.7.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAtt
ention.k.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.8.layer.0.layer_norm.weight', 'retriever.encoder.encoder.
block.8.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.8.layer.1.layer_norm.wei
ght', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.9
.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.9.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 're
triever.encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.9.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.10.layer.0.S
elfAttention.k.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.10.layer.0.layer_norm.weight', 'retriever.encoder
.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.10.layer.1.l
ayer_norm.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.v.weight', 'retriever.encoder
.encoder.block.11.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.11.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDen
se.wi_1.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.11.layer.1.layer_norm.weight', 'retriever.encoder.encoder.final_layer_norm.weight']
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['pytorch-lightning_version', 'global_step', 'epoch', 'state_dict
', 'callbacks', 'loops', 'legacy_pytorch-lightning_version', 'hyper_parameters']
2024-09-08 19:10:02.963 | INFO     | prover.proof_search:__init__:451 - Loaded model from /data/yingzi_ma/lean_project/kaiyuy_leandojo-lean4-retriever-tacgen-byt5-small/model_lightning.ckpt
2024-09-08 19:10:02.964 | INFO     | prover.proof_search:__init__:452 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-08 19:10:02.965 | INFO     | prover.proof_search:__init__:455 - Loading indexed corpus from /data/yingzi_ma/lean_project/datasets_retrieval_single_repo_no_ewc_pfr/merged_with_new_mathematics_in_lean_source_5297e0fb051367c48c0a084411853a
576389ecf5/corpus.jsonl
2024-09-08 19:10:02.965 | INFO     | common:__init__:208 - Building the corpus from /data/yingzi_ma/lean_project/datasets_retrieval_single_repo_no_ewc_pfr/merged_with_new_mathematics_in_lean_source_5297e0fb051367c48c0a084411853a576389ecf5/corpu
s.jsonl
2024-09-08 19:10:09.817 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: True
2024-09-08 19:10:09.817 | INFO     | prover.proof_search:__init__:457 - Loaded indexed corpus from /data/yingzi_ma/lean_project/datasets_retrieval_single_repo_no_ewc_pfr/merged_with_new_mathematics_in_lean_source_5297e0fb051367c48c0a084411853a5
76389ecf5/corpus.jsonl
2024-09-08 19:10:09.817 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-08 19:10:13,126 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8265
(pid=1547057) [2024-09-08 19:10:49,859] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
(ProverActor pid=1547057) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle
 module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the
 default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by th
e user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimen
tal feature.
(ProverActor pid=1547057)   return torch.load(io.BytesIO(b))
(pid=1547194) [2024-09-08 19:10:58,795] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
(ProverActor pid=1547194) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle
 module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the
 default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by th
e user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimen
tal feature.
(ProverActor pid=1547194)   return torch.load(io.BytesIO(b))
2024-09-08 19:11:06.852 | INFO     | __main__:prove_sorry_theorems:814 - Found 29 sorry theorems to prove
Processing theorems from avigad/mathematics_in_lean_source:   0%|                                                                                                                                                       | 0/29 [00:00<?, ?theorem/s]
2024-09-08 19:11:06.854 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for MyRing.neg_neg
2024-09-08 19:11:06.854 | INFO     | __main__:prove_sorry_theorems:838 - Position: (305, 1)
2024-09-08 19:11:06.854 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for Cantor
2024-09-08 19:11:06.854 | INFO     | __main__:prove_sorry_theorems:838 - Position: (673, 1)
2024-09-08 19:11:06.854 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for MyGroup.mul_right_inv
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:838 - Position: (468, 1)
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for C03S06.aux
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:838 - Position: (275, 1)
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for cauchySeq_of_le_geometric_two'
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:838 - Position: (423, 1)
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for C03S05.MyAbs.lt_abs
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:838 - Position: (193, 1)
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for MyRing.zero_mul
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:838 - Position: (279, 1)
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for C03S01.my_lemma3
2024-09-08 19:11:06.855 | INFO     | __main__:prove_sorry_theorems:838 - Position: (99, 1)
2024-09-08 19:11:06.856 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for MyRing.two_mul
2024-09-08 19:11:06.856 | INFO     | __main__:prove_sorry_theorems:838 - Position: (407, 1)
2024-09-08 19:11:06.856 | INFO     | __main__:prove_sorry_theorems:837 - Searching for proof for C03S05.MyAbs.abs_add
2024-09-08 19:11:06.856 | INFO     | __main__:prove_sorry_theorems:838 - Position: (163, 1)
2024-09-08 19:11:06.856 | INFO     | prover.proof_search:search_unordered:514 - Distributed
(ProverActor pid=1547057) 2024-09-08 19:11:06.864 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C03S06.aux')
(pid=1547359) [2024-09-08 19:11:08,688] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
(ProverActor pid=1547194) 2024-09-08 19:11:12.933 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyGroup.mul_right_inv')
(ProverActor pid=1547359) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle
 module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the
 default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by th
e user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimen
tal feature.
(ProverActor pid=1547359)   return torch.load(io.BytesIO(b))
(pid=1547548) [2024-09-08 19:11:17,029] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
(ProverActor pid=1547359) 2024-09-08 19:11:20.941 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C04_Sets_and_Functions/S02_Functions.lean'), full_name='Cantor')
(ProverActor pid=1547548) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle
 module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the
 default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by th
e user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimen
tal feature.
(ProverActor pid=1547548)   return torch.load(io.BytesIO(b))
(ProverActor pid=1547548) 2024-09-08 19:11:30.594 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyRing.neg_neg')
(ProverActor pid=1547548) 2024-09-08 19:12:37.306 | INFO     | prover.proof_search:_best_first_search:171 - Found a proof!
(ProverActor pid=1547548) 2024-09-08 19:12:43.516 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyRing.neg_neg'), status=<Status.PROVED: 'Proved'>, proof=['simp [id]'], actor_time=1.4401665900368243, environment_time=0.014269757
084548473, total_time=2.454749113996513, num_total_nodes=3, num_searched_nodes=1)
(ProverActor pid=1547548) 2024-09-08 19:12:43.520 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C09_Topology/S02_Metric_Spaces.lean'), full_name="cauchySeq_of_le_geometric_two'")
(ProverActor pid=1547194) 2024-09-08 19:12:38.257 | INFO     | prover.proof_search:_best_first_search:171 - Found a proof!
(ProverActor pid=1547194) 2024-09-08 19:12:44.386 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyGroup.mul_right_inv'), status=<Status.PROVED: 'Proved'>, proof=['simp [id]'], actor_time=1.6798181449994445, environment_time=0.00
8636530954390764, total_time=2.6887507539941, num_total_nodes=2, num_searched_nodes=1)
(ProverActor pid=1547194) 2024-09-08 19:12:44.390 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.lt_abs')
(ProverActor pid=1547057) 2024-09-08 19:12:45.640 | INFO     | prover.proof_search:_best_first_search:163 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1547057) 2024-09-08 19:12:52.286 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C03_Logic/S06_Sequences_and_Convergence.lean'), full_name='C03S06.aux'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=7.379448315245099, environment_time=2.574111058493145, total_time=10.96099356794729
8, num_total_nodes=168, num_searched_nodes=5)
(ProverActor pid=1547057) 2024-09-08 19:12:52.290 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyRing.zero_mul')
(ProverActor pid=1547359) 2024-09-08 19:12:47.592 | INFO     | prover.proof_search:_best_first_search:163 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1547359) 2024-09-08 19:12:53.451 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C04_Sets_and_Functions/S02_Functions.lean'), full_name='Cantor'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=7.177774962969124, environment_time=2.1924594892188907, total_time=10.378691709949635, num
_total_nodes=213, num_searched_nodes=6)
(ProverActor pid=1547359) 2024-09-08 19:12:53.455 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C03_Logic/S01_Implication_and_the_Universal_Quantifier.lean'), full_name='C03S01.my_lemma3')
(ProverActor pid=1547194) 2024-09-08 19:13:34.747 | INFO     | prover.proof_search:_best_first_search:149 - 1017122.44660519
(ProverActor pid=1547194) 2024-09-08 19:13:34.747 | INFO     | prover.proof_search:_best_first_search:150 - 1017112.449137122
(ProverActor pid=1547194) 2024-09-08 19:13:34.748 | INFO     | prover.proof_search:_best_first_search:151 - 9.998177186935209
(ProverActor pid=1547194) 2024-09-08 19:13:34.748 | INFO     | prover.proof_search:_best_first_search:152 - 10
(ProverActor pid=1547194) 2024-09-08 19:13:34.748 | INFO     | prover.proof_search:_best_first_search:163 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1547057) 2024-09-08 19:13:35.113 | INFO     | prover.proof_search:_best_first_search:171 - Found a proof!
(ProverActor pid=1547194) 2024-09-08 19:13:41.819 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.lt_abs'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=8.631539542227983, environment_time=1.35176762053743, total_time=10.998511204961687, num
_total_nodes=222, num_searched_nodes=4)
(ProverActor pid=1547194) 2024-09-08 19:13:41.823 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyRing.two_mul')
(ProverActor pid=1547548) 2024-09-08 19:13:35.152 | INFO     | prover.proof_search:_best_first_search:163 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1547057) 2024-09-08 19:13:42.086 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyRing.zero_mul'), status=<Status.PROVED: 'Proved'>, proof=['simp [id]'], actor_time=1.4077017310773954, environment_time=0.01339748
3970038593, total_time=2.4213610120350495, num_total_nodes=2, num_searched_nodes=1)
(ProverActor pid=1547057) 2024-09-08 19:13:42.090 | INFO     | prover.proof_search:search:81 - Proving Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a576389ecf5'), file
_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.abs_add')
(ProverActor pid=1547548) 2024-09-08 19:13:42.091 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C09_Topology/S02_Metric_Spaces.lean'), full_name="cauchySeq_of_le_geometric_two'"), status=<Status.OPEN: 'Open'>, proof=None, actor_time=7.672700713970698, environment_time=1.7352388030849397, total_time=10.41
2817714037374, num_total_nodes=146, num_searched_nodes=3)
(ProverActor pid=1547359) 2024-09-08 19:13:44.116 | INFO     | prover.proof_search:_best_first_search:163 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1547057) 2024-09-08 19:14:30.486 | INFO     | prover.proof_search:_best_first_search:149 - 1017178.185065754
(ProverActor pid=1547057) 2024-09-08 19:14:30.486 | INFO     | prover.proof_search:_best_first_search:150 - 1017168.187512939
(ProverActor pid=1547057) 2024-09-08 19:14:30.486 | INFO     | prover.proof_search:_best_first_search:151 - 9.997906033997424
(ProverActor pid=1547057) 2024-09-08 19:14:30.486 | INFO     | prover.proof_search:_best_first_search:152 - 10
(ProverActor pid=1547057) 2024-09-08 19:14:30.486 | INFO     | prover.proof_search:_best_first_search:163 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1547194) 2024-09-08 19:14:30.884 | INFO     | prover.proof_search:_best_first_search:163 - Hit the resource limit (timeout or max_expansions).
(ProverActor pid=1547359) 2024-09-08 19:14:37.867 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C03_Logic/S01_Implication_and_the_Universal_Quantifier.lean'), full_name='C03S01.my_lemma3'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=2.7926970900734887, environment_time=7.193294775788672, total_
time=10.989225883036852, num_total_nodes=92, num_searched_nodes=2)
2024-09-08 19:14:40.791 | INFO     | __main__:process_theorem_batch:750 - Proof found for MyRing.neg_neg
(ProverActor pid=1547194) 2024-09-08 19:14:40.789 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C02_Basics/S02_Proving_Identities_in_Algebraic_Structures.lean'), full_name='MyRing.two_mul'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=6.5352691690204665, environment_time=2.4753583077108487, tota
l_time=10.016892412910238, num_total_nodes=130, num_searched_nodes=5)
2024-09-08 19:14:40.802 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:14:40.802 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:14:40.802 | INFO     | __main__:process_theorem_batch:762 - Updated theorem MyRing.neg_neg in the database
2024-09-08 19:14:40.802 | INFO     | __main__:process_theorem_batch:750 - Proof found for MyGroup.mul_right_inv
2024-09-08 19:14:40.806 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:14:40.806 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:14:40.806 | INFO     | __main__:process_theorem_batch:762 - Updated theorem MyGroup.mul_right_inv in the database
2024-09-08 19:14:40.806 | INFO     | __main__:process_theorem_batch:764 - No proof found for C03S06.aux
2024-09-08 19:14:40.806 | INFO     | __main__:process_theorem_batch:764 - No proof found for Cantor
2024-09-08 19:14:40.806 | INFO     | __main__:process_theorem_batch:764 - No proof found for C03S05.MyAbs.lt_abs
2024-09-08 19:14:40.806 | INFO     | __main__:process_theorem_batch:750 - Proof found for MyRing.zero_mul
2024-09-08 19:14:40.811 | INFO     | dynamic_database:update_repository:614 - Attempting to update repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:14:40.811 | INFO     | dynamic_database:update_repository:618 - Updated repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-08 19:14:40.811 | INFO     | __main__:process_theorem_batch:762 - Updated theorem MyRing.zero_mul in the database
2024-09-08 19:14:40.811 | INFO     | __main__:process_theorem_batch:764 - No proof found for cauchySeq_of_le_geometric_two'
2024-09-08 19:14:40.812 | INFO     | __main__:process_theorem_batch:764 - No proof found for C03S01.my_lemma3
2024-09-08 19:14:40.812 | INFO     | __main__:process_theorem_batch:764 - No proof found for C03S05.MyAbs.abs_add
2024-09-08 19:14:40.812 | INFO     | __main__:process_theorem_batch:764 - No proof found for MyRing.two_mul
Processing theorems from avigad/mathematics_in_lean_source:  31%|████████████████████████████████████████████▍                                                                                                  | 9/29 [05:03<11:15, 33.77s/theorem]
2024-09-08 19:16:10.779 | INFO     | __main__:save_progress:769 - Saving encountered theorems...
2024-09-08 19:16:10.784 | INFO     | __main__:prove_sorry_theorems:867 - Finished attempting to prove sorry theorems
2024-09-08 19:17:26.630 | INFO     | __main__:main:1674 - Finished searching for proofs of sorry theorems
2024-09-08 19:17:26.630 | INFO     | __main__:main:1694 - current epoch: 1
2024-09-08 19:17:26.630 | INFO     | __main__:main:1364 - length of lean_git_repos: 2
2024-09-08 19:17:26.630 | INFO     | __main__:main:1365 - i: 1
2024-09-08 19:17:26.630 | INFO     | __main__:main:1371 - Main process
2024-09-08 19:17:26.630 | INFO     | __main__:main:1372 - Using lambda = 0.0
2024-09-08 19:17:26.630 | INFO     | __main__:main:1373 - Processing https://github.com/teorth/pfr
2024-09-08 19:17:26.630 | INFO     | __main__:main:1396 - Adding repo to repos_for_merged_dataset
2024-09-08 19:17:26.630 | INFO     | __main__:main:1407 - All GPUs
2024-09-08 19:17:26.630 | INFO     | __main__:main:1640 - Starting the prover
2024-09-08 19:17:26.631 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-08 19:17:26.631 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-08 19:17:26.631 | INFO     | prover.proof_search:__init__:427 - Using RAG
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly.
It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `
weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.se
rialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../kaiyuy_leandojo-lean4-retriever-tacgen-byt5-small/mo
del_lightning.ckpt`
2024-09-08 19:17:26.824 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma/lean_project/checkpoints/mathlib4_29dcec074de168ac2bf835a77ef68bbe069194c5.ckpt
2024-09-08 19:17:26.824 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma/lean_project/checkpoints/mathlib4_29dcec074de168ac2bf835a77ef68bbe069194c5.ckpt
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../checkpoints/mathlib4_29dcec074de168ac2bf835a77ef68bb
e069194c5.ckpt`
2024-09-08 19:17:28.333 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Found keys that are in the model state dict but not in the checkpoint: ['retriever.encoder.shared.weight', 'retriever.encoder.encoder.em
bed_tokens.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.v.weight', 'retriever.encoder.e
ncoder.block.0.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'retriever.encoder.encoder.block.0.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.0.layer.1.
DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.0.layer.1.layer_norm.weight', 'retriever
.encoder.encoder.block.1.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAtt
ention.o.weight', 'retriever.encoder.encoder.block.1.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.
encoder.block.1.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.1.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.k.wei
ght', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.2.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.2.laye
r.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.2.layer.1.layer_norm.weight', 'retri
ever.encoder.encoder.block.3.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.3.layer.0.Sel
fAttention.o.weight', 'retriever.encoder.encoder.block.3.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'retriever.enco
der.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.3.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.k
.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.4.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.4.
layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.4.layer.1.layer_norm.weight', 'r
etriever.encoder.encoder.block.5.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.5.layer.0
.SelfAttention.o.weight', 'retriever.encoder.encoder.block.5.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 'retriever.
encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.5.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttenti
on.k.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.6.layer.0.layer_norm.weight', 'retriever.encoder.encoder.bloc
k.6.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.6.layer.1.layer_norm.weight'
, 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.7.lay
er.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.7.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'retrie
ver.encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.7.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAtt
ention.k.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.8.layer.0.layer_norm.weight', 'retriever.encoder.encoder.
block.8.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.8.layer.1.layer_norm.wei
ght', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.9
.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.9.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 're
triever.encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.9.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.10.layer.0.S
elfAttention.k.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.10.layer.0.layer_norm.weight', 'retriever.encoder
.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.10.layer.1.l
ayer_norm.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.v.weight', 'retriever.encoder
.encoder.block.11.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.11.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDen
se.wi_1.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.11.layer.1.layer_norm.weight', 'retriever.encoder.encoder.final_layer_norm.weight']
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['pytorch-lightning_version', 'global_step', 'epoch', 'state_dict
', 'callbacks', 'loops', 'legacy_pytorch-lightning_version', 'hyper_parameters']
2024-09-08 19:17:28.861 | INFO     | prover.proof_search:__init__:451 - Loaded model from /data/yingzi_ma/lean_project/kaiyuy_leandojo-lean4-retriever-tacgen-byt5-small/model_lightning.ckpt
2024-09-08 19:17:28.862 | INFO     | prover.proof_search:__init__:452 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-08 19:17:28.862 | INFO     | prover.proof_search:__init__:455 - Loading indexed corpus from /data/yingzi_ma/lean_project/datasets_retrieval_single_repo_no_ewc_pfr/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687/corpus.jsonl
2024-09-08 19:17:28.862 | INFO     | common:__init__:208 - Building the corpus from /data/yingzi_ma/lean_project/datasets_retrieval_single_repo_no_ewc_pfr/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687/corpus.jsonl
2024-09-08 19:17:35.243 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: True
2024-09-08 19:17:35.244 | INFO     | prover.proof_search:__init__:457 - Loaded indexed corpus from /data/yingzi_ma/lean_project/datasets_retrieval_single_repo_no_ewc_pfr/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687/corpus.jsonl
2024-09-08 19:17:35.244 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
(autoscaler +9m23s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.
(autoscaler +9m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to thi
s Ray cluster.
2024-09-08 19:18:12.000 | INFO     | __main__:prove_sorry_theorems:814 - Found 37 sorry theorems to prove
Processing theorems from teorth/pfr:   0%|                                                                                                                                                                              | 0/37 [00:00<?, ?theorem/s]
2024-09-08 19:18:12.001 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multiDist_indep
2024-09-08 19:18:12.001 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condMultiDist_eq
2024-09-08 19:18:12.001 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: iter_multiDist_chainRule
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_minus_le
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: phi_min_exists
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_of_translate
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_sum_le
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multiDist_nonneg
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: I_one_le
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: dist_add_dist_eq
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: rho_of_translate
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: rho_continuous
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multiDist_chainRule
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multidist_eq_zero
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: cond_multiDist_chainRule
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: rho_plus_of_sum
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_of_sum_le
2024-09-08 19:18:12.002 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multidist_ruzsa_III
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: rho_of_sum_le
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_plus_le
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: dist_le_of_sum_zero
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: iter_multiDist_chainRule'
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: rho_of_subgroup
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: cor_multiDist_chainRule
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multidist_ruzsa_I
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: dist_of_min_eq_zero
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: I_two_le
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_sum_le'
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_of_injective
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multidist_ruzsa_IV
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multiTau_continuous
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: ent_of_sum_le_ent_of_sum
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: condRho_le
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multiTau_min_exists
2024-09-08 19:18:12.003 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: rho_minus_of_sum
2024-09-08 19:18:12.004 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: multidist_ruzsa_II
2024-09-08 19:18:12.004 | INFO     | __main__:prove_sorry_theorems:827 - Skipping already encountered theorem: rho_of_sum
Processing theorems from teorth/pfr: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:00<00:00, 14820.86theorem/s]
2024-09-08 19:18:12.004 | INFO     | __main__:save_progress:769 - Saving encountered theorems...
2024-09-08 19:18:12.006 | INFO     | __main__:prove_sorry_theorems:867 - Finished attempting to prove sorry theorems
(pid=1549688) [2024-09-08 19:18:20,322] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
(ProverActor pid=1549688) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle
 module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the
 default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by th
e user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimen
tal feature.
(ProverActor pid=1549688)   return torch.load(io.BytesIO(b))
(ProverActor pid=1547057) 2024-09-08 19:14:40.567 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/avigad/mathematics_in_lean_source', commit='5297e0fb051367c48c0a084411853a5763
89ecf5'), file_path=PosixPath('MIL/C03_Logic/S05_Disjunction.lean'), full_name='C03S05.MyAbs.abs_add'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=5.410588116967119, environment_time=3.6521942077670246, total_time=10.998074359027669,
num_total_nodes=145, num_searched_nodes=3)
^Z
[1]+  Stopped                 bash run_code.sh
(base) yingzi_ma@compute-permanent-node-345:~/lean_project/ReProver$
