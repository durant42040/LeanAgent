[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank2]:     return optimizer.step(closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank2]:     ret = func(self, *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank2]:     loss = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank2]:     closure_result = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank2]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank2]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank2]:     out = method(*_args, **_kwargs)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 206, in training_step
[rank2]:     custom_barrier(timeout=timedelta(seconds=5))
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 191, in custom_barrier
[rank2]:     raise TimeoutError("Did not receive confirmation from rank 0 within {timeout} seconds")
[rank2]: TimeoutError: Did not receive confirmation from rank 0 within {timeout} seconds
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 255, in <module>
[rank3]:     main(args)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 247, in main
[rank3]:     trainer.fit(model, train_loader)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank3]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:     return optimizer.step(closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank3]:     ret = func(self, *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank3]:     loss = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank3]:     closure_result = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank3]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank3]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank3]:     out = method(*_args, **_kwargs)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 206, in training_step
[rank3]:     custom_barrier(timeout=timedelta(seconds=5))
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 191, in custom_barrier
[rank3]:     raise TimeoutError("Did not receive confirmation from rank 0 within {timeout} seconds")
[rank3]: TimeoutError: Did not receive confirmation from rank 0 within {timeout} seconds
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 255, in <module>
[rank0]:     main(args)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 247, in main
[rank0]:     trainer.fit(model, train_loader)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank0]:     loss = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 206, in training_step
[rank0]:     custom_barrier(timeout=timedelta(seconds=5))
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 176, in custom_barrier
[rank0]:     raise TimeoutError(f"Rank {i} did not respond within {timeout} seconds")
[rank0]: TimeoutError: Rank 1 did not respond within 5.0 seconds
Epoch 0:   0%|          | 0/3 [00:05<?, ?it/s]
[rank0]:[W901 03:46:15.507310493 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any
 pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only bee
n added since PyTorch 2.4 (function operator())
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ python distributed_test.py --timeout 30 --num_gpus 4
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read
 https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type   | Params
---------------------------------
0 | layer | Linear | 2
---------------------------------
2         Trainable params
0         Non-trainable params
2         Total params
0.000     Total estimated model params size (MB)
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_ever
y_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]
before barrier
before barrier
before barrier
before barrier
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 255, in <module>
[rank3]:     main(args)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 247, in main
[rank3]:     trainer.fit(model, train_loader)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank3]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:     return optimizer.step(closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank3]:     ret = func(self, *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank3]:     loss = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank3]:     closure_result = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank3]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank3]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank3]:     out = method(*_args, **_kwargs)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 206, in training_step
[rank3]:     custom_barrier(timeout=timedelta(seconds=30))
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 191, in custom_barrier
[rank3]:     raise TimeoutError("Did not receive confirmation from rank 0 within {timeout} seconds")
[rank3]: TimeoutError: Did not receive confirmation from rank 0 within {timeout} seconds
[rank2]: Traceback (most recent call last):
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 255, in <module>
[rank2]:     main(args)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 247, in main
[rank2]:     trainer.fit(model, train_loader)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank2]:     self.advance()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank2]:     self._optimizer_step(batch_idx, closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank2]:     call._call_lightning_module_hook(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank2]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank2]:     return optimizer.step(closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank2]:     ret = func(self, *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank2]:     loss = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank2]:     closure_result = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank2]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank2]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank2]:     out = method(*_args, **_kwargs)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 206, in training_step
[rank2]:     custom_barrier(timeout=timedelta(seconds=30))
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 191, in custom_barrier
[rank2]:     raise TimeoutError("Did not receive confirmation from rank 0 within {timeout} seconds")
[rank2]: TimeoutError: Did not receive confirmation from rank 0 within {timeout} seconds
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 255, in <module>
[rank1]:     main(args)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 247, in main
[rank1]:     trainer.fit(model, train_loader)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank1]:     self.advance()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank1]:     self._optimizer_step(batch_idx, closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank1]:     call._call_lightning_module_hook(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank1]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank1]:     return optimizer.step(closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank1]:     out = func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank1]:     ret = func(self, *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank1]:     loss = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank1]:     closure_result = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank1]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank1]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank1]:     out = method(*_args, **_kwargs)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 206, in training_step
[rank1]:     custom_barrier(timeout=timedelta(seconds=30))
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 191, in custom_barrier
[rank1]:     raise TimeoutError("Did not receive confirmation from rank 0 within {timeout} seconds")
[rank1]: TimeoutError: Did not receive confirmation from rank 0 within {timeout} seconds
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 255, in <module>
[rank0]:     main(args)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 247, in main
[rank0]:     trainer.fit(model, train_loader)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank0]:     loss = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 206, in training_step
[rank0]:     custom_barrier(timeout=timedelta(seconds=30))
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 176, in custom_barrier
[rank0]:     raise TimeoutError(f"Rank {i} did not respond within {timeout} seconds")
[rank0]: TimeoutError: Rank 1 did not respond within 30.0 seconds
Epoch 0:   0%|          | 0/3 [00:30<?, ?it/s]
[rank0]:[W901 03:48:39.904546125 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any
 pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only bee
n added since PyTorch 2.4 (function operator())
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ clear
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ python distributed_test.py --timeout 30 --num_gpus 4
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read
 https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type   | Params
---------------------------------
0 | layer | Linear | 2
---------------------------------
2         Trainable params
0         Non-trainable params
2         Total params
0.000     Total estimated model params size (MB)
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_ever
y_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]
before barrier
rank: 3
send to rank 0
before barrier
before barrier
rank: 2
send to rank 0
rank: 1
send to rank 0
rank 2 still waiting
rank 3 still waiting
rank 1 still waiting
before barrier
inside rank 0 barrier
rank 0 waiting
rank 2 still waiting
rank 1 still waiting
rank 3 still waiting
rank 0 waiting
rank 3 still waiting
rank 1 still waiting
rank 2 still waiting
rank 0 waiting
rank 3 still waiting
rank 2 still waiting
rank 1 still waiting
rank 0 waiting
rank 3 still waiting
rank 1 still waiting
rank 2 still waiting
rank 0 waiting
rank 2 still waiting
rank 1 still waiting
rank 3 still waiting
rank 0 waiting
rank 1 still waiting
rank 2 still waiting
rank 3 still waiting
rank 0 waiting
rank 3 still waiting
rank 2 still waiting
rank 1 still waiting
rank 0 waiting
rank 2 still waiting
rank 1 still waiting
rank 3 still waiting
rank 0 waiting
rank 1 still waiting
rank 2 still waiting
rank 3 still waiting
rank 0 waiting
rank 1 still waiting
rank 2 still waiting
rank 3 still waiting
rank 0 waiting
rank 2 still waiting
rank 3 still waiting
rank 1 still waiting
rank 0 waiting
^Z
[10]+  Stopped                 python distributed_test.py --timeout 30 --num_gpus 4
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ clear
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ clear
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ python distributed_test.py --timeout 30 --num_gpus 4
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read
 https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type   | Params
---------------------------------
0 | layer | Linear | 2
---------------------------------
2         Trainable params
0         Non-trainable params
2         Total params
0.000     Total estimated model params size (MB)
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_ever
y_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]
before barrier
rank: 3
send to rank 0
before barrier
rank: 2
send to rank 0
before barrier
rank: 1
send to rank 0
rank 2 still waiting
rank 3 still waiting
rank 1 still waiting
before barrier
inside rank 0 barrier
rank 0 waiting
rank 3 still waiting
rank 2 still waiting
rank 1 still waiting
rank 0 waiting
rank 2 still waiting
rank 3 still waiting
rank 1 still waiting
rank 0 waiting
rank 2 still waiting
rank 3 still waiting
rank 1 still waiting
rank 0 waiting
rank 3 still waiting
rank 2 still waiting
rank 1 still waiting
rank 0 waiting
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 261, in <module>
[rank3]:     main(args)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 253, in main
[rank3]:     trainer.fit(model, train_loader)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank3]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:     return optimizer.step(closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank3]:     ret = func(self, *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank3]:     loss = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank3]:     closure_result = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank3]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank3]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank3]:     out = method(*_args, **_kwargs)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 212, in training_step
[rank3]:     custom_barrier(timeout=timedelta(seconds=5))
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank3]:     raise TimeoutError(f"Did not receive confirmation from rank 0 within {timeout} seconds")
[rank3]: TimeoutError: Did not receive confirmation from rank 0 within 5.0 seconds
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 261, in <module>
[rank1]:     main(args)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 253, in main
[rank1]:     trainer.fit(model, train_loader)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank1]:     self.advance()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank1]:     self._optimizer_step(batch_idx, closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank1]:     call._call_lightning_module_hook(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank1]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank1]:     return optimizer.step(closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank1]:     out = func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank1]:     ret = func(self, *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank1]:     loss = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank1]:     closure_result = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank1]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank1]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank1]:     out = method(*_args, **_kwargs)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 212, in training_step
[rank1]:     custom_barrier(timeout=timedelta(seconds=5))
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank1]:     raise TimeoutError(f"Did not receive confirmation from rank 0 within {timeout} seconds")
[rank1]: TimeoutError: Did not receive confirmation from rank 0 within 5.0 seconds
[rank2]: Traceback (most recent call last):
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 261, in <module>
[rank2]:     main(args)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 253, in main
[rank2]:     trainer.fit(model, train_loader)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank2]:     self.advance()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank2]:     self._optimizer_step(batch_idx, closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank2]:     call._call_lightning_module_hook(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank2]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank2]:     return optimizer.step(closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank2]:     ret = func(self, *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank2]:     loss = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank2]:     closure_result = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank2]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank2]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank2]:     out = method(*_args, **_kwargs)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 212, in training_step
[rank2]:     custom_barrier(timeout=timedelta(seconds=5))
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank2]:     raise TimeoutError(f"Did not receive confirmation from rank 0 within {timeout} seconds")
[rank2]: TimeoutError: Did not receive confirmation from rank 0 within 5.0 seconds
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 261, in <module>
[rank0]:     main(args)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 253, in main
[rank0]:     trainer.fit(model, train_loader)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank0]:     loss = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 212, in training_step
[rank0]:     custom_barrier(timeout=timedelta(seconds=5))
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 178, in custom_barrier
[rank0]:     raise TimeoutError(f"Rank {i} did not respond within {timeout} seconds")
[rank0]: TimeoutError: Rank 1 did not respond within 5.0 seconds
Epoch 0:   0%|          | 0/3 [00:05<?, ?it/s]
[rank0]:[W901 03:51:13.238573932 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any
 pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only bee
n added since PyTorch 2.4 (function operator())
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ python distributed_test.py --timeout 30 --num_gpus 4
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read
 https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type   | Params
---------------------------------
0 | layer | Linear | 2
---------------------------------
2         Trainable params
0         Non-trainable params
2         Total params
0.000     Total estimated model params size (MB)
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_ever
y_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]
before barrier
Rank 3: Sending to rank 0
before barrier
Rank 2: Sending to rank 0
before barrier
Rank 1: Sending to rank 0
before barrier
Rank 0: Waiting for 3 other ranks
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank3]:     main(args)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank3]:     trainer.fit(model, train_loader)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank3]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:     return optimizer.step(closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank3]:     ret = func(self, *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank3]:     loss = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank3]:     closure_result = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank3]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank3]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank3]:     out = method(*_args, **_kwargs)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank3]:     custom_barrier(timeout=timedelta(seconds=5))
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank3]:     raise TimeoutError(f"Rank {rank} could not send to rank 0 within {timeout} seconds")
[rank3]: TimeoutError: Rank 3 could not send to rank 0 within 5.0 seconds
[rank2]: Traceback (most recent call last):
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank2]:     main(args)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank2]:     trainer.fit(model, train_loader)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank2]:     self.advance()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank2]:     self._optimizer_step(batch_idx, closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank2]:     call._call_lightning_module_hook(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank2]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank2]:     return optimizer.step(closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank2]:     ret = func(self, *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank2]:     loss = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank2]:     closure_result = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank2]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank2]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank2]:     out = method(*_args, **_kwargs)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank2]:     custom_barrier(timeout=timedelta(seconds=5))
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank2]:     raise TimeoutError(f"Rank {rank} could not send to rank 0 within {timeout} seconds")
[rank2]: TimeoutError: Rank 2 could not send to rank 0 within 5.0 seconds
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank1]:     main(args)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank1]:     trainer.fit(model, train_loader)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank1]:     self.advance()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank1]:     self._optimizer_step(batch_idx, closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank1]:     call._call_lightning_module_hook(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank1]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank1]:     return optimizer.step(closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank1]:     out = func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank1]:     ret = func(self, *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank1]:     loss = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank1]:     closure_result = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank1]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank1]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank1]:     out = method(*_args, **_kwargs)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank1]:     custom_barrier(timeout=timedelta(seconds=5))
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank1]:     raise TimeoutError(f"Rank {rank} could not send to rank 0 within {timeout} seconds")
[rank1]: TimeoutError: Rank 1 could not send to rank 0 within 5.0 seconds
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank0]:     main(args)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank0]:     trainer.fit(model, train_loader)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank0]:     loss = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank0]:     custom_barrier(timeout=timedelta(seconds=5))
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 180, in custom_barrier
[rank0]:     raise TimeoutError(f"Rank {i} did not respond within {timeout} seconds")
[rank0]: TimeoutError: Rank 1 did not respond within 5.0 seconds
Epoch 0:   0%|          | 0/3 [00:05<?, ?it/s]
[rank0]:[W901 03:55:05.210320174 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any
 pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only bee
n added since PyTorch 2.4 (function operator())
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ python distributed_test.py --timeout 30 --num_gpus 4
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prep
end your python command with `srun` like so: srun python distributed_test.py --timeout 30 --num_gpus 4 ...
You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read
 https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type   | Params
---------------------------------
0 | layer | Linear | 2
---------------------------------
2         Trainable params
0         Non-trainable params
2         Total params
0.000     Total estimated model params size (MB)
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_ever
y_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]
before barrier
Rank 2: Sending to rank 0
before barrier
Rank 1: Sending to rank 0
before barrier
Rank 3: Sending to rank 0
before barrier
Rank 0: Waiting for 3 other ranks
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank0]:     main(args)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank0]:     trainer.fit(model, train_loader)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank0]:     self.advance()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank0]:     return optimizer.step(closure=closure, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank0]:     out = func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank0]:     ret = func(self, *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank0]:     loss = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank0]:     closure_result = closure()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank0]:     custom_barrier(timeout=timedelta(seconds=30))
[rank0]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 180, in custom_barrier
[rank0]:     raise TimeoutError(f"Rank {i} did not respond within {timeout} seconds")
[rank0]: TimeoutError: Rank 1 did not respond within 30.0 seconds
[rank2]: Traceback (most recent call last):
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank2]:     main(args)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank2]:     trainer.fit(model, train_loader)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank2]:     self.advance()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank2]:     self._optimizer_step(batch_idx, closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank2]:     call._call_lightning_module_hook(
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank2]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank2]:     return optimizer.step(closure=closure, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank2]:     out = func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank2]:     ret = func(self, *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank2]:     loss = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank2]:     closure_result = closure()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank2]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank2]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank2]:     out = method(*_args, **_kwargs)
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank2]:     custom_barrier(timeout=timedelta(seconds=30))
[rank2]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank2]:     raise TimeoutError(f"Rank {rank} could not send to rank 0 within {timeout} seconds")
[rank2]: TimeoutError: Rank 2 could not send to rank 0 within 30.0 seconds
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank1]:     main(args)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank1]:     trainer.fit(model, train_loader)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank1]:     self.advance()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank1]:     self._optimizer_step(batch_idx, closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank1]:     call._call_lightning_module_hook(
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank1]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank1]:     return optimizer.step(closure=closure, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank1]:     out = func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank1]:     ret = func(self, *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank1]:     loss = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank1]:     closure_result = closure()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank1]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank1]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank1]:     out = method(*_args, **_kwargs)
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank1]:     custom_barrier(timeout=timedelta(seconds=30))
[rank1]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank1]:     raise TimeoutError(f"Rank {rank} could not send to rank 0 within {timeout} seconds")
[rank1]: TimeoutError: Rank 1 could not send to rank 0 within 30.0 seconds
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 274, in <module>
[rank3]:     main(args)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 266, in main
[rank3]:     trainer.fit(model, train_loader)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1033, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
[rank3]:     self.advance()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 250, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 190, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 268, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1303, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 152, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py", line 270, in optimizer_step
[rank3]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 122, in optimizer_step
[rank3]:     return optimizer.step(closure=closure, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
[rank3]:     out = func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
[rank3]:     ret = func(self, *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/optim/sgd.py", line 112, in step
[rank3]:     loss = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 108, in _wrap_closure
[rank3]:     closure_result = closure()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 144, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 129, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 318, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
[rank3]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 642, in __call__
[rank3]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1636, in forward
[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1454, in _run_ddp_forward
[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 635, in wrapped_forward
[rank3]:     out = method(*_args, **_kwargs)
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 225, in training_step
[rank3]:     custom_barrier(timeout=timedelta(seconds=30))
[rank3]:   File "/data/yingzi_ma/lean_project/ReProver/distributed_test.py", line 197, in custom_barrier
[rank3]:     raise TimeoutError(f"Rank {rank} could not send to rank 0 within {timeout} seconds")
[rank3]: TimeoutError: Rank 3 could not send to rank 0 within 30.0 seconds
Epoch 0:   0%|          | 0/3 [00:30<?, ?it/s]
[rank0]:[W901 03:56:01.898837252 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any
 pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only bee
n added since PyTorch 2.4 (function operator())
(ReProver) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$
