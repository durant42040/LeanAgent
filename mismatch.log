Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
Stopping ray
Did not find any active Ray processes.
kill: (6957): Operation not permitted
kill: (7275): Operation not permitted
kill: (2360661): Operation not permitted
kill: (3306425): Operation not permitted
kill: (3314876): Operation not permitted
kill: (3314948): Operation not permitted
kill: (3314979): Operation not permitted
kill: (3315058): Operation not permitted
kill: (3318263): Operation not permitted
kill: (3341782): Operation not permitted
kill: (3341818): Operation not permitted
kill: (3370414): No such process
kill: (3733179): Operation not permitted
kill: (3733198): Operation not permitted
kill: (3733199): Operation not permitted
kill: (3733200): Operation not permitted
kill: (3733207): Operation not permitted
kill: (3734071): Operation not permitted
kill: (3734089): Operation not permitted
kill: (3734090): Operation not permitted
kill: (3734091): Operation not permitted
kill: (3734098): Operation not permitted
kill: (3734775): Operation not permitted
kill: (3734794): Operation not permitted
kill: (3734795): Operation not permitted
kill: (3734796): Operation not permitted
kill: (3734803): Operation not permitted
Sun Sep 22 18:55:40 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0F:00.0 Off |                    0 |
| N/A   39C    P0             89W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:15:00.0 Off |                    0 |
| N/A   36C    P0             83W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:50:00.0 Off |                    0 |
| N/A   36C    P0             84W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:53:00.0 Off |                    0 |
| N/A   37C    P0             85W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running main3_more_sorries_big_model.py
[2024-09-22 18:55:46,245] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-22 18:55:49.975 | INFO     | __main__:main:1606 - Running progressive training
2024-09-22 18:55:49.975 | INFO     | __main__:main:1612 - Configuring LeanDojo...
2024-09-22 18:55:49.979 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-22 18:55:49.979 | INFO     | __main__:main:1614 - LeanDojo configured
2024-09-22 18:55:49.979 | INFO     | __main__:main:1619 - Starting the main process
2024-09-22 18:55:49.980 | INFO     | __main__:main:1627 - Loading database from /data/yingzi_ma/lean_project/dynamic_database_PT_single_repo_no_ewc_curriculum_sorries_big_model.json
2024-09-22 18:56:40.593 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/ahhwuhu/zeta_3_irrational (commit: 914712200e463cfc97fe37e929d518dd58806a38)
2024-09-22 18:56:40.593 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/ahhwuhu/zeta_3_irrational (commit: 914712200e463cfc97fe37e929d518dd58806a38)
2024-09-22 18:56:47.322 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/apnelson1/Matroid (commit: 244315752bb0a771f20b676b946130b664d60712)
2024-09-22 18:56:47.322 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/apnelson1/Matroid (commit: 244315752bb0a771f20b676b946130b664d60712)
2024-09-22 18:56:55.336 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/mo271/formal_book (commit: 6fbe8c2985008c0bfb30050750a71b90388ad3a3)
2024-09-22 18:56:55.336 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/mo271/formal_book (commit: 6fbe8c2985008c0bfb30050750a71b90388ad3a3)
2024-09-22 18:56:57.122 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/fpvandoorn/carleson (commit: bec7808b907190882fa1fa54ce749af297c6cf37)
2024-09-22 18:56:57.123 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/fpvandoorn/carleson (commit: bec7808b907190882fa1fa54ce749af297c6cf37)
2024-09-22 18:57:05.847 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/YaelDillies/LeanAPAP (commit: 951c660a8d7ba8e39f906fdf657674a984effa8b)
2024-09-22 18:57:05.847 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/YaelDillies/LeanAPAP (commit: 951c660a8d7ba8e39f906fdf657674a984effa8b)
2024-09-22 18:57:07.577 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/NUS-Math-Formalization/coxeter (commit: 96af8aee7943ca8685ed1b00cc83a559ea389a97)
2024-09-22 18:57:07.577 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/NUS-Math-Formalization/coxeter (commit: 96af8aee7943ca8685ed1b00cc83a559ea389a97)
2024-09-22 18:57:17.463 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/yangky11/miniF2F-lean4 (commit: 9e445f5435407f014b88b44a98436d50dd7abd00)
2024-09-22 18:57:17.463 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/yangky11/miniF2F-lean4 (commit: 9e445f5435407f014b88b44a98436d50dd7abd00)
2024-09-22 18:57:17.933 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/m4lvin/lean4-pdl (commit: c7f649fe3c4891cf1a01c120e82ebc5f6199856e)
2024-09-22 18:57:17.933 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/m4lvin/lean4-pdl (commit: c7f649fe3c4891cf1a01c120e82ebc5f6199856e)
2024-09-22 18:57:19.718 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/Louis-Le-Grand/Formalisation-of-constructable-numbers (commit: 01ef1f22a04f2ba8081c5fb29413f515a0e52878)
2024-09-22 18:57:19.718 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/Louis-Le-Grand/Formalisation-of-constructable-numbers (commit: 01ef1f22a04f2ba8081c5fb29413f515a0e52878)
2024-09-22 18:57:31.026 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/corent1234/hairy-ball-theorem-lean (commit: a778826d19c8a7ddf1d26beeea628c45450612e6)
2024-09-22 18:57:31.027 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/corent1234/hairy-ball-theorem-lean (commit: a778826d19c8a7ddf1d26beeea628c45450612e6)
2024-09-22 18:57:32.061 | INFO     | __main__:main:1629 - Loaded database from /data/yingzi_ma/lean_project/dynamic_database_PT_single_repo_no_ewc_curriculum_sorries_big_model.json
2024-09-22 18:57:32.062 | INFO     | __main__:main:1636 - Found 9 repositories
2024-09-22 18:57:32.062 | INFO     | __main__:main:1639 - Starting curriculum learning
2024-09-22 18:57:32.518 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
Following Github server redirection from /repos/mo271/formal_book to /repositories/537006181
2024-09-22 18:57:50.013 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-22 18:58:08.824 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-22 18:58:27.105 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-22 18:58:43.523 | INFO     | __main__:main:1775 - length of lean_git_repos: 8
2024-09-22 18:58:43.523 | INFO     | __main__:main:1776 - i: 0
2024-09-22 18:58:43.524 | INFO     | __main__:main:1782 - Main process
2024-09-22 18:58:43.524 | INFO     | __main__:main:1783 - Using lambda = 0.1
2024-09-22 18:58:43.524 | INFO     | __main__:main:1784 - Processing https://github.com/ahhwuhu/zeta_3_irrational
2024-09-22 18:58:43.525 | INFO     | __main__:main:1791 - Adding repo to repos_for_merged_dataset
2024-09-22 18:58:43.526 | INFO     | dynamic_database:generate_merged_dataset:415 - Merging selected repositories in the database:
2024-09-22 18:58:43.526 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/ahhwuhu/zeta_3_irrational (commit: 914712200e463cfc97fe37e929d518dd58806a38)
2024-09-22 19:01:07.643 | WARNING  | dynamic_database:safe_remove_dir_path:377 - /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38 already exists. Removing it now.
2024-09-22 19:01:30.721 | INFO     | dynamic_database:generate_merged_dataset:439 - Exported proofs to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38
2024-09-22 19:01:31.329 | INFO     | dynamic_database:generate_merged_dataset:442 - Merged and exported corpus to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38
2024-09-22 19:01:31.350 | INFO     | dynamic_database:generate_merged_dataset:445 - Exported traced files to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38
2024-09-22 19:01:31.352 | INFO     | dynamic_database:generate_merged_dataset:448 - Exported metadata to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38
2024-09-22 19:01:31.372 | INFO     | __main__:main:1803 - All GPUs
2024-09-22 19:01:31.373 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:01:31.373 | INFO     | __main__:main:1810 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:01:31.373 | INFO     | __main__:main:1816 - Inside train_test_fisher
2024-09-22 19:01:31.373 | INFO     | __main__:main:1817 - Starting training at epoch 0
[rank: 0] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 19:01:35.021 | INFO     | __main__:main:1841 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python main3_more_sorries_big_model.py ...
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
2024-09-22 19:01:35.122 | INFO     | __main__:main:1899 - right before barrier for data module
2024-09-22 19:01:35.122 | INFO     | __main__:main:1914 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random
2024-09-22 19:01:35.229 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/corpus.jsonl
  0%|          | 0/115368 [00:00<?, ?it/s]  1%|          | 752/115368 [00:00<00:15, 7468.21it/s]  1%|▏         | 1499/115368 [00:00<00:16, 7113.34it/s]  2%|▏         | 2212/115368 [00:00<00:16, 6809.46it/s]  3%|▎         | 2971/115368 [00:00<00:15, 7103.81it/s]  3%|▎         | 3729/115368 [00:00<00:15, 7250.49it/s]  4%|▍         | 4456/115368 [00:00<00:15, 7191.10it/s]  4%|▍         | 5177/115368 [00:00<00:15, 7152.84it/s]  5%|▌         | 5966/115368 [00:00<00:14, 7380.64it/s]  6%|▌         | 6705/115368 [00:00<00:15, 7040.57it/s]  6%|▋         | 7413/115368 [00:01<00:15, 6850.98it/s]  7%|▋         | 8101/115368 [00:01<00:15, 6721.90it/s]  8%|▊         | 8855/115368 [00:01<00:15, 6954.21it/s]  8%|▊         | 9553/115368 [00:01<00:16, 6507.74it/s]  9%|▉         | 10211/115368 [00:01<00:16, 6448.83it/s]  9%|▉         | 10898/115368 [00:01<00:15, 6567.60it/s] 10%|█         | 11628/115368 [00:01<00:15, 6774.32it/s] 11%|█         | 12309/115368 [00:01<00:15, 6526.86it/s] 11%|█▏        | 13054/115368 [00:01<00:15, 6789.77it/s] 12%|█▏        | 13769/115368 [00:02<00:14, 6819.01it/s] 13%|█▎        | 14454/115368 [00:02<00:15, 6610.95it/s] 13%|█▎        | 15176/115368 [00:02<00:15, 6623.08it/s] 14%|█▎        | 15841/115368 [00:02<00:15, 6593.09it/s] 14%|█▍        | 16586/115368 [00:02<00:14, 6836.30it/s] 15%|█▌        | 17416/115368 [00:02<00:13, 7255.11it/s] 16%|█▌        | 18144/115368 [00:02<00:13, 7140.40it/s] 16%|█▋        | 18860/115368 [00:02<00:13, 6947.86it/s] 17%|█▋        | 19557/115368 [00:02<00:13, 6881.20it/s] 18%|█▊        | 20247/115368 [00:02<00:14, 6514.95it/s] 18%|█▊        | 21099/115368 [00:03<00:13, 7071.82it/s] 19%|█▉        | 21813/115368 [00:03<00:13, 6993.33it/s] 20%|█▉        | 22665/115368 [00:03<00:12, 7427.94it/s] 20%|██        | 23413/115368 [00:03<00:12, 7257.59it/s] 21%|██        | 24254/115368 [00:03<00:12, 7585.11it/s] 22%|██▏       | 25081/115368 [00:03<00:11, 7776.98it/s] 22%|██▏       | 25862/115368 [00:03<00:12, 7179.13it/s] 23%|██▎       | 26591/115368 [00:03<00:12, 7106.62it/s] 24%|██▎       | 27309/115368 [00:03<00:12, 7018.61it/s] 24%|██▍       | 28016/115368 [00:04<00:12, 6835.41it/s] 25%|██▍       | 28704/115368 [00:04<00:13, 6607.07it/s] 25%|██▌       | 29396/115368 [00:04<00:12, 6694.06it/s] 26%|██▌       | 30249/115368 [00:04<00:11, 7214.44it/s] 27%|██▋       | 30975/115368 [00:04<00:11, 7168.16it/s] 27%|██▋       | 31695/115368 [00:04<00:11, 6990.58it/s] 28%|██▊       | 32471/115368 [00:04<00:11, 7184.44it/s] 29%|██▉       | 33192/115368 [00:04<00:11, 7036.36it/s] 29%|██▉       | 33973/115368 [00:04<00:11, 7258.35it/s] 30%|███       | 34712/115368 [00:04<00:11, 7294.40it/s] 31%|███       | 35444/115368 [00:05<00:11, 7200.23it/s] 31%|███▏      | 36166/115368 [00:05<00:11, 6805.95it/s] 32%|███▏      | 36891/115368 [00:05<00:11, 6912.20it/s] 33%|███▎      | 37614/115368 [00:05<00:11, 7003.28it/s] 33%|███▎      | 38376/115368 [00:05<00:10, 7181.61it/s] 34%|███▍      | 39234/115368 [00:05<00:10, 7583.11it/s] 35%|███▍      | 40092/115368 [00:05<00:09, 7876.69it/s] 35%|███▌      | 40882/115368 [00:05<00:09, 7511.36it/s] 36%|███▌      | 41639/115368 [00:05<00:10, 7003.33it/s] 37%|███▋      | 42415/115368 [00:06<00:10, 7211.02it/s] 37%|███▋      | 43145/115368 [00:06<00:10, 7198.59it/s] 38%|███▊      | 43871/115368 [00:06<00:10, 6897.82it/s] 39%|███▊      | 44692/115368 [00:06<00:09, 7252.52it/s] 39%|███▉      | 45461/115368 [00:06<00:09, 7367.16it/s] 40%|████      | 46203/115368 [00:06<00:09, 7348.66it/s] 41%|████      | 47025/115368 [00:06<00:08, 7601.38it/s] 41%|████▏     | 47789/115368 [00:06<00:09, 7345.89it/s] 42%|████▏     | 48528/115368 [00:06<00:09, 7347.58it/s] 43%|████▎     | 49266/115368 [00:06<00:09, 6762.90it/s] 43%|████▎     | 50118/115368 [00:07<00:09, 7245.51it/s] 44%|████▍     | 50879/115368 [00:07<00:08, 7319.78it/s] 45%|████▍     | 51619/115368 [00:07<00:08, 7200.99it/s] 45%|████▌     | 52345/115368 [00:07<00:09, 6805.52it/s] 46%|████▌     | 53055/115368 [00:07<00:09, 6885.29it/s] 47%|████▋     | 53750/115368 [00:07<00:09, 6605.72it/s] 47%|████▋     | 54500/115368 [00:07<00:08, 6848.36it/s] 48%|████▊     | 55191/115368 [00:07<00:08, 6839.55it/s] 48%|████▊     | 55879/115368 [00:07<00:08, 6687.49it/s] 49%|████▉     | 56637/115368 [00:08<00:08, 6939.55it/s] 50%|████▉     | 57391/115368 [00:08<00:08, 7098.79it/s] 50%|█████     | 58163/115368 [00:08<00:07, 7278.66it/s] 51%|█████     | 58894/115368 [00:08<00:07, 7172.63it/s] 52%|█████▏    | 59614/115368 [00:08<00:08, 6672.08it/s] 52%|█████▏    | 60289/115368 [00:08<00:08, 6680.88it/s] 53%|█████▎    | 60988/115368 [00:08<00:08, 6767.51it/s] 53%|█████▎    | 61716/115368 [00:08<00:07, 6884.38it/s] 54%|█████▍    | 62414/115368 [00:08<00:07, 6910.53it/s] 55%|█████▍    | 63108/115368 [00:08<00:07, 6735.60it/s] 55%|█████▌    | 63838/115368 [00:09<00:07, 6898.20it/s] 56%|█████▌    | 64530/115368 [00:09<00:07, 6882.93it/s] 57%|█████▋    | 65294/115368 [00:09<00:07, 7088.63it/s] 57%|█████▋    | 66048/115368 [00:09<00:06, 7190.72it/s] 58%|█████▊    | 66769/115368 [00:09<00:06, 7078.03it/s] 59%|█████▊    | 67533/115368 [00:09<00:06, 7240.94it/s] 59%|█████▉    | 68259/115368 [00:09<00:06, 7144.76it/s] 60%|█████▉    | 69024/115368 [00:09<00:06, 7289.59it/s] 60%|██████    | 69754/115368 [00:09<00:06, 6901.73it/s] 61%|██████    | 70449/115368 [00:10<00:06, 6883.87it/s] 62%|██████▏   | 71207/115368 [00:10<00:06, 7045.82it/s] 62%|██████▏   | 71915/115368 [00:10<00:06, 6996.36it/s] 63%|██████▎   | 72731/115368 [00:10<00:05, 7334.22it/s] 64%|██████▎   | 73535/115368 [00:10<00:05, 7541.77it/s] 64%|██████▍   | 74298/115368 [00:10<00:05, 7558.91it/s] 65%|██████▌   | 75058/115368 [00:10<00:05, 7569.77it/s] 66%|██████▌   | 75816/115368 [00:10<00:05, 6982.23it/s] 66%|██████▋   | 76596/115368 [00:10<00:05, 7210.01it/s] 67%|██████▋   | 77448/115368 [00:10<00:05, 7583.77it/s] 68%|██████▊   | 78304/115368 [00:11<00:04, 7862.91it/s] 69%|██████▊   | 79097/115368 [00:11<00:04, 7268.61it/s] 69%|██████▉   | 79837/115368 [00:11<00:04, 7299.18it/s] 70%|██████▉   | 80576/115368 [00:11<00:04, 7104.20it/s] 71%|███████   | 81365/115368 [00:11<00:04, 7322.63it/s] 71%|███████   | 82104/115368 [00:11<00:04, 7228.82it/s] 72%|███████▏  | 82967/115368 [00:11<00:04, 7628.58it/s] 73%|███████▎  | 83836/115368 [00:11<00:03, 7936.70it/s] 73%|███████▎  | 84638/115368 [00:11<00:03, 7959.85it/s] 74%|███████▍  | 85437/115368 [00:12<00:04, 7395.42it/s] 75%|███████▍  | 86188/115368 [00:12<00:03, 7418.19it/s] 75%|███████▌  | 86982/115368 [00:12<00:03, 7564.95it/s] 76%|███████▌  | 87744/115368 [00:12<00:03, 6986.20it/s] 77%|███████▋  | 88477/115368 [00:12<00:03, 7056.52it/s] 77%|███████▋  | 89192/115368 [00:12<00:03, 7042.18it/s] 78%|███████▊  | 89995/115368 [00:12<00:03, 7324.94it/s] 79%|███████▊  | 90734/115368 [00:12<00:03, 7124.13it/s] 79%|███████▉  | 91514/115368 [00:12<00:03, 7305.86it/s] 80%|███████▉  | 92269/115368 [00:12<00:03, 7376.67it/s] 81%|████████  | 93034/115368 [00:13<00:02, 7450.07it/s] 81%|████████▏ | 93790/115368 [00:13<00:02, 7481.84it/s] 82%|████████▏ | 94595/115368 [00:13<00:02, 7601.44it/s] 83%|████████▎ | 95357/115368 [00:13<00:02, 7409.10it/s] 83%|████████▎ | 96100/115368 [00:13<00:02, 7381.27it/s] 84%|████████▍ | 96856/115368 [00:13<00:02, 7428.69it/s] 85%|████████▍ | 97640/115368 [00:13<00:02, 7510.39it/s] 85%|████████▌ | 98392/115368 [00:13<00:02, 7335.26it/s] 86%|████████▌ | 99127/115368 [00:13<00:02, 7135.16it/s] 87%|████████▋ | 99845/115368 [00:14<00:02, 7132.84it/s] 87%|████████▋ | 100618/115368 [00:14<00:02, 7293.76it/s] 88%|████████▊ | 101349/115368 [00:14<00:02, 6810.24it/s] 89%|████████▊ | 102129/115368 [00:14<00:01, 7079.36it/s] 89%|████████▉ | 102844/115368 [00:14<00:01, 6720.40it/s] 90%|████████▉ | 103630/115368 [00:14<00:01, 7028.52it/s] 90%|█████████ | 104370/115368 [00:14<00:01, 7128.66it/s] 91%|█████████ | 105089/115368 [00:14<00:01, 7076.58it/s] 92%|█████████▏| 105902/115368 [00:14<00:01, 7369.94it/s] 92%|█████████▏| 106643/115368 [00:14<00:01, 7185.51it/s] 93%|█████████▎| 107392/115368 [00:15<00:01, 7247.70it/s] 94%|█████████▎| 108120/115368 [00:15<00:01, 6957.33it/s] 94%|█████████▍| 108820/115368 [00:15<00:00, 6752.80it/s] 95%|█████████▌| 109624/115368 [00:15<00:00, 7113.49it/s] 96%|█████████▌| 110340/115368 [00:15<00:00, 6943.19it/s] 96%|█████████▋| 111164/115368 [00:15<00:00, 7310.04it/s] 97%|█████████▋| 111915/115368 [00:15<00:00, 7361.11it/s] 98%|█████████▊| 112664/115368 [00:15<00:00, 7388.02it/s] 98%|█████████▊| 113405/115368 [00:15<00:00, 6965.38it/s] 99%|█████████▉| 114266/115368 [00:16<00:00, 7407.63it/s]100%|█████████▉| 115094/115368 [00:16<00:00, 7653.29it/s]100%|██████████| 115368/115368 [00:16<00:00, 7133.23it/s]
2024-09-22 19:02:19.890 | INFO     | retrieval.datamodule:load_or_cache_data:65 - Saved loaded data to cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
Training dataset size: 357252
  0%|          | 0/2403 [00:00<?, ?it/s] 29%|██▉       | 700/2403 [00:00<00:00, 6975.14it/s] 61%|██████    | 1458/2403 [00:00<00:00, 7229.89it/s] 95%|█████████▍| 2274/2403 [00:00<00:00, 7647.24it/s]100%|██████████| 2403/2403 [00:00<00:00, 7542.81it/s]
2024-09-22 19:02:20.293 | INFO     | retrieval.datamodule:load_or_cache_data:65 - Saved loaded data to cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
Validation dataset size: 4833
  0%|          | 0/2403 [00:00<?, ?it/s] 32%|███▏      | 757/2403 [00:00<00:00, 7349.11it/s] 64%|██████▍   | 1540/2403 [00:00<00:00, 7625.03it/s] 96%|█████████▌| 2303/2403 [00:00<00:00, 7276.51it/s]100%|██████████| 2403/2403 [00:00<00:00, 7445.82it/s]
2024-09-22 19:02:20.706 | INFO     | retrieval.datamodule:load_or_cache_data:65 - Saved loaded data to cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
2024-09-22 19:02:20.706 | INFO     | __main__:main:1928 - Training dataset size after load: 357252
2024-09-22 19:02:20.706 | INFO     | __main__:main:1929 - Validation dataset size after load: 4833
2024-09-22 19:02:20.706 | INFO     | __main__:main:1930 - Testing dataset size after load: 5139
2024-09-22 19:02:20.706 | INFO     | __main__:main:1932 - Starting progressive training from epoch 0 to 1
2024-09-22 19:02:20.706 | INFO     | __main__:main:1935 - hit the barrier before training
[rank: 0] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[2024-09-22 19:02:26,440] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-22 19:02:26,556] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-22 19:02:26,556] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-22 19:02:30.029 | INFO     | __main__:main:1606 - Running progressive training
2024-09-22 19:02:30.029 | INFO     | __main__:main:1612 - Configuring LeanDojo...
2024-09-22 19:02:30.032 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-22 19:02:30.032 | INFO     | __main__:main:1614 - LeanDojo configured
2024-09-22 19:02:30.032 | INFO     | __main__:main:1636 - Found 9 repositories
2024-09-22 19:02:30.032 | INFO     | __main__:main:1639 - Starting curriculum learning
2024-09-22 19:02:30.183 | INFO     | __main__:main:1606 - Running progressive training
2024-09-22 19:02:30.183 | INFO     | __main__:main:1606 - Running progressive training
2024-09-22 19:02:30.183 | INFO     | __main__:main:1612 - Configuring LeanDojo...
2024-09-22 19:02:30.183 | INFO     | __main__:main:1612 - Configuring LeanDojo...
2024-09-22 19:02:30.188 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-22 19:02:30.188 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-22 19:02:30.188 | INFO     | __main__:main:1614 - LeanDojo configured
2024-09-22 19:02:30.188 | INFO     | __main__:main:1614 - LeanDojo configured
2024-09-22 19:02:30.188 | INFO     | __main__:main:1636 - Found 9 repositories
2024-09-22 19:02:30.188 | INFO     | __main__:main:1636 - Found 9 repositories
2024-09-22 19:02:30.188 | INFO     | __main__:main:1639 - Starting curriculum learning
2024-09-22 19:02:30.188 | INFO     | __main__:main:1639 - Starting curriculum learning
2024-09-22 19:02:30.206 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-22 19:02:30.403 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-22 19:02:30.467 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
Following Github server redirection from /repos/mo271/formal_book to /repositories/537006181
Following Github server redirection from /repos/mo271/formal_book to /repositories/537006181
2024-09-22 19:02:47.736 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
Following Github server redirection from /repos/mo271/formal_book to /repositories/537006181
2024-09-22 19:02:47.850 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-22 19:02:47.962 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-22 19:03:06.120 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-22 19:03:06.450 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-22 19:03:07.098 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-22 19:03:23.789 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-22 19:03:23.815 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-22 19:03:24.978 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-22 19:03:40.319 | INFO     | __main__:main:1775 - length of lean_git_repos: 8
2024-09-22 19:03:40.319 | INFO     | __main__:main:1776 - i: 0
2024-09-22 19:03:40.320 | INFO     | __main__:main:1803 - All GPUs
2024-09-22 19:03:40.321 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:40.321 | INFO     | __main__:main:1810 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:40.321 | INFO     | __main__:main:1816 - Inside train_test_fisher
2024-09-22 19:03:40.321 | INFO     | __main__:main:1817 - Starting training at epoch 0
[rank: 1] Seed set to 3407
2024-09-22 19:03:40.530 | INFO     | __main__:main:1775 - length of lean_git_repos: 8
2024-09-22 19:03:40.530 | INFO     | __main__:main:1776 - i: 0
2024-09-22 19:03:40.530 | INFO     | __main__:main:1803 - All GPUs
2024-09-22 19:03:40.531 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:40.531 | INFO     | __main__:main:1810 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:40.531 | INFO     | __main__:main:1816 - Inside train_test_fisher
2024-09-22 19:03:40.531 | INFO     | __main__:main:1817 - Starting training at epoch 0
[rank: 3] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
2024-09-22 19:03:41.781 | INFO     | __main__:main:1775 - length of lean_git_repos: 8
2024-09-22 19:03:41.781 | INFO     | __main__:main:1776 - i: 0
2024-09-22 19:03:41.782 | INFO     | __main__:main:1803 - All GPUs
2024-09-22 19:03:41.783 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:41.783 | INFO     | __main__:main:1810 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:41.783 | INFO     | __main__:main:1816 - Inside train_test_fisher
2024-09-22 19:03:41.783 | INFO     | __main__:main:1817 - Starting training at epoch 0
[rank: 2] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 19:03:44.708 | INFO     | __main__:main:1841 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:44.816 | INFO     | __main__:main:1899 - right before barrier for data module
2024-09-22 19:03:44.816 | INFO     | __main__:main:1914 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random
2024-09-22 19:03:44.914 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/corpus.jsonl
2024-09-22 19:03:45.340 | INFO     | __main__:main:1841 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 19:03:45.395 | INFO     | __main__:main:1899 - right before barrier for data module
2024-09-22 19:03:45.395 | INFO     | __main__:main:1914 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random
2024-09-22 19:03:45.495 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/corpus.jsonl
2024-09-22 19:03:47.042 | INFO     | __main__:main:1841 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:03:47.158 | INFO     | __main__:main:1899 - right before barrier for data module
2024-09-22 19:03:47.158 | INFO     | __main__:main:1914 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random
2024-09-22 19:03:47.264 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/corpus.jsonl
2024-09-22 19:04:11.421 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
2024-09-22 19:04:11.445 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
2024-09-22 19:04:11.472 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
2024-09-22 19:04:11.472 | INFO     | __main__:main:1928 - Training dataset size after load: 357252
2024-09-22 19:04:11.472 | INFO     | __main__:main:1929 - Validation dataset size after load: 4833
2024-09-22 19:04:11.472 | INFO     | __main__:main:1930 - Testing dataset size after load: 5139
2024-09-22 19:04:11.472 | INFO     | __main__:main:1932 - Starting progressive training from epoch 0 to 1
2024-09-22 19:04:11.473 | INFO     | __main__:main:1935 - hit the barrier before training
[rank: 3] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
2024-09-22 19:04:20.330 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
2024-09-22 19:04:20.354 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
2024-09-22 19:04:20.381 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
2024-09-22 19:04:20.381 | INFO     | __main__:main:1928 - Training dataset size after load: 357252
2024-09-22 19:04:20.381 | INFO     | __main__:main:1929 - Validation dataset size after load: 4833
2024-09-22 19:04:20.381 | INFO     | __main__:main:1930 - Testing dataset size after load: 5139
2024-09-22 19:04:20.381 | INFO     | __main__:main:1932 - Starting progressive training from epoch 0 to 1
2024-09-22 19:04:20.382 | INFO     | __main__:main:1935 - hit the barrier before training
[rank: 1] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
2024-09-22 19:04:22.130 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
2024-09-22 19:04:22.154 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
2024-09-22 19:04:22.179 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
2024-09-22 19:04:22.180 | INFO     | __main__:main:1928 - Training dataset size after load: 357252
2024-09-22 19:04:22.180 | INFO     | __main__:main:1929 - Validation dataset size after load: 4833
2024-09-22 19:04:22.180 | INFO     | __main__:main:1930 - Testing dataset size after load: 5139
2024-09-22 19:04:22.180 | INFO     | __main__:main:1932 - Starting progressive training from epoch 0 to 1
2024-09-22 19:04:22.180 | INFO     | __main__:main:1935 - hit the barrier before training
[rank: 2] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
2024-09-22 19:04:27.687 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
2024-09-22 19:04:27.887 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
2024-09-22 19:04:33.412 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
2024-09-22 19:04:33.583 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
2024-09-22 19:04:33.615 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
2024-09-22 19:04:36.764 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
2024-09-22 19:04:36.999 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_train/cached_data.pkl
2024-09-22 19:04:37.006 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
2024-09-22 19:04:37.056 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
2024-09-22 19:04:37.226 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_val/cached_data.pkl
2024-09-22 19:04:37.271 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
2024-09-22 19:04:37.913 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38/random/cache_pred/cached_data.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model exists and is not empty.
Restoring states from the checkpoint path at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
2024-09-22 19:04:40.733 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-22 19:04:40.733 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-22 19:04:40.736 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-22 19:04:40.736 | INFO     | common:get_optimizers:449 - Optimizing with AdamW

  | Name    | Type           | Params
-------------------------------------------
0 | encoder | T5EncoderModel | 414 M 
-------------------------------------------
414 M     Trainable params
0         Non-trainable params
414 M     Total params
1,658.814 Total estimated model params size (MB)
Restored all states from the checkpoint at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
Testing dataset size: 5139
Training dataset size: 357252
Validation dataset size: 4833
Testing dataset size: 5139
Training dataset size: 357252
Validation dataset size: 4833
Testing dataset size: 5139
Training dataset size: 357252
Validation dataset size: 4833
Testing dataset size: 5139
Training dataset size: 357252
Validation dataset size: 4833
Testing dataset size: 5139
Training dataset size: 357252
Validation dataset size: 4833
Testing dataset size: 5139
Training dataset size: 357252
Validation dataset size: 4833
Testing dataset size: 5139
Training dataset size: 357252
Validation dataset size: 4833
Testing dataset size: 5139
`Trainer.fit` stopped: `max_epochs=1` reached.
2024-09-22 19:04:45.309 | INFO     | __main__:main:1938 - hit the barrier after training
2024-09-22 19:04:45.438 | INFO     | __main__:main:1938 - hit the barrier after training
2024-09-22 19:04:45.928 | INFO     | __main__:main:1938 - hit the barrier after training
2024-09-22 19:04:46.013 | INFO     | __main__:main:1938 - hit the barrier after training
2024-09-22 19:04:46.013 | INFO     | __main__:main:1944 - Finished progressive training at epoch 1
2024-09-22 19:04:46.013 | INFO     | __main__:main:1944 - Finished progressive training at epoch 1
2024-09-22 19:04:46.013 | INFO     | __main__:main:1944 - Finished progressive training at epoch 1
2024-09-22 19:04:46.013 | INFO     | __main__:main:1944 - Finished progressive training at epoch 1
2024-09-22 19:04:46.014 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:04:46.014 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:04:46.014 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:04:46.014 | INFO     | __main__:find_latest_checkpoint:911 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:04:46.014 | INFO     | __main__:main:1951 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:04:46.014 | INFO     | __main__:main:1951 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:04:46.014 | INFO     | __main__:main:1951 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:04:46.014 | INFO     | __main__:main:1951 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 19:04:50.083 | INFO     | __main__:main:1960 - Testing...
2024-09-22 19:04:50.086 | INFO     | retrieval.main:run_cli:60 - PID: 3370433
2024-09-22 19:04:50.140 | INFO     | __main__:main:1960 - Testing...
2024-09-22 19:04:50.141 | INFO     | retrieval.main:run_cli:60 - PID: 3375132
[rank: 0] Seed set to 3407
2024-09-22 19:04:50.290 | INFO     | retrieval.main:before_instantiate_classes:33 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random
2024-09-22 19:04:50.290 | INFO     | retrieval.main:before_instantiate_classes:34 - Corpus path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
[rank: 2] Seed set to 3407
2024-09-22 19:04:50.333 | INFO     | retrieval.main:before_instantiate_classes:33 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random
2024-09-22 19:04:50.333 | INFO     | retrieval.main:before_instantiate_classes:34 - Corpus path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
2024-09-22 19:04:50.819 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
2024-09-22 19:04:50.848 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
2024-09-22 19:04:50.895 | INFO     | __main__:main:1960 - Testing...
2024-09-22 19:04:50.896 | INFO     | retrieval.main:run_cli:60 - PID: 3375133
2024-09-22 19:04:51.043 | INFO     | __main__:main:1960 - Testing...
2024-09-22 19:04:51.044 | INFO     | retrieval.main:run_cli:60 - PID: 3375131
[rank: 3] Seed set to 3407
2024-09-22 19:04:51.177 | INFO     | retrieval.main:before_instantiate_classes:33 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random
2024-09-22 19:04:51.177 | INFO     | retrieval.main:before_instantiate_classes:34 - Corpus path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
[rank: 1] Seed set to 3407
2024-09-22 19:04:51.290 | INFO     | retrieval.main:before_instantiate_classes:33 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random
2024-09-22 19:04:51.290 | INFO     | retrieval.main:before_instantiate_classes:34 - Corpus path: /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
2024-09-22 19:04:51.801 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
2024-09-22 19:04:51.821 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/corpus.jsonl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python main.py predict --config retrieval/confs/cli_lean4_r ...
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[rank: 0] Seed set to 3407
[rank: 2] Seed set to 3407
[rank: 3] Seed set to 3407
[rank: 1] Seed set to 3407
2024-09-22 19:05:07.342 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_train/cached_data.pkl
2024-09-22 19:05:07.371 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_pred/cached_data.pkl
2024-09-22 19:05:10.480 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_train/cached_data.pkl
2024-09-22 19:05:10.493 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_pred/cached_data.pkl
2024-09-22 19:05:10.623 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_train/cached_data.pkl
2024-09-22 19:05:10.636 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_pred/cached_data.pkl
2024-09-22 19:05:12.607 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_train/cached_data.pkl
2024-09-22 19:05:12.627 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_carleson_bec7808b907190882fa1fa54ce749af297c6cf37/random/cache_pred/cached_data.pkl
Restoring states from the checkpoint path at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_sorries_big_model/merged_with_new_zeta_3_irrational_914712200e463cfc97fe37e929d518dd58806a38_lambda_0.1_epoch=0-Recall@10_val=61.50.ckpt
2024-09-22 19:05:14.093 | INFO     | __main__:main:2484 - An error occurred: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_more_sorries_big_model.py", line 1973, in main
    run_cli(best_model_path, data_path)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 63, in run_cli
    cli = CLI(PremiseRetriever, RetrievalDataModule)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 19, in __init__
    super().__init__(*args,
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 388, in __init__
    self._run_subcommand(self.subcommand)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 679, in _run_subcommand
    fn(**fn_kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 864, in predict
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 903, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 956, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 398, in _restore_modules_and_callbacks
    self.restore_model()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 275, in restore_model
    self.trainer.strategy.load_model_state_dict(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 372, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"], strict=strict)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2215, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Training dataset size: 165200
Testing dataset size: 2371
2024-09-22 19:05:14.127 | INFO     | __main__:main:2484 - An error occurred: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_more_sorries_big_model.py", line 1973, in main
    run_cli(best_model_path, data_path)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 63, in run_cli
    cli = CLI(PremiseRetriever, RetrievalDataModule)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 19, in __init__
    super().__init__(*args,
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 388, in __init__
    self._run_subcommand(self.subcommand)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 679, in _run_subcommand
    fn(**fn_kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 864, in predict
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 903, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 956, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 398, in _restore_modules_and_callbacks
    self.restore_model()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 275, in restore_model
    self.trainer.strategy.load_model_state_dict(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 372, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"], strict=strict)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2215, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Training dataset size: 165200
Testing dataset size: 2371
2024-09-22 19:05:14.573 | INFO     | __main__:main:2484 - An error occurred: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_more_sorries_big_model.py", line 1973, in main
    run_cli(best_model_path, data_path)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 63, in run_cli
    cli = CLI(PremiseRetriever, RetrievalDataModule)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 19, in __init__
    super().__init__(*args,
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 388, in __init__
    self._run_subcommand(self.subcommand)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 679, in _run_subcommand
    fn(**fn_kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 864, in predict
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 903, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 956, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 398, in _restore_modules_and_callbacks
    self.restore_model()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 275, in restore_model
    self.trainer.strategy.load_model_state_dict(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 372, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"], strict=strict)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2215, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Training dataset size: 165200
Testing dataset size: 2371
2024-09-22 19:05:14.655 | INFO     | __main__:main:2484 - An error occurred: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_more_sorries_big_model.py", line 1973, in main
    run_cli(best_model_path, data_path)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 63, in run_cli
    cli = CLI(PremiseRetriever, RetrievalDataModule)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/main.py", line 19, in __init__
    super().__init__(*args,
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 388, in __init__
    self._run_subcommand(self.subcommand)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/cli.py", line 679, in _run_subcommand
    fn(**fn_kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 864, in predict
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 903, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 956, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 398, in _restore_modules_and_callbacks
    self.restore_model()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 275, in restore_model
    self.trainer.strategy.load_model_state_dict(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 372, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"], strict=strict)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2215, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PremiseRetriever:
	Unexpected key(s) in state_dict: "encoder.encoder.block.12.layer.0.SelfAttention.q.weight", "encoder.encoder.block.12.layer.0.SelfAttention.k.weight", "encoder.encoder.block.12.layer.0.SelfAttention.v.weight", "encoder.encoder.block.12.layer.0.SelfAttention.o.weight", "encoder.encoder.block.12.layer.0.layer_norm.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.12.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.12.layer.1.layer_norm.weight", "encoder.encoder.block.13.layer.0.SelfAttention.q.weight", "encoder.encoder.block.13.layer.0.SelfAttention.k.weight", "encoder.encoder.block.13.layer.0.SelfAttention.v.weight", "encoder.encoder.block.13.layer.0.SelfAttention.o.weight", "encoder.encoder.block.13.layer.0.layer_norm.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.13.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.13.layer.1.layer_norm.weight", "encoder.encoder.block.14.layer.0.SelfAttention.q.weight", "encoder.encoder.block.14.layer.0.SelfAttention.k.weight", "encoder.encoder.block.14.layer.0.SelfAttention.v.weight", "encoder.encoder.block.14.layer.0.SelfAttention.o.weight", "encoder.encoder.block.14.layer.0.layer_norm.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.14.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.14.layer.1.layer_norm.weight", "encoder.encoder.block.15.layer.0.SelfAttention.q.weight", "encoder.encoder.block.15.layer.0.SelfAttention.k.weight", "encoder.encoder.block.15.layer.0.SelfAttention.v.weight", "encoder.encoder.block.15.layer.0.SelfAttention.o.weight", "encoder.encoder.block.15.layer.0.layer_norm.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.15.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.15.layer.1.layer_norm.weight", "encoder.encoder.block.16.layer.0.SelfAttention.q.weight", "encoder.encoder.block.16.layer.0.SelfAttention.k.weight", "encoder.encoder.block.16.layer.0.SelfAttention.v.weight", "encoder.encoder.block.16.layer.0.SelfAttention.o.weight", "encoder.encoder.block.16.layer.0.layer_norm.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.16.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.16.layer.1.layer_norm.weight", "encoder.encoder.block.17.layer.0.SelfAttention.q.weight", "encoder.encoder.block.17.layer.0.SelfAttention.k.weight", "encoder.encoder.block.17.layer.0.SelfAttention.v.weight", "encoder.encoder.block.17.layer.0.SelfAttention.o.weight", "encoder.encoder.block.17.layer.0.layer_norm.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_0.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wi_1.weight", "encoder.encoder.block.17.layer.1.DenseReluDense.wo.weight", "encoder.encoder.block.17.layer.1.layer_norm.weight". 
	size mismatch for encoder.shared.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.embed_tokens.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: copying a param with shape torch.Size([32, 12]) from checkpoint, the shape in current model is torch.Size([32, 6]).
	size mismatch for encoder.encoder.block.0.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.0.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.0.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.1.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.1.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.1.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.2.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.2.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.2.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.2.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.3.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.3.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.3.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.4.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.4.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.4.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.4.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.5.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.5.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.5.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.6.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.6.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.6.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.7.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.7.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.7.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.7.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.8.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.8.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.8.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.9.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.9.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.9.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.9.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.10.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.10.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.10.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.q.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.k.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.v.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([384, 1472]).
	size mismatch for encoder.encoder.block.11.layer.0.SelfAttention.o.weight: copying a param with shape torch.Size([1536, 768]) from checkpoint, the shape in current model is torch.Size([1472, 384]).
	size mismatch for encoder.encoder.block.11.layer.0.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_0.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight: copying a param with shape torch.Size([3968, 1536]) from checkpoint, the shape in current model is torch.Size([3584, 1472]).
	size mismatch for encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight: copying a param with shape torch.Size([1536, 3968]) from checkpoint, the shape in current model is torch.Size([1472, 3584]).
	size mismatch for encoder.encoder.block.11.layer.1.layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
	size mismatch for encoder.encoder.final_layer_norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([1472]).
Training dataset size: 165200
Testing dataset size: 2371
[rank0]:[W922 19:05:26.499192603 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
