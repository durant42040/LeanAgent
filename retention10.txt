██████████████████████████████████████▉     | 3758/4054 [04:59<00:22, 13.27i 93%|█████████████████████████████
██████████████████████████████████▉     | 3760/4054 [05:00<00:23, 12.39i 93%|█████████████████████████████████
███████████████████████████████     | 3763/4054 [05:00<00:20, 13.94i 93%|█████████████████████████████████████
███████████████████████████     | 3765/4054 [05:00<00:23, 12.43i 93%|█████████████████████████████████████████
███████████████████████     | 3767/4054 [05:00<00:24, 11.84i 93%|█████████████████████████████████████████████
███████████████████▏    | 3769/4054 [05:00<00:24, 11.73i 93%|█████████████████████████████████████████████████
███████████████▏    | 3771/4054 [05:01<00:27, 10.44i 93%|█████████████████████████████████████████████████████
███████████▏    | 3773/4054 [05:01<00:28,  9.86i 93%|█████████████████████████████████████████████████████████
███████▎    | 3775/4054 [05:01<00:24, 11.31i 93%|█████████████████████████████████████████████████████████████
███▎    | 3777/4054 [05:01<00:25, 10.96i 93%|████████████████████████████████████████████████████████████████▎
    | 3779/4054 [05:01<00:26, 10.54i 93%|████████████████████████████████████████████████████████████████▎
| 3781/4054 [05:02<00:23, 11.46i 93%|████████████████████████████████████████████████████████████████▍    | 37
83/4054 [05:02<00:24, 11.20i 93%|████████████████████████████████████████████████████████████████▍    | 3785/4
054 [05:02<00:23, 11.43i 93%|████████████████████████████████████████████████████████████████▍    | 3787/4054
[05:02<00:20, 12.88i 93%|████████████████████████████████████████████████████████████████▍    | 3789/4054 [05:
02<00:23, 11.19i 94%|████████████████████████████████████████████████████████████████▌    | 3791/4054 [05:02<0
0:26, 10.03i 94%|████████████████████████████████████████████████████████████████▌    | 3793/4054 [05:03<00:26
, 10.02i 94%|████████████████████████████████████████████████████████████████▌    | 3795/4054 [05:03<00:26,  9
.70i 94%|████████████████████████████████████████████████████████████████▋    | 3797/4054 [05:03<00:28,  9.15i
 94%|████████████████████████████████████████████████████████████████▋    | 3798/4054 [05:03<00:28,  8.94i 94%
|████████████████████████████████████████████████████████████████▋    | 3799/4054 [05:03<00:29,  8.74i 94%|███
█████████████████████████████████████████████████████████████▋    | 3801/4054 [05:04<00:27,  9.27i 94%|███████
█████████████████████████████████████████████████████████▋    | 3802/4054 [05:04<00:28,  8.92i 94%|███████████
█████████████████████████████████████████████████████▋    | 3804/4054 [05:04<00:27,  8.99i 94%|███████████████
█████████████████████████████████████████████████▊    | 3806/4054 [05:04<00:25,  9.83i 94%|███████████████████
█████████████████████████████████████████████▊    | 3807/4054 [05:04<00:26,  9.42i 94%|███████████████████████
█████████████████████████████████████████▊    | 3808/4054 [05:04<00:27,  9.08i 94%|███████████████████████████
█████████████████████████████████████▊    | 3809/4054 [05:04<00:27,  8.81i 94%|███████████████████████████████
█████████████████████████████████▊    | 3811/4054 [05:05<00:27,  8.87i 94%|███████████████████████████████████
█████████████████████████████▉    | 3812/4054 [05:05<00:27,  8.66i 94%|███████████████████████████████████████
█████████████████████████▉    | 3814/4054 [05:05<00:25,  9.55i 94%|███████████████████████████████████████████
█████████████████████▉    | 3815/4054 [05:05<00:26,  9.18i 94%|███████████████████████████████████████████████
█████████████████▉    | 3817/4054 [05:05<00:23,  9.89i 94%|███████████████████████████████████████████████████
█████████████▉    | 3818/4054 [05:05<00:25,  9.34i 94%|███████████████████████████████████████████████████████
██████████    | 3820/4054 [05:06<00:20, 11.60i 94%|███████████████████████████████████████████████████████████
██████    | 3822/4054 [05:06<00:19, 11.76i 94%|███████████████████████████████████████████████████████████████
██    | 3824/4054 [05:06<00:20, 11.43i 94%|█████████████████████████████████████████████████████████████████
  | 3826/4054 [05:06<00:20, 11.14i 94%|█████████████████████████████████████████████████████████████████▏   |
3828/4054 [05:06<00:22,  9.94i 94%|█████████████████████████████████████████████████████████████████▏   | 3830
/4054 [05:07<00:23,  9.70i 95%|█████████████████████████████████████████████████████████████████▏   | 3832/405
4 [05:07<00:24,  9.14i 95%|█████████████████████████████████████████████████████████████████▏   | 3833/4054 [0
5:07<00:24,  8.92i 95%|█████████████████████████████████████████████████████████████████▎   | 3834/4054 [05:07
<00:24,  8.87i 95%|█████████████████████████████████████████████████████████████████▎   | 3835/4054 [05:07<00:
25,  8.68i 95%|█████████████████████████████████████████████████████████████████▎   | 3836/4054 [05:07<00:25,
 8.53i 95%|█████████████████████████████████████████████████████████████████▎   | 3838/4054 [05:07<00:22,  9.4
7i 95%|█████████████████████████████████████████████████████████████████▎   | 3841/4054 [05:08<00:16, 13.21i 9
5%|█████████████████████████████████████████████████████████████████▍   | 3843/4054 [05:08<00:18, 11.60i 95%|█
████████████████████████████████████████████████████████████████▍   | 3845/4054 [05:08<00:18, 11.04i 95%|█████
████████████████████████████████████████████████████████████▍   | 3847/4054 [05:08<00:18, 11.06i 95%|█████████
████████████████████████████████████████████████████████▌   | 3849/4054 [05:08<00:16, 12.31i 95%|█████████████
████████████████████████████████████████████████████▌   | 3851/4054 [05:08<00:15, 13.33i 95%|█████████████████
████████████████████████████████████████████████▌   | 3853/4054 [05:09<00:18, 11.14i 95%|█████████████████████
████████████████████████████████████████████▌   | 3855/4054 [05:09<00:19, 10.10i 95%|█████████████████████████
████████████████████████████████████████▋   | 3857/4054 [05:09<00:20,  9.38i 95%|█████████████████████████████
████████████████████████████████████▋   | 3859/4054 [05:09<00:20,  9.49i 95%|█████████████████████████████████
████████████████████████████████▋   | 3861/4054 [05:10<00:19, 10.11i 95%|█████████████████████████████████████
████████████████████████████▋   | 3863/4054 [05:10<00:20,  9.40i 95%|█████████████████████████████████████████
████████████████████████▊   | 3864/4054 [05:10<00:20,  9.08i 95%|█████████████████████████████████████████████
████████████████████▊   | 3865/4054 [05:10<00:21,  8.86i 95%|█████████████████████████████████████████████████
████████████████▊   | 3866/4054 [05:10<00:21,  8.74i 95%|█████████████████████████████████████████████████████
████████████▊   | 3867/4054 [05:10<00:21,  8.57i 95%|█████████████████████████████████████████████████████████
████████▊   | 3868/4054 [05:10<00:22,  8.44i 95%|█████████████████████████████████████████████████████████████
████▊   | 3869/4054 [05:11<00:22,  8.34i 95%|█████████████████████████████████████████████████████████████████
▊   | 3870/4054 [05:11<00:22,  8.26i 95%|█████████████████████████████████████████████████████████████████▉
| 3871/4054 [05:11<00:22,  8.20i 96%|█████████████████████████████████████████████████████████████████▉   | 38
72/4054 [05:11<00:22,  8.17i 96%|█████████████████████████████████████████████████████████████████▉   | 3873/4
054 [05:11<00:22,  8.14i 96%|█████████████████████████████████████████████████████████████████▉   | 3874/4054
[05:11<00:22,  8.16i 96%|█████████████████████████████████████████████████████████████████▉   | 3875/4054 [05:
11<00:20,  8.58i 96%|█████████████████████████████████████████████████████████████████▉   | 3876/4054 [05:11<0
0:20,  8.82i 96%|██████████████████████████████████████████████████████████████████   | 3878/4054 [05:12<00:17
,  9.86i 96%|██████████████████████████████████████████████████████████████████   | 3879/4054 [05:12<00:18,  9
.36i 96%|██████████████████████████████████████████████████████████████████   | 3880/4054 [05:12<00:19,  9.03i
 96%|██████████████████████████████████████████████████████████████████   | 3881/4054 [05:12<00:19,  8.74i 96%
|██████████████████████████████████████████████████████████████████   | 3882/4054 [05:12<00:20,  8.53i 96%|███
███████████████████████████████████████████████████████████████   | 3883/4054 [05:12<00:20,  8.45i 96%|███████
███████████████████████████████████████████████████████████   | 3885/4054 [05:12<00:16, 10.02i 96%|███████████
███████████████████████████████████████████████████████▏  | 3886/4054 [05:12<00:17,  9.45i 96%|███████████████
███████████████████████████████████████████████████▏  | 3888/4054 [05:13<00:16, 10.10i 96%|███████████████████
███████████████████████████████████████████████▏  | 3889/4054 [05:13<00:16,  9.86i 96%|███████████████████████
███████████████████████████████████████████▏  | 3890/4054 [05:13<00:17,  9.35i 96%|███████████████████████████
███████████████████████████████████████▏  | 3891/4054 [05:13<00:18,  8.97i 96%|███████████████████████████████
███████████████████████████████████▎  | 3893/4054 [05:13<00:17,  8.96i 96%|███████████████████████████████████
███████████████████████████████▎  | 3895/4054 [05:13<00:14, 10.78i 96%|███████████████████████████████████████
███████████████████████████▎  | 3897/4054 [05:13<00:13, 11.36i 96%|███████████████████████████████████████████
███████████████████████▎  | 3899/4054 [05:14<00:14, 10.43i 96%|███████████████████████████████████████████████
███████████████████▍  | 3901/4054 [05:14<00:15,  9.75i 96%|███████████████████████████████████████████████████
███████████████▍  | 3903/4054 [05:14<00:16,  9.15i 96%|███████████████████████████████████████████████████████
███████████▍  | 3905/4054 [05:14<00:15,  9.67i 96%|███████████████████████████████████████████████████████████
███████▍  | 3906/4054 [05:14<00:15,  9.34i 96%|███████████████████████████████████████████████████████████████
███▍  | 3907/4054 [05:15<00:16,  9.05i 96%|██████████████████████████████████████████████████████████████████▌
  | 3908/4054 [05:15<00:16,  8.96i 96%|██████████████████████████████████████████████████████████████████▌  |
3910/4054 [05:15<00:15,  9.39i 96%|██████████████████████████████████████████████████████████████████▌  | 3911
/4054 [05:15<00:15,  9.19i 97%|██████████████████████████████████████████████████████████████████▌  | 3913/405
4 [05:15<00:14,  9.85i 97%|██████████████████████████████████████████████████████████████████▌  | 3914/4054 [0
5:15<00:14,  9.41i 97%|██████████████████████████████████████████████████████████████████▋  | 3915/4054 [05:15
<00:14,  9.31i 97%|██████████████████████████████████████████████████████████████████▋  | 3916/4054 [05:16<00:
14,  9.33i 97%|██████████████████████████████████████████████████████████████████▋  | 3917/4054 [05:16<00:15,
 9.06i 97%|██████████████████████████████████████████████████████████████████▋  | 3919/4054 [05:16<00:14,  9.3
8i 97%|██████████████████████████████████████████████████████████████████▋  | 3920/4054 [05:16<00:14,  9.18i 9
7%|██████████████████████████████████████████████████████████████████▊  | 3922/4054 [05:16<00:14,  9.39i 97%|█
█████████████████████████████████████████████████████████████████▊  | 3923/4054 [05:16<00:14,  9.05i 97%|█████
█████████████████████████████████████████████████████████████▊  | 3925/4054 [05:17<00:13,  9.25i 97%|█████████
█████████████████████████████████████████████████████████▊  | 3927/4054 [05:17<00:13,  9.76i 97%|█████████████
█████████████████████████████████████████████████████▊  | 3928/4054 [05:17<00:13,  9.36i 97%|█████████████████
█████████████████████████████████████████████████▊  | 3929/4054 [05:17<00:13,  9.03i 97%|█████████████████████
█████████████████████████████████████████████▉  | 3931/4054 [05:17<00:12,  9.83i 97%|█████████████████████████
█████████████████████████████████████████▉  | 3934/4054 [05:17<00:10, 11.39i 97%|█████████████████████████████
█████████████████████████████████████▉  | 3936/4054 [05:17<00:09, 11.85i 97%|█████████████████████████████████
██████████████████████████████████  | 3938/4054 [05:18<00:11, 10.39i 97%|█████████████████████████████████████
██████████████████████████████  | 3940/4054 [05:18<00:11,  9.87i 97%|█████████████████████████████████████████
██████████████████████████  | 3942/4054 [05:18<00:10, 10.33i 97%|█████████████████████████████████████████████
██████████████████████▏ | 3944/4054 [05:18<00:10, 10.46i 97%|█████████████████████████████████████████████████
██████████████████▏ | 3946/4054 [05:19<00:10, 10.13i 97%|█████████████████████████████████████████████████████
██████████████▏ | 3948/4054 [05:19<00:11,  9.40i 97%|█████████████████████████████████████████████████████████
██████████▏ | 3950/4054 [05:19<00:10,  9.59i 97%|█████████████████████████████████████████████████████████████
██████▏ | 3951/4054 [05:19<00:11,  9.27i 97%|█████████████████████████████████████████████████████████████████
██▎ | 3952/4054 [05:19<00:11,  9.00i 98%|███████████████████████████████████████████████████████████████████▎
| 3953/4054 [05:19<00:11,  8.78i 98%|███████████████████████████████████████████████████████████████████▎ | 39
54/4054 [05:19<00:11,  8.90i 98%|███████████████████████████████████████████████████████████████████▎ | 3955/4
054 [05:20<00:11,  8.68i 98%|███████████████████████████████████████████████████████████████████▎ | 3956/4054
[05:20<00:11,  8.50i 98%|███████████████████████████████████████████████████████████████████▎ | 3958/4054 [05:
20<00:10,  9.02i 98%|███████████████████████████████████████████████████████████████████▍ | 3959/4054 [05:20<0
0:10,  8.77i 98%|███████████████████████████████████████████████████████████████████▍ | 3961/4054 [05:20<00:09
, 10.13i 98%|███████████████████████████████████████████████████████████████████▍ | 3963/4054 [05:20<00:08, 10
.30i 98%|███████████████████████████████████████████████████████████████████▍ | 3965/4054 [05:21<00:09,  9.41i
 98%|███████████████████████████████████████████████████████████████████▌ | 3966/4054 [05:21<00:09,  9.14i 98%
|███████████████████████████████████████████████████████████████████▌ | 3967/4054 [05:21<00:09,  8.88i 98%|███
████████████████████████████████████████████████████████████████▌ | 3968/4054 [05:21<00:09,  8.92i 98%|███████
████████████████████████████████████████████████████████████▌ | 3969/4054 [05:21<00:09,  8.67i 98%|███████████
████████████████████████████████████████████████████████▌ | 3971/4054 [05:21<00:08,  9.39i 98%|███████████████
████████████████████████████████████████████████████▌ | 3972/4054 [05:21<00:09,  9.05i 98%|███████████████████
████████████████████████████████████████████████▌ | 3973/4054 [05:22<00:09,  8.79i 98%|███████████████████████
████████████████████████████████████████████▋ | 3975/4054 [05:22<00:07, 11.08i 98%|███████████████████████████
████████████████████████████████████████▋ | 3977/4054 [05:22<00:07, 10.13i 98%|███████████████████████████████
████████████████████████████████████▋ | 3979/4054 [05:22<00:07, 10.06i 98%|███████████████████████████████████
████████████████████████████████▊ | 3981/4054 [05:22<00:07,  9.31i 98%|███████████████████████████████████████
████████████████████████████▊ | 3982/4054 [05:22<00:07,  9.33i 98%|███████████████████████████████████████████
████████████████████████▊ | 3984/4054 [05:23<00:07,  9.54i 98%|███████████████████████████████████████████████
████████████████████▊ | 3985/4054 [05:23<00:07,  9.20i 98%|███████████████████████████████████████████████████
████████████████▊ | 3986/4054 [05:23<00:07,  9.36i 98%|███████████████████████████████████████████████████████
████████████▊ | 3987/4054 [05:23<00:07,  9.22i 98%|███████████████████████████████████████████████████████████
████████▉ | 3988/4054 [05:23<00:07,  8.89i 98%|███████████████████████████████████████████████████████████████
████▉ | 3989/4054 [05:23<00:07,  8.64i 98%|███████████████████████████████████████████████████████████████████
▉ | 3990/4054 [05:23<00:07,  8.48i 98%|███████████████████████████████████████████████████████████████████▉ |
3992/4054 [05:24<00:06,  9.00i 99%|███████████████████████████████████████████████████████████████████▉ | 3995
/4054 [05:24<00:04, 12.69i 99%|████████████████████████████████████████████████████████████████████ | 3997/405
4 [05:24<00:04, 14.06i 99%|████████████████████████████████████████████████████████████████████ | 4000/4054 [0
5:24<00:03, 16.07i 99%|████████████████████████████████████████████████████████████████████ | 4002/4054 [05:24
<00:03, 14.34i 99%|████████████████████████████████████████████████████████████████████▏| 4004/4054 [05:24<00:
04, 11.75i 99%|████████████████████████████████████████████████████████████████████▏| 4006/4054 [05:25<00:04,
10.66i 99%|████████████████████████████████████████████████████████████████████▏| 4008/4054 [05:25<00:04, 10.8
4i 99%|████████████████████████████████████████████████████████████████████▎| 4010/4054 [05:25<00:04, 10.40i 9
9%|████████████████████████████████████████████████████████████████████▎| 4012/4054 [05:25<00:03, 10.81i 99%|█
███████████████████████████████████████████████████████████████████▎| 4014/4054 [05:25<00:03, 10.14i 99%|█████
███████████████████████████████████████████████████████████████▎| 4016/4054 [05:26<00:03, 10.23i 99%|█████████
███████████████████████████████████████████████████████████▍| 4018/4054 [05:26<00:03,  9.60i 99%|█████████████
███████████████████████████████████████████████████████▍| 4019/4054 [05:26<00:03,  9.30i 99%|█████████████████
███████████████████████████████████████████████████▍| 4020/4054 [05:26<00:03,  9.03i 99%|█████████████████████
███████████████████████████████████████████████▍| 4021/4054 [05:26<00:03,  8.79i 99%|█████████████████████████
███████████████████████████████████████████▍| 4022/4054 [05:26<00:03,  8.61i 99%|█████████████████████████████
███████████████████████████████████████▍| 4023/4054 [05:26<00:03,  8.48i 99%|█████████████████████████████████
███████████████████████████████████▍| 4024/4054 [05:27<00:03,  8.35i 99%|█████████████████████████████████████
███████████████████████████████▌| 4025/4054 [05:27<00:03,  8.26i 99%|█████████████████████████████████████████
███████████████████████████▌| 4026/4054 [05:27<00:03,  8.21i 99%|█████████████████████████████████████████████
███████████████████████▌| 4027/4054 [05:27<00:03,  8.18i 99%|█████████████████████████████████████████████████
███████████████████▌| 4028/4054 [05:27<00:03,  8.14i 99%|█████████████████████████████████████████████████████
███████████████▌| 4029/4054 [05:27<00:03,  8.12i 99%|█████████████████████████████████████████████████████████
███████████▌| 4030/4054 [05:27<00:02,  8.11i 99%|█████████████████████████████████████████████████████████████
███████▌| 4031/4054 [05:27<00:02,  8.09i 99%|█████████████████████████████████████████████████████████████████
███▋| 4032/4054 [05:28<00:02,  8.08i 99%|████████████████████████████████████████████████████████████████████▋
| 4033/4054 [05:28<00:02,  8.06i100%|████████████████████████████████████████████████████████████████████▋| 40
34/4054 [05:28<00:02,  8.07i100%|████████████████████████████████████████████████████████████████████▋| 4035/4
054 [05:28<00:02,  8.06i100%|████████████████████████████████████████████████████████████████████▋| 4036/4054
[05:28<00:02,  8.07i100%|████████████████████████████████████████████████████████████████████▋| 4037/4054 [05:
28<00:02,  8.07i100%|████████████████████████████████████████████████████████████████████▋| 4038/4054 [05:28<0
0:01,  8.06i100%|████████████████████████████████████████████████████████████████████▋| 4039/4054 [05:28<00:01
,  8.07i100%|████████████████████████████████████████████████████████████████████▊| 4040/4054 [05:29<00:01,  8
.07i100%|████████████████████████████████████████████████████████████████████▊| 4041/4054 [05:29<00:01,  8.05i
100%|████████████████████████████████████████████████████████████████████▊| 4042/4054 [05:29<00:01,  8.07i100%
|████████████████████████████████████████████████████████████████████▊| 4043/4054 [05:29<00:01,  8.07i100%|███
█████████████████████████████████████████████████████████████████▊| 4046/4054 [05:29<00:00, 12.03i100%|███████
█████████████████████████████████████████████████████████████▉| 4048/4054 [05:29<00:00, 11.88i100%|███████████
█████████████████████████████████████████████████████████▉| 4050/4054 [05:29<00:00, 10.28i100%|███████████████
█████████████████████████████████████████████████████▉| 4052/4054 [05:30<00:00,  9.42i100%|███████████████████
█████████████████████████████████████████████████▉| 4053/4054 [05:30<00:00,  9.14i100%|███████████████████████
██████████████████████████████████████████████| 4054/4054 [05:30<00:00,  8.88i100%|███████████████████████████
██████████████████████████████████████████| 4054/4054 [05:30<00:00, 12.27it/s]
2024-09-21 22:17:47.718 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 22:17:47.719 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 22:17:51,297 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=311267) [2024-09-21 22:18:26,436] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=311267) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=311267)   return torch.load(io.BytesIO(b))
(pid=311458) [2024-09-21 22:18:38,051] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=311458) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=311458)   return torch.load(io.BytesIO(b))
(pid=311627) [2024-09-21 22:18:49,211] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 22:18:52.841 | INFO     | __main__:prove_sorry_theorems:862 - Found 22 proved sorry theorems to re-
prove
Processing theorems from lecopivo/SciLean:   0%|                              | 0/22 [00:00<?, ?theorem/s]2024
-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.ite_pull_
ennreal_toReal
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:885 - Position: (144, 1)
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.Distr
ibution.action_iteD
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:885 - Position: (261, 1)
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for Function.Bije
ctive.Equiv.toFun.arg_a0.Bijective_rule
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:885 - Position: (241, 1)
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.CDiff
erentiableAt.comp_rule
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:885 - Position: (57, 1)
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for IsLinearMap.i
sLinearMap_apply
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:885 - Position: (40, 1)
2024-09-21 22:18:52.842 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.ContC
DiffAt.id_rule
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:885 - Position: (41, 1)
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.ContC
DiffAt.comp_rule
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:885 - Position: (49, 1)
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.ContC
DiffMapFD.zero_apply
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:885 - Position: (141, 1)
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.scala
r_max_zero_one
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:885 - Position: (306, 1)
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.scala
r_min_zero_one
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:885 - Position: (312, 1)
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.ite_p
ull_measureOf
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:885 - Position: (138, 1)
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.Measu
re.prod_volume
2024-09-21 22:18:52.843 | INFO     | __main__:prove_sorry_theorems:885 - Position: (38, 1)
2024-09-21 22:18:52.843 | INFO     | prover.proof_search_all_sorries:search_unordered:513 - Distributed
(ProverActor pid=311267) 2024-09-21 22:18:52.852 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/CDifferentiable.lean'), full_name='SciLea
n.CDifferentiableAt.comp_rule')
(ProverActor pid=311458) 2024-09-21 22:18:52.851 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/Bijective.lean'), full_name='Function.Bij
ective.Equiv.toFun.arg_a0.Bijective_rule')
(ProverActor pid=311627) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=311627)   return torch.load(io.BytesIO(b))
(pid=312245) [2024-09-21 22:19:00,153] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=311627) 2024-09-21 22:19:02.307 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Distribution/Basic.lean'), full_name='SciLean.Distribution.act
ion_iteD')
(ProverActor pid=312245) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=312245)   return torch.load(io.BytesIO(b))
(ProverActor pid=312245) 2024-09-21 22:19:13.839 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Integral/Common.lean'), full_name='SciLean.ite_pull_ennreal_to
Real')
(ProverActor pid=312245) 2024-09-21 22:19:50.660 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311627) 2024-09-21 22:19:57.118 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof! [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 t
o disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logg
ing.html#log-deduplication for more options.)
(ProverActor pid=312245) 2024-09-21 22:19:58.468 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Integral/Common.lean'), full_name='SciLean.ite_p
ull_ennreal_toReal'), status=<Status.PROVED: 'Proved'>, proof=['split_ifs <;> rfl'], actor_time=2.167223444906
9947, environment_time=0.01817344408482313, total_time=3.1857680880930275, num_total_nodes=2, num_searched_nod
es=1)
(ProverActor pid=312245) 2024-09-21 22:19:58.473 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/IsLinearMap.lean'), full_name='IsLinearMa
p.isLinearMap_apply')
(ProverActor pid=311267) 2024-09-21 22:20:01.440 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/CDifferentiable.lean'), ful
l_name='SciLean.CDifferentiableAt.comp_rule'), status=<Status.PROVED: 'Proved'>, proof=['rw [CDifferentiableAt
] at *', 'aesop'], actor_time=3.5043732500635087, environment_time=2.6807743087410927, total_time=7.1877340371
72049, num_total_nodes=76, num_searched_nodes=2)
(ProverActor pid=311267) 2024-09-21 22:20:01.446 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/ContCDiff.lean'), full_name='SciLean.Cont
CDiffAt.id_rule')
(ProverActor pid=311627) 2024-09-21 22:20:06.347 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Distribution/Basic.lean'), full_name='SciLean.Di
stribution.action_iteD'), status=<Status.PROVED: 'Proved'>, proof=['aesop'], actor_time=2.1102287750691175, en
vironment_time=0.8003915818408132, total_time=3.911683193175122, num_total_nodes=18, num_searched_nodes=1)
(ProverActor pid=311627) 2024-09-21 22:20:06.354 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/ContCDiff.lean'), full_name='SciLean.Cont
CDiffAt.comp_rule')
(ProverActor pid=311458) 2024-09-21 22:20:06.490 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=312245) 2024-09-21 22:20:45.149 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311267) 2024-09-21 22:20:45.540 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311267) 2024-09-21 22:20:55.765 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/ContCDiff.lean'), full_name
='SciLean.ContCDiffAt.id_rule'), status=<Status.PROVED: 'Proved'>, proof=['rw [ContCDiffAt]', 'tauto'], actor_
time=2.7625211679842323, environment_time=0.7402021607849747, total_time=4.504978999961168, num_total_nodes=84
, num_searched_nodes=2)
(ProverActor pid=311267) 2024-09-21 22:20:55.770 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionSpaces/ContCDiffMapFD.lean'), full_name='SciLean.ContC
DiffMapFD.zero_apply')
(ProverActor pid=312245) 2024-09-21 22:20:56.817 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/IsLinearMap.lean'), full_na
me='IsLinearMap.isLinearMap_apply'), status=<Status.PROVED: 'Proved'>, proof=['constructor', 'all_goals aesop'
], actor_time=3.9114431261550635, environment_time=1.091271079145372, total_time=6.004807487828657, num_total_
nodes=42, num_searched_nodes=2)
(ProverActor pid=312245) 2024-09-21 22:20:56.821 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Objects/Scalar.lean'), full_name='SciLean.scalar_max_zero_one'
)
(ProverActor pid=311627) 2024-09-21 22:20:58.611 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311627) 2024-09-21 22:21:08.562 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/ContCDiff.lean'), full_name
='SciLean.ContCDiffAt.comp_rule'), status=<Status.PROVED: 'Proved'>, proof=['rw [ContCDiffAt] at *', 'aesop'],
 actor_time=3.0898160377983004, environment_time=3.3990038610063493, total_time=7.491624476853758, num_total_n
odes=67, num_searched_nodes=2)
(ProverActor pid=311627) 2024-09-21 22:21:08.566 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Objects/Scalar.lean'), full_name='SciLean.scalar_min_zero_one'
)
(ProverActor pid=311267) 2024-09-21 22:21:43.242 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311458) 2024-09-21 22:21:48.602 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/Bijective.lean'), full_name
='Function.Bijective.Equiv.toFun.arg_a0.Bijective_rule'), status=<Status.PROVED: 'Proved'>, proof=['haveI := C
lassical.decEq Z', 'exact f.bijective.comp hf'], actor_time=16.769963479368016, environment_time=2.88679556222
63253, total_time=20.667642088141292, num_total_nodes=337, num_searched_nodes=8)
(ProverActor pid=311458) 2024-09-21 22:21:48.609 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Integral/Common.lean'), full_name='SciLean.ite_pull_measureOf'
)
(ProverActor pid=311267) 2024-09-21 22:21:50.628 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionSpaces/ContCDiffMapFD.lean'), full_name=
'SciLean.ContCDiffMapFD.zero_apply'), status=<Status.PROVED: 'Proved'>, proof=['rfl'], actor_time=1.7841170420
870185, environment_time=0.004734613001346588, total_time=2.789150512078777, num_total_nodes=2, num_searched_n
odes=1)
(ProverActor pid=311267) 2024-09-21 22:21:50.632 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Integral/Common.lean'), full_name='SciLean.Measure.prod_volume
')
(ProverActor pid=312245) 2024-09-21 22:21:56.545 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311627) 2024-09-21 22:22:11.788 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Objects/Scalar.lean'), full_name='SciLean.scalar
_min_zero_one'), status=<Status.PROVED: 'Proved'>, proof=['rw [min_comm]', 'simp'], actor_time=5.5828879990149
29, environment_time=4.8969826637767255, total_time=11.484556023962796, num_total_nodes=116, num_searched_node
s=4)
(ProverActor pid=311627) 2024-09-21 22:21:57.753 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311458) 2024-09-21 22:22:32.741 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311458) 2024-09-21 22:22:41.814 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Integral/Common.lean'), full_name='SciLean.ite_p
ull_measureOf'), status=<Status.PROVED: 'Proved'>, proof=['split_ifs <;> rfl'], actor_time=2.1664490059483796,
 environment_time=0.021468262188136578, total_time=3.1882273950614035, num_total_nodes=2, num_searched_nodes=1
)
(ProverActor pid=311267) 2024-09-21 22:22:35.155 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311267) 2024-09-21 22:22:43.915 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Integral/Common.lean'), full_name='SciLean.Measu
re.prod_volume'), status=<Status.PROVED: 'Proved'>, proof=['rfl'], actor_time=4.082840695977211, environment_t
ime=0.0032182568684220314, total_time=5.086329650133848, num_total_nodes=2, num_searched_nodes=1)
2024-09-21 22:22:48.505 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.ite_pull_enn
real_toReal
2024-09-21 22:22:48.507 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.ite_p
ull_ennreal_toReal
2024-09-21 22:22:48.507 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.CDifferentia
bleAt.comp_rule
(ProverActor pid=312245) 2024-09-21 22:22:48.502 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Objects/Scalar.lean'), full_name='SciLean.scalar
_max_zero_one'), status=<Status.PROVED: 'Proved'>, proof=['rw [max_comm]', 'simp'], actor_time=10.443075564224
273, environment_time=7.521976437652484, total_time=18.973750807112083, num_total_nodes=174, num_searched_node
s=6)
2024-09-21 22:22:48.509 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.CDiff
erentiableAt.comp_rule
2024-09-21 22:22:48.509 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.Distribution
.action_iteD
2024-09-21 22:22:48.510 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.Distr
ibution.action_iteD
2024-09-21 22:22:48.510 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.ContCDiffAt.
id_rule
2024-09-21 22:22:48.511 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.ContC
DiffAt.id_rule
2024-09-21 22:22:48.511 | INFO     | __main__:process_theorem_batch:801 - Proof found for IsLinearMap.isLinear
Map_apply
2024-09-21 22:22:48.512 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: IsLinearMap.i
sLinearMap_apply
2024-09-21 22:22:48.512 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.ContCDiffAt.
comp_rule
2024-09-21 22:22:48.513 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.ContC
DiffAt.comp_rule
2024-09-21 22:22:48.513 | INFO     | __main__:process_theorem_batch:801 - Proof found for Function.Bijective.E
quiv.toFun.arg_a0.Bijective_rule
2024-09-21 22:22:48.514 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: Function.Bije
ctive.Equiv.toFun.arg_a0.Bijective_rule
2024-09-21 22:22:48.514 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.ContCDiffMap
FD.zero_apply
2024-09-21 22:22:48.515 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.ContC
DiffMapFD.zero_apply
2024-09-21 22:22:48.515 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.scalar_min_z
ero_one
2024-09-21 22:22:48.516 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.scala
r_min_zero_one
2024-09-21 22:22:48.516 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.ite_pull_mea
sureOf
2024-09-21 22:22:48.516 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.ite_p
ull_measureOf
2024-09-21 22:22:48.517 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.Measure.prod
_volume
2024-09-21 22:22:48.517 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.Measu
re.prod_volume
2024-09-21 22:22:48.518 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.scalar_max_z
ero_one
2024-09-21 22:22:48.518 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.scala
r_max_zero_one
Processing theorems from lecopivo/SciLean:  55%|███████████▍         | 12/22 [03:55<03:16, 19.64s/theorem]2024
-09-21 22:22:48.519 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.ContCDiff
Map.zero_apply
2024-09-21 22:22:48.519 | INFO     | __main__:prove_sorry_theorems:885 - Position: (128, 1)
2024-09-21 22:22:48.519 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for Function.Bije
ctive.Prod.mk.arg_fstsnd.Bijective_rule_simple
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:885 - Position: (61, 1)
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.scala
r_div_one
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:885 - Position: (294, 1)
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for IsAffineMap.I
sAffineMap_apply
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:885 - Position: (45, 1)
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.norm₂
_scalar
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:885 - Position: (64, 1)
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.Smoot
hLinearMap.zero_apply
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:885 - Position: (121, 1)
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.re_fl
oat
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:885 - Position: (222, 1)
2024-09-21 22:22:48.520 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for Function.invF
un.id_rule
2024-09-21 22:22:48.521 | INFO     | __main__:prove_sorry_theorems:885 - Position: (25, 1)
2024-09-21 22:22:48.521 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for IsLinearMap.i
sLinearMap_const_zero
2024-09-21 22:22:48.521 | INFO     | __main__:prove_sorry_theorems:885 - Position: (30, 1)
2024-09-21 22:22:48.521 | INFO     | __main__:prove_sorry_theorems:884 - Searching for proof for SciLean.CDiff
erentiableAt.id_rule
2024-09-21 22:22:48.521 | INFO     | __main__:prove_sorry_theorems:885 - Position: (36, 1)
Processing theorems from lecopivo/SciLean: 100%|█████████████████████| 22/22 [03:55<00:00, 10.71s/theorem]
2024-09-21 22:22:48.521 | INFO     | prover.proof_search_all_sorries:search_unordered:513 - Distributed
(ProverActor pid=311267) 2024-09-21 22:22:48.526 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/Bijective.lean'), full_name='Function.Bij
ective.Prod.mk.arg_fstsnd.Bijective_rule_simple')
(ProverActor pid=311458) 2024-09-21 22:22:48.527 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Objects/Scalar.lean'), full_name='SciLean.scalar_div_one')
(ProverActor pid=311627) 2024-09-21 22:22:48.528 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/IsAffineMap.lean'), full_name='IsAffineMa
p.IsAffineMap_apply')
(ProverActor pid=312245) 2024-09-21 22:22:48.524 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionSpaces/ContCDiffMap.lean'), full_name='SciLean.ContCDi
ffMap.zero_apply')
(ProverActor pid=311267) 2024-09-21 22:23:23.488 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311458) 2024-09-21 22:23:31.708 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Objects/Scalar.lean'), full_name='SciLean.scalar
_div_one'), status=<Status.PROVED: 'Proved'>, proof=['simp'], actor_time=1.3808634551241994, environment_time=
0.022526646964251995, total_time=2.403628828935325, num_total_nodes=2, num_searched_nodes=1)
(ProverActor pid=311458) 2024-09-21 22:23:31.718 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/Objects/SemiInnerProductSpace.lean'), full_name='SciLean.norm₂
_scalar')
(ProverActor pid=312245) 2024-09-21 22:23:26.157 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof! [repeated 2x across cluster]
(ProverActor pid=311267) 2024-09-21 22:23:31.889 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/Bijective.lean'), full_name
='Function.Bijective.Prod.mk.arg_fstsnd.Bijective_rule_simple'), status=<Status.PROVED: 'Proved'>, proof=['exa
ct Function.bijective_id'], actor_time=1.9015330269467086, environment_time=0.09622102556750178, total_time=2.
998299686005339, num_total_nodes=16, num_searched_nodes=1)
(ProverActor pid=311267) 2024-09-21 22:23:31.895 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionSpaces/SmoothLinearMap.lean'), full_name='SciLean.Smoo
thLinearMap.zero_apply')
(ProverActor pid=312245) 2024-09-21 22:23:33.866 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionSpaces/ContCDiffMap.lean'), full_name='S
ciLean.ContCDiffMap.zero_apply'), status=<Status.PROVED: 'Proved'>, proof=['rfl'], actor_time=1.53409907198511
06, environment_time=0.00682084308937192, total_time=2.541181340115145, num_total_nodes=2, num_searched_nodes=
1)
(ProverActor pid=312245) 2024-09-21 22:23:33.871 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FloatAsReal.lean'), full_name='SciLean.re_float')
(ProverActor pid=311627) 2024-09-21 22:23:51.560 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311458) 2024-09-21 22:24:17.083 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311458) 2024-09-21 22:24:29.587 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/Objects/SemiInnerProductSpace.lean'), full_name=
'SciLean.norm₂_scalar'), status=<Status.PROVED: 'Proved'>, proof=['simp'], actor_time=2.286733719985932, envir
onment_time=0.011103536002337933, total_time=3.2981479419395328, num_total_nodes=2, num_searched_nodes=1)
(ProverActor pid=311458) 2024-09-21 22:24:29.592 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionTransformations/InvFun.lean'), full_name='Function.inv
Fun.id_rule')
(ProverActor pid=312245) 2024-09-21 22:24:20.552 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof! [repeated 2x across cluster]
(ProverActor pid=311267) 2024-09-21 22:24:31.472 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionSpaces/SmoothLinearMap.lean'), full_name
='SciLean.SmoothLinearMap.zero_apply'), status=<Status.PROVED: 'Proved'>, proof=['rfl'], actor_time=1.65272488
28206211, environment_time=0.003999995067715645, total_time=2.656983254943043, num_total_nodes=2, num_searched
_nodes=1)
(ProverActor pid=311267) 2024-09-21 22:24:31.476 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/IsLinearMap.lean'), full_name='IsLinearMa
p.isLinearMap_const_zero')
(ProverActor pid=312245) 2024-09-21 22:24:33.103 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FloatAsReal.lean'), full_name='SciLean.re_float'
), status=<Status.PROVED: 'Proved'>, proof=['exact RCLike.re_eq_self_of_le le_rfl'], actor_time=2.054711873875
931, environment_time=0.5946414978243411, total_time=3.6506959449034184, num_total_nodes=25, num_searched_node
s=1)
(ProverActor pid=312245) 2024-09-21 22:24:33.113 | INFO     | prover.proof_search_all_sorries:search:81 - Prov
ing Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a172e71da6eb9c91
6e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/CDifferentiable.lean'), full_name='SciLea
n.CDifferentiableAt.id_rule')
(ProverActor pid=311627) 2024-09-21 22:24:39.786 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/IsAffineMap.lean'), full_na
me='IsAffineMap.IsAffineMap_apply'), status=<Status.PROVED: 'Proved'>, proof=['constructor', 'constructor', 's
imp', 'simp'], actor_time=18.531353494385257, environment_time=10.307221405906603, total_time=29.853742423933,
 num_total_nodes=331, num_searched_nodes=11)
(ProverActor pid=311267) 2024-09-21 22:25:07.922 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=311267) 2024-09-21 22:25:17.065 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/IsLinearMap.lean'), full_na
me='IsLinearMap.isLinearMap_const_zero'), status=<Status.PROVED: 'Proved'>, proof=['constructor', 'all_goals a
esop'], actor_time=3.07363043888472, environment_time=0.4267043247818947, total_time=4.502049379982054, num_to
tal_nodes=48, num_searched_nodes=2)
(ProverActor pid=311458) 2024-09-21 22:25:22.055 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=312245) 2024-09-21 22:25:29.764 | INFO     | prover.proof_search_all_sorries:_best_first_sear
ch:171 - Found a proof!
(ProverActor pid=312245) 2024-09-21 22:25:39.018 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionPropositions/CDifferentiable.lean'), ful
l_name='SciLean.CDifferentiableAt.id_rule'), status=<Status.PROVED: 'Proved'>, proof=['unfold SciLean.CDiffere
ntiableAt', 'intro c hc hcx', 'simpa using hcx'], actor_time=20.971707108197734, environment_time=2.4787322075
571865, total_time=24.460282974876463, num_total_nodes=257, num_searched_nodes=9)
2024-09-21 22:26:07.349 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.scalar_div_o
ne
2024-09-21 22:26:07.350 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.scala
r_div_one
2024-09-21 22:26:07.350 | INFO     | __main__:process_theorem_batch:801 - Proof found for Function.Bijective.P
rod.mk.arg_fstsnd.Bijective_rule_simple
2024-09-21 22:26:07.351 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: Function.Bije
ctive.Prod.mk.arg_fstsnd.Bijective_rule_simple
2024-09-21 22:26:07.351 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.ContCDiffMap
.zero_apply
2024-09-21 22:26:07.352 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.ContC
DiffMap.zero_apply
2024-09-21 22:26:07.352 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.norm₂_scalar
2024-09-21 22:26:07.353 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.norm₂
_scalar
2024-09-21 22:26:07.353 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.SmoothLinear
Map.zero_apply
2024-09-21 22:26:07.354 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.Smoot
hLinearMap.zero_apply
2024-09-21 22:26:07.354 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.re_float
2024-09-21 22:26:07.355 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.re_fl
oat
2024-09-21 22:26:07.355 | INFO     | __main__:process_theorem_batch:801 - Proof found for IsAffineMap.IsAffine
Map_apply
2024-09-21 22:26:07.356 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: IsAffineMap.I
sAffineMap_apply
2024-09-21 22:26:07.356 | INFO     | __main__:process_theorem_batch:801 - Proof found for IsLinearMap.isLinear
Map_const_zero
2024-09-21 22:26:07.356 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: IsLinearMap.i
sLinearMap_const_zero
2024-09-21 22:26:07.357 | INFO     | __main__:process_theorem_batch:801 - Proof found for SciLean.CDifferentia
bleAt.id_rule
2024-09-21 22:26:07.357 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: SciLean.CDiff
erentiableAt.id_rule
2024-09-21 22:26:07.358 | INFO     | __main__:process_theorem_batch:801 - Proof found for Function.invFun.id_r
ule
2024-09-21 22:26:07.358 | INFO     | __main__:log_proved_theorem:788 - Logged re-proved theorem: Function.invF
un.id_rule
2024-09-21 22:26:07.359 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 22:26:07.362 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(ProverActor pid=311458) 2024-09-21 22:26:07.347 | INFO     | prover.proof_search_all_sorries:search:128 - Sea
rchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/lecopivo/SciLean', commit='22d53b2f4e3db2a1
72e71da6eb9c916e62655744'), file_path=PosixPath('SciLean/Core/FunctionTransformations/InvFun.lean'), full_name
='Function.invFun.id_rule'), status=<Status.PROVED: 'Proved'>, proof=['apply Function.invFun_comp', 'exact Fun
ction.injective_id'], actor_time=17.050663067027926, environment_time=2.0888930642977357, total_time=20.148788
260063156, num_total_nodes=301, num_searched_nodes=8)
2024-09-21 22:29:27.166 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 22:29:27.166 | INFO     | __main__:main:1671 - Shutting down Ray after proving
2024-09-21 22:29:30.482 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 22:29:30.482 | INFO     | __main__:main:1693 - current epoch: 6
2024-09-21 22:29:30.482 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 22:29:30.482 | INFO     | __main__:main:1364 - i: 6
2024-09-21 22:29:30.482 | INFO     | __main__:main:1370 - Main process
2024-09-21 22:29:30.482 | INFO     | __main__:main:1371 - Using lambda = 0.0
2024-09-21 22:29:30.482 | INFO     | __main__:main:1372 - Processing https://github.com/google-deepmind/debate
2024-09-21 22:29:30.482 | INFO     | __main__:main:1379 - Adding repo to repos_for_merged_dataset
2024-09-21 22:29:30.483 | INFO     | __main__:main:1391 - All GPUs
2024-09-21 22:29:30.483 | INFO     | __main__:main:1627 - Starting the prover
2024-09-21 22:29:30.483 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-21 22:29:30.483 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-21 22:29:30.483 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-21 22:29:30.764 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:29:30.764 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:29:32.657 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-21 22:29:32.998 | INFO     | prover.proof_search_all_sorries:__init__:451 - Loaded model from /data/yi
ngzi_ma/lean_project/model_lightning.ckpt
2024-09-21 22:29:32.999 | INFO     | prover.proof_search_all_sorries:__init__:452 - Using retriever: PremiseRe
triever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-21 22:29:33.000 | INFO     | prover.proof_search_all_sorries:__init__:455 - Loading indexed corpus fro
m /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_debate_7fb39251b70579
7ee54e08c96177fabd29a5b5a3/corpus.jsonl
2024-09-21 22:29:33.000 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_debate_7fb39251b705797ee54e08c96177fabd29a5b5a3/c
orpus.jsonl
2024-09-21 22:29:45.973 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-21 22:29:45.973 | INFO     | prover.proof_search_all_sorries:__init__:457 - Loaded indexed corpus from
 /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_debate_7fb39251b705797
ee54e08c96177fabd29a5b5a3/corpus.jsonl
2024-09-21 22:29:45.974 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|█████████████████████████████████████████████████████████████████████| 3240/3240 [04:56<00:00, 10.91it/s]
2024-09-21 22:34:42.952 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 22:34:42.952 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 22:34:46,584 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=349008) [2024-09-21 22:35:19,855] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=349008) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=349008)   return torch.load(io.BytesIO(b))
(pid=349174) [2024-09-21 22:35:28,216] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=349174) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=349174)   return torch.load(io.BytesIO(b))
(pid=349356) [2024-09-21 22:35:38,162] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 22:35:41.388 | INFO     | __main__:prove_sorry_theorems:862 - Found 0 proved sorry theorems to re-p
rove
Processing theorems from google-deepmind/debate: 0theorem [00:00, ?theorem/s]
2024-09-21 22:35:41.389 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 22:35:41.391 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(ProverActor pid=349356) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=349356)   return torch.load(io.BytesIO(b))
(pid=349528) [2024-09-21 22:35:48,881] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=349528) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=349528)   return torch.load(io.BytesIO(b))
2024-09-21 22:37:03.181 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 22:37:03.182 | INFO     | __main__:main:1671 - Shutting down Ray after proving
2024-09-21 22:37:05.557 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 22:37:05.558 | INFO     | __main__:main:1693 - current epoch: 7
2024-09-21 22:37:05.558 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 22:37:05.558 | INFO     | __main__:main:1364 - i: 7
2024-09-21 22:37:05.558 | INFO     | __main__:main:1370 - Main process
2024-09-21 22:37:05.558 | INFO     | __main__:main:1371 - Using lambda = 0.0
2024-09-21 22:37:05.558 | INFO     | __main__:main:1372 - Processing https://github.com/eric-wieser/lean-matri
x-cookbook
2024-09-21 22:37:05.558 | INFO     | __main__:main:1379 - Adding repo to repos_for_merged_dataset
2024-09-21 22:37:05.558 | INFO     | __main__:main:1391 - All GPUs
2024-09-21 22:37:05.558 | INFO     | __main__:main:1627 - Starting the prover
2024-09-21 22:37:05.558 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-21 22:37:05.559 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-21 22:37:05.559 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-21 22:37:05.742 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:37:05.742 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:37:07.489 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-21 22:37:07.844 | INFO     | prover.proof_search_all_sorries:__init__:451 - Loaded model from /data/yi
ngzi_ma/lean_project/model_lightning.ckpt
2024-09-21 22:37:07.845 | INFO     | prover.proof_search_all_sorries:__init__:452 - Using retriever: PremiseRe
triever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-21 22:37:07.845 | INFO     | prover.proof_search_all_sorries:__init__:455 - Loading indexed corpus fro
m /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f/corpus.jsonl
2024-09-21 22:37:07.846 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c024b58e
7882f564669f/corpus.jsonl
2024-09-21 22:37:13.257 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-21 22:37:13.258 | INFO     | prover.proof_search_all_sorries:__init__:457 - Loaded indexed corpus from
 /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_lean-matrix-cookbook_f
15a149d321ac99ff9b9c024b58e7882f564669f/corpus.jsonl
2024-09-21 22:37:13.258 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|█████████████████████████████████████████████████████████████████████| 3197/3197 [04:51<00:00, 10.95it/s]
2024-09-21 22:42:05.131 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 22:42:05.131 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 22:42:08,875 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=381819) [2024-09-21 22:42:41,848] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=381819) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=381819)   return torch.load(io.BytesIO(b))
(pid=381978) [2024-09-21 22:42:49,885] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=381978) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=381978)   return torch.load(io.BytesIO(b))
(pid=382152) [2024-09-21 22:42:58,433] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 22:42:58.564 | INFO     | __main__:prove_sorry_theorems:862 - Found 0 proved sorry theorems to re-p
rove
Processing theorems from eric-wieser/lean-matrix-cookbook: 0theorem [00:00, ?theorem/s]
2024-09-21 22:42:58.565 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 22:42:58.567 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(ProverActor pid=382152) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=382152)   return torch.load(io.BytesIO(b))
(pid=382308) [2024-09-21 22:43:05,916] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 22:44:32.374 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 22:44:32.374 | INFO     | __main__:main:1671 - Shutting down Ray after proving
(ProverActor pid=382308) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=382308)   return torch.load(io.BytesIO(b))
2024-09-21 22:44:34.711 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 22:44:34.712 | INFO     | __main__:main:1693 - current epoch: 8
2024-09-21 22:44:34.712 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 22:44:34.712 | INFO     | __main__:main:1364 - i: 8
2024-09-21 22:44:34.712 | INFO     | __main__:main:1370 - Main process
2024-09-21 22:44:34.712 | INFO     | __main__:main:1371 - Using lambda = 0.0
2024-09-21 22:44:34.712 | INFO     | __main__:main:1372 - Processing https://github.com/leanprover-community/c
on-nf
2024-09-21 22:44:34.712 | INFO     | __main__:main:1379 - Adding repo to repos_for_merged_dataset
2024-09-21 22:44:34.712 | INFO     | __main__:main:1391 - All GPUs
2024-09-21 22:44:34.712 | INFO     | __main__:main:1627 - Starting the prover
2024-09-21 22:44:34.712 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-21 22:44:34.712 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-21 22:44:34.713 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-21 22:44:35.045 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:44:35.045 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:44:36.902 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-21 22:44:37.362 | INFO     | prover.proof_search_all_sorries:__init__:451 - Loaded model from /data/yi
ngzi_ma/lean_project/model_lightning.ckpt
2024-09-21 22:44:37.363 | INFO     | prover.proof_search_all_sorries:__init__:452 - Using retriever: PremiseRe
triever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-21 22:44:37.363 | INFO     | prover.proof_search_all_sorries:__init__:455 - Loading indexed corpus fro
m /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_con-nf_00bdc85ba7d486
a9e544a0806a1018dd06fa3856/corpus.jsonl
2024-09-21 22:44:37.364 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_con-nf_00bdc85ba7d486a9e544a0806a1018dd06fa3856/c
orpus.jsonl
2024-09-21 22:44:39.792 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-21 22:44:39.792 | INFO     | prover.proof_search_all_sorries:__init__:457 - Loaded indexed corpus from
 /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_con-nf_00bdc85ba7d486a
9e544a0806a1018dd06fa3856/corpus.jsonl
2024-09-21 22:44:39.792 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|█████████████████████████████████████████████████████████████████████| 2006/2006 [02:46<00:00, 12.01it/s]
2024-09-21 22:47:26.765 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 22:47:26.765 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 22:47:30,449 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=414370) [2024-09-21 22:48:00,031] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=414370) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=414370)   return torch.load(io.BytesIO(b))
(pid=414507) [2024-09-21 22:48:05,239] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 22:48:09.197 | INFO     | __main__:prove_sorry_theorems:862 - Found 0 proved sorry theorems to re-p
rove
Processing theorems from leanprover-community/con-nf: 0theorem [00:00, ?theorem/s]
2024-09-21 22:48:09.198 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 22:48:09.199 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(ProverActor pid=414507) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=414507)   return torch.load(io.BytesIO(b))
(pid=414698) [2024-09-21 22:48:11,670] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=414698) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=414698)   return torch.load(io.BytesIO(b))
2024-09-21 22:49:45.064 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 22:49:45.064 | INFO     | __main__:main:1671 - Shutting down Ray after proving
(pid=414858) [2024-09-21 22:48:16,678] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=414858) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=414858)   return torch.load(io.BytesIO(b))
2024-09-21 22:49:47.188 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 22:49:47.189 | INFO     | __main__:main:1693 - current epoch: 9
2024-09-21 22:49:47.189 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 22:49:47.189 | INFO     | __main__:main:1364 - i: 9
2024-09-21 22:49:47.189 | INFO     | __main__:main:1370 - Main process
2024-09-21 22:49:47.189 | INFO     | __main__:main:1371 - Using lambda = 0.0
2024-09-21 22:49:47.189 | INFO     | __main__:main:1372 - Processing https://github.com/FormalizedFormalLogic/
Foundation
2024-09-21 22:49:47.189 | INFO     | __main__:main:1379 - Adding repo to repos_for_merged_dataset
2024-09-21 22:49:47.189 | INFO     | __main__:main:1391 - All GPUs
2024-09-21 22:49:47.189 | INFO     | __main__:main:1627 - Starting the prover
2024-09-21 22:49:47.189 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-21 22:49:47.189 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-21 22:49:47.189 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-21 22:49:47.524 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:49:47.524 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:49:49.329 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-21 22:49:49.687 | INFO     | prover.proof_search_all_sorries:__init__:451 - Loaded model from /data/yi
ngzi_ma/lean_project/model_lightning.ckpt
2024-09-21 22:49:49.688 | INFO     | prover.proof_search_all_sorries:__init__:452 - Using retriever: PremiseRe
triever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-21 22:49:49.688 | INFO     | prover.proof_search_all_sorries:__init__:455 - Loading indexed corpus fro
m /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_Foundation_d5fe5d057a
90a0703a745cdc318a1b6621490c21/corpus.jsonl
2024-09-21 22:49:49.689 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_Foundation_d5fe5d057a90a0703a745cdc318a1b6621490c
21/corpus.jsonl
2024-09-21 22:49:51.720 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-21 22:49:51.720 | INFO     | prover.proof_search_all_sorries:__init__:457 - Loaded indexed corpus from
 /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_Foundation_d5fe5d057a9
0a0703a745cdc318a1b6621490c21/corpus.jsonl
2024-09-21 22:49:51.720 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|█████████████████████████████████████████████████████████████████████| 1812/1812 [02:32<00:00, 11.87it/s]
2024-09-21 22:52:24.349 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 22:52:24.349 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 22:52:28,039 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=447195) [2024-09-21 22:52:57,342] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=447195) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=447195)   return torch.load(io.BytesIO(b))
(pid=447330) [2024-09-21 22:53:02,397] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 22:53:04.154 | INFO     | __main__:prove_sorry_theorems:862 - Found 0 proved sorry theorems to re-p
rove
Processing theorems from FormalizedFormalLogic/Foundation: 0theorem [00:00, ?theorem/s]
2024-09-21 22:53:04.155 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 22:53:04.157 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(ProverActor pid=447330) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=447330)   return torch.load(io.BytesIO(b))
(pid=447426) [2024-09-21 22:53:07,710] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=447426) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=447426)   return torch.load(io.BytesIO(b))
2024-09-21 22:54:42.746 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 22:54:42.746 | INFO     | __main__:main:1671 - Shutting down Ray after proving
(pid=447598) [2024-09-21 22:53:11,663] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=447598) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=447598)   return torch.load(io.BytesIO(b))
2024-09-21 22:54:45.981 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 22:54:45.981 | INFO     | __main__:main:1693 - current epoch: 10
2024-09-21 22:54:45.981 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 22:54:45.981 | INFO     | __main__:main:1364 - i: 10
2024-09-21 22:54:45.981 | INFO     | __main__:main:1370 - Main process
2024-09-21 22:54:45.982 | INFO     | __main__:main:1371 - Using lambda = 0.0
2024-09-21 22:54:45.982 | INFO     | __main__:main:1372 - Processing https://github.com/siddhartha-gadgil/Satu
rn
2024-09-21 22:54:45.982 | INFO     | __main__:main:1379 - Adding repo to repos_for_merged_dataset
2024-09-21 22:54:45.982 | INFO     | __main__:main:1391 - All GPUs
2024-09-21 22:54:45.982 | INFO     | __main__:main:1627 - Starting the prover
2024-09-21 22:54:45.982 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-21 22:54:45.982 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-21 22:54:45.982 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-21 22:54:46.310 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:54:46.310 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:54:48.335 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-21 22:54:48.955 | INFO     | prover.proof_search_all_sorries:__init__:451 - Loaded model from /data/yi
ngzi_ma/lean_project/model_lightning.ckpt
2024-09-21 22:54:48.956 | INFO     | prover.proof_search_all_sorries:__init__:452 - Using retriever: PremiseRe
triever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-21 22:54:48.957 | INFO     | prover.proof_search_all_sorries:__init__:455 - Loading indexed corpus fro
m /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_Saturn_3811a9dd46cdfd
5fa0c0c1896720c28d2ec4a42a/corpus.jsonl
2024-09-21 22:54:48.957 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_Saturn_3811a9dd46cdfd5fa0c0c1896720c28d2ec4a42a/c
orpus.jsonl
2024-09-21 22:54:50.128 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-21 22:54:50.128 | INFO     | prover.proof_search_all_sorries:__init__:457 - Loaded indexed corpus from
 /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_Saturn_3811a9dd46cdfd5
fa0c0c1896720c28d2ec4a42a/corpus.jsonl
2024-09-21 22:54:50.128 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|█████████████████████████████████████████████████████████████████████| 1079/1079 [01:43<00:00, 10.45it/s]
2024-09-21 22:56:33.390 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 22:56:33.391 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 22:56:37,090 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=479553) [2024-09-21 22:57:05,728] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=479553) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=479553)   return torch.load(io.BytesIO(b))
2024-09-21 22:57:10.102 | INFO     | __main__:prove_sorry_theorems:862 - Found 0 proved sorry theorems to re-p
rove
Processing theorems from siddhartha-gadgil/Saturn: 0theorem [00:00, ?theorem/s]
2024-09-21 22:57:10.103 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 22:57:10.104 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(pid=479837) [2024-09-21 22:57:13,855] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect) [repeated 2x across cluster]
(ProverActor pid=479837) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature. [r
epeated 2x across cluster]
(ProverActor pid=479837)   return torch.load(io.BytesIO(b)) [repeated 2x across cluster]
(pid=480008) [2024-09-21 22:57:17,868] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 22:58:43.044 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 22:58:43.044 | INFO     | __main__:main:1671 - Shutting down Ray after proving
(ProverActor pid=480008) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=480008)   return torch.load(io.BytesIO(b))
2024-09-21 22:58:46.216 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 22:58:46.217 | INFO     | __main__:main:1693 - current epoch: 11
2024-09-21 22:58:46.217 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 22:58:46.217 | INFO     | __main__:main:1364 - i: 11
2024-09-21 22:58:46.217 | INFO     | __main__:main:1370 - Main process
2024-09-21 22:58:46.217 | INFO     | __main__:main:1371 - Using lambda = 0.0
2024-09-21 22:58:46.217 | INFO     | __main__:main:1372 - Processing https://github.com/loganrjmurphy/LeanEucl
id
2024-09-21 22:58:46.217 | INFO     | __main__:main:1379 - Adding repo to repos_for_merged_dataset
2024-09-21 22:58:46.217 | INFO     | __main__:main:1391 - All GPUs
2024-09-21 22:58:46.217 | INFO     | __main__:main:1627 - Starting the prover
2024-09-21 22:58:46.217 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-21 22:58:46.217 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-21 22:58:46.218 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-21 22:58:46.549 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:58:46.549 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 22:58:48.439 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-21 22:58:48.796 | INFO     | prover.proof_search_all_sorries:__init__:451 - Loaded model from /data/yi
ngzi_ma/lean_project/model_lightning.ckpt
2024-09-21 22:58:48.797 | INFO     | prover.proof_search_all_sorries:__init__:452 - Using retriever: PremiseRe
triever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-21 22:58:48.797 | INFO     | prover.proof_search_all_sorries:__init__:455 - Loading indexed corpus fro
m /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_LeanEuclid_f1912c3090
eb82820575758efc31e40b9db86bb8/corpus.jsonl
2024-09-21 22:58:48.797 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_LeanEuclid_f1912c3090eb82820575758efc31e40b9db86b
b8/corpus.jsonl
2024-09-21 22:58:50.354 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-21 22:58:50.355 | INFO     | prover.proof_search_all_sorries:__init__:457 - Loaded indexed corpus from
 /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_LeanEuclid_f1912c3090e
b82820575758efc31e40b9db86bb8/corpus.jsonl
2024-09-21 22:58:50.355 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|█████████████████████████████████████████████████████████████████████| 1268/1268 [01:58<00:00, 10.69it/s]
2024-09-21 23:00:48.987 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 23:00:48.987 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 23:00:52,599 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=512013) [2024-09-21 23:01:21,589] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
(ProverActor pid=512013) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=512013)   return torch.load(io.BytesIO(b))
2024-09-21 23:01:25.769 | INFO     | __main__:prove_sorry_theorems:862 - Found 0 proved sorry theorems to re-p
rove
Processing theorems from loganrjmurphy/LeanEuclid: 0theorem [00:00, ?theorem/s]
2024-09-21 23:01:25.770 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 23:01:25.772 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(pid=512220) [2024-09-21 23:01:29,077] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect) [repeated 2x across cluster]
(ProverActor pid=512220) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature. [r
epeated 2x across cluster]
(ProverActor pid=512220)   return torch.load(io.BytesIO(b)) [repeated 2x across cluster]
(pid=512457) [2024-09-21 23:01:33,779] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 23:02:56.658 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 23:02:56.658 | INFO     | __main__:main:1671 - Shutting down Ray after proving
(ProverActor pid=512457) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=512457)   return torch.load(io.BytesIO(b))
2024-09-21 23:02:58.893 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 23:02:58.893 | INFO     | __main__:main:1693 - current epoch: 12
2024-09-21 23:02:58.893 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 23:02:58.893 | INFO     | __main__:main:1364 - i: 12
2024-09-21 23:02:58.893 | INFO     | __main__:main:1370 - Main process
2024-09-21 23:02:58.893 | INFO     | __main__:main:1371 - Using lambda = 0.0
2024-09-21 23:02:58.894 | INFO     | __main__:main:1372 - Processing https://github.com/digama0/lean4lean
2024-09-21 23:02:58.894 | INFO     | __main__:main:1379 - Adding repo to repos_for_merged_dataset
2024-09-21 23:02:58.894 | INFO     | __main__:main:1391 - All GPUs
2024-09-21 23:02:58.894 | INFO     | __main__:main:1627 - Starting the prover
2024-09-21 23:02:58.894 | INFO     | prover.proof_search_all_sorries:__init__:407 - Inside __init__
2024-09-21 23:02:58.894 | INFO     | prover.proof_search_all_sorries:__init__:412 - ckpt_path is not None
2024-09-21 23:02:58.894 | INFO     | prover.proof_search_all_sorries:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-21 23:02:59.233 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 23:02:59.233 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a5
6fef21276e0f_lambda_0.1_epoch=13-Recall@10_val=76.62.ckpt
2024-09-21 23:03:00.997 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-21 23:03:01.388 | INFO     | prover.proof_search_all_sorries:__init__:451 - Loaded model from /data/yi
ngzi_ma/lean_project/model_lightning.ckpt
2024-09-21 23:03:01.389 | INFO     | prover.proof_search_all_sorries:__init__:452 - Using retriever: PremiseRe
triever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-21 23:03:01.389 | INFO     | prover.proof_search_all_sorries:__init__:455 - Loading indexed corpus fro
m /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5
facea96a5ee51c6a56fef21276e0f/corpus.jsonl
2024-09-21 23:03:01.390 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5facea96a5ee51c6a56fef21276e0
f/corpus.jsonl
2024-09-21 23:03:01.969 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-21 23:03:01.970 | INFO     | prover.proof_search_all_sorries:__init__:457 - Loaded indexed corpus from
 /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum/merged_with_new_lean4lean_05b1f4a68c5f
acea96a5ee51c6a56fef21276e0f/corpus.jsonl
2024-09-21 23:03:01.970 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|███████████████████████████████████████████████████████████████████████| 710/710 [01:10<00:00, 10.08it/s]
2024-09-21 23:04:12.403 | INFO     | prover.proof_search_all_sorries:__init__:459 - Finished reindexing!
2024-09-21 23:04:12.403 | INFO     | prover.proof_search_all_sorries:__init__:470 - Launching 4 workers with 4
 GPUs.
2024-09-21 23:04:15,954 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=544557) [2024-09-21 23:04:44,065] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 23:04:45.658 | INFO     | __main__:prove_sorry_theorems:862 - Found 0 proved sorry theorems to re-p
rove
Processing theorems from digama0/lean4lean: 0theorem [00:00, ?theorem/s]
2024-09-21 23:04:45.659 | INFO     | __main__:save_progress:819 - Saving encountered theorems...
2024-09-21 23:04:45.661 | INFO     | __main__:prove_sorry_theorems:910 - Finished attempting to re-prove sorry
 theorems
(ProverActor pid=544557) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=544557)   return torch.load(io.BytesIO(b))
(pid=544787) [2024-09-21 23:04:50,365] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect) [repeated 2x across cluster]
(ProverActor pid=544787) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature. [r
epeated 2x across cluster]
(ProverActor pid=544787)   return torch.load(io.BytesIO(b)) [repeated 2x across cluster]
(ProverActor pid=544963) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.p
y:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execut
e arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mod
els for more details). In a future release, the default value for `weights_only` will be flipped to `True`. Th
is limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_saf
e_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full cont
rol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=544963)   return torch.load(io.BytesIO(b))
2024-09-21 23:06:21.808 | INFO     | __main__:main:1668 - Finished searching for proofs of sorry theorems
2024-09-21 23:06:21.808 | INFO     | __main__:main:1671 - Shutting down Ray after proving
(pid=544963) [2024-09-21 23:04:53,693] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator
 to cuda (auto detect)
2024-09-21 23:06:23.983 | INFO     | __main__:main:1691 - Finished processing the repository
2024-09-21 23:06:23.984 | INFO     | __main__:main:1693 - current epoch: 13
2024-09-21 23:06:23.984 | INFO     | __main__:main:1363 - length of lean_git_repos: 13
2024-09-21 23:06:23.984 | INFO     | __main__:main:1364 - i: 13
2024-09-21 23:06:23.984 | INFO     | __main__:main:2073 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_all_sorries.py", line 1365, in main
    for lambda_value in lambdas:
IndexError: list index out of range
run_code3_all_sorries.sh: line 16: y: command not found
kill: (6218): Operation not permitted
kill: (6943): Operation not permitted
kill: (9126): Operation not permitted
kill: (195368): Operation not permitted
kill: (195386): Operation not permitted
kill: (195387): Operation not permitted
kill: (195388): Operation not permitted
kill: (195395): Operation not permitted
kill: (196414): Operation not permitted
kill: (196430): Operation not permitted
kill: (196431): Operation not permitted
kill: (196432): Operation not permitted
kill: (196439): Operation not permitted
kill: (197196): Operation not permitted
kill: (197213): Operation not permitted
kill: (197214): Operation not permitted
kill: (197215): Operation not permitted
kill: (197222): Operation not permitted
kill: (316348): Operation not permitted
kill: (316382): Operation not permitted
kill: (545486): No such process
kill: (3408138): Operation not permitted
kill: (4012144): Operation not permitted
kill: (4014630): Operation not permitted
kill: (4016013): Operation not permitted
kill: (4189406): Operation not permitted
Sat Sep 21 23:06:34 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0F:00.0 Off |                    0 |
| N/A   41C    P0             88W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:15:00.0 Off |                    0 |
| N/A   38C    P0             90W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   47C    P0             93W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   39C    P0             87W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running main3_all_sorries.py
[2024-09-21 23:06:40,240] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (aut
o detect)
2024-09-21 23:06:44.024 | INFO     | __main__:main:1251 - Running retrieval baseline
2024-09-21 23:06:44.024 | INFO     | __main__:main:1254 - Configuring LeanDojo...
2024-09-21 23:06:44.027 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directo
ry: /data/yingzi_ma/lean_project/ReProver
2024-09-21 23:06:44.027 | INFO     | __main__:main:1256 - LeanDojo configured
2024-09-21 23:06:44.027 | INFO     | __main__:main:1261 - Starting the main process
2024-09-21 23:06:44.027 | INFO     | __main__:main:1269 - Loading database from /data/yingzi_ma/lean_project/d
ynamic_database_PT_single_repo_no_ewc_curriculum_retention.json
^Z
[2]+  Stopped                 bash run_code3_all_sorries.sh
(base) yingzi_ma@compute-permanent-node-106:~/lean_project/ReProver$
