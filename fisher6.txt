LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
2024-09-13 07:18:12.178 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:18:12.179 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:18:12.179 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:18:12.181 | INFO     | common:get_optimizers:449 - Optimizing with AdamW

  | Name    | Type           | Params
-------------------------------------------
0 | encoder | T5EncoderModel | 217 M
-------------------------------------------
217 M     Trainable params
0         Non-trainable params
217 M     Total params
870.630   Total estimated model params size (MB)
Restored all states from the checkpoint at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_ne
w_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_val=70.07.ckpt
`Trainer.fit` stopped: `max_epochs=2` reached.
2024-09-13 07:18:15.552 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:18:15.636 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:18:15.873 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:18:15.956 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:18:15.956 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:18:15.957 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:18:15.957 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:18:15.957 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:18:15.957 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:18:15.957 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:18:15.957 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:18:15.957 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:18:15.957 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:18:15.957 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:18:15.957 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:18:15.958 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:18:18.352 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:18:18.352 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:18:18.422 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:18:18.422 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:18:18.688 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:18:18.688 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:18:18.962 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:18:18.963 | INFO     | __main__:main:1629 - right before barrier fisher
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204
: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM,
prepend your python command with `srun` like so: srun python main.py ...
[rank: 2] Seed set to 3407
[rank: 0] Seed set to 3407
[rank: 3] Seed set to 3407
[rank: 1] Seed set to 3407
2024-09-13 07:18:22.367 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:18:23.592 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:18:23.827 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
2024-09-13 07:18:23.890 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
Training dataset size: 149228
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connecto
r.py:232: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(de
vices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `Di
stributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
2024-09-13 07:18:24.704 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:18:24.736 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:18:24.796 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:18:24.819 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:18:24.825 | INFO     | retrieval.model:test_step:406 - Inside test_step
2024-09-13 07:18:24.849 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:18:24.886 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:18:24.904 | INFO     | retrieval.model:test_step:406 - Inside test_step
Testing: |                                                                                        | 0/? [00:00<?, ?it/s]
2024-09-13 07:18:24.926 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:18:24.947 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:18:25.004 | INFO     | retrieval.model:test_step:406 - Inside test_step
Testing DataLoader 0:   0%|                                                                    | 0/9327 [00:00<?, ?it/s]
2024-09-13 07:18:25.053 | INFO     | retrieval.model:test_step:406 - Inside test_step
2024-09-13 07:18:25.437 | INFO     | retrieval.model:test_step:416 - Test loss before EWC: 0.0135
2024-09-13 07:18:25.555 | INFO     | retrieval.model:test_step:416 - Test loss before EWC: 0.0290
2024-09-13 07:18:25.556 | INFO     | retrieval.model:test_step:416 - Test loss before EWC: 0.0257
2024-09-13 07:18:25.777 | INFO     | retrieval.model:test_step:416 - Test loss before EWC: 0.0351
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 417, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:18:26.186 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:18:26.186 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:18:26.186 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:18:26.186 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:18:26.186 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 417, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:18:26.372 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:18:26.372 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:18:26.372 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:18:26.372 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:18:26.372 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 417, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:18:26.405 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:18:26.405 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:18:26.405 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:18:26.406 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:18:26.406 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 417, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:18:26.687 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:18:26.687 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:18:26.687 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:18:26.687 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:18:26.687 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
Testing DataLoader 0:   0%|                                                                    | 0/9327 [00:03<?, ?it/s]
[rank0]:[W913 07:18:30.837615183 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed befor
e we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that
 any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and bl
ock the progress of another member of the process group. This constraint has always been present,  but this warning has
only been added since PyTorch 2.4 (function operator())
(base) yingzi_ma@compute-permanent-node-352:~/lean_project/ReProver$ bash run_code.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834741.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834743.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834746.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834747.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_835354.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_GCS.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834744.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_RAYLET.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834742.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_833907.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_AUTOSCALER.log': Permission deni
ed
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834748.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834745.log': Permiss
ion denied
Stopping ray
Could not terminate `/usr/bin/python3 /usr/local/bin/user_traffic_monitor.py` due to (pid=784996, name='python3')
Did not find any active Ray processes.
Running main.py
[2024-09-13 07:22:43,176] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-13 07:22:47.131 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:22:47.131 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:22:47.134 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:22:47.134 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:22:47.134 | INFO     | __main__:main:1210 - Starting the main process
2024-09-13 07:22:47.135 | INFO     | __main__:main:1218 - Loading database from /data/yingzi_ma/lean_project/dynamic_dat
abase_PT_single_repo_no_ewc.json
^Z
[11]+  Stopped                 bash run_code.sh
(base) yingzi_ma@compute-permanent-node-352:~/lean_project/ReProver$ bash run_code.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834741.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834743.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834746.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834747.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_835354.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_GCS.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834744.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_RAYLET.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834742.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_833907.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_AUTOSCALER.log': Permission deni
ed
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834748.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834745.log': Permiss
ion denied
Stopping ray
Could not terminate `/usr/bin/python3 /usr/local/bin/user_traffic_monitor.py` due to (pid=784996, name='python3')
Did not find any active Ray processes.
Running main.py
[2024-09-13 07:23:03,813] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-13 07:23:07.798 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:23:07.798 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:23:07.801 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:23:07.801 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:23:07.801 | INFO     | __main__:main:1210 - Starting the main process
2024-09-13 07:23:07.802 | INFO     | __main__:main:1218 - Loading database from /data/yingzi_ma/lean_project/dynamic_dat
abase_PT_single_repo_no_ewc.json
2024-09-13 07:23:30.608 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.
com/leanprover-community/mathlib4 (commit: 2b29e73438e240a427bcecc7c0fe19306beb1310)
2024-09-13 07:23:30.608 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/lean
prover-community/mathlib4 (commit: 2b29e73438e240a427bcecc7c0fe19306beb1310)
2024-09-13 07:23:35.365 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.
com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-13 07:23:35.365 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/leco
pivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-13 07:23:35.721 | INFO     | __main__:main:1220 - Loaded database from /data/yingzi_ma/lean_project/dynamic_data
base_PT_single_repo_no_ewc.json
2024-09-13 07:23:35.722 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:23:35.722 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:23:36.125 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:23:52.313 | INFO     | __main__:main:1347 - Finding compatible repositories...
2024-09-13 07:23:52.315 | INFO     | __main__:main:1350 - Finished finding compatible repositories
2024-09-13 07:23:52.315 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:23:52.315 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:23:52.315 | INFO     | __main__:main:1375 - Main process
2024-09-13 07:23:52.316 | INFO     | __main__:main:1376 - Using lambda = 0.1
2024-09-13 07:23:52.316 | INFO     | __main__:main:1377 - Processing https://github.com/lecopivo/SciLean
2024-09-13 07:23:52.316 | INFO     | __main__:main:1398 - Adding repo to repos_for_merged_dataset
2024-09-13 07:23:52.316 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:23:52.316 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:23:52.316 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:23:52.317 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:23:52.317 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 0] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
2024-09-13 07:23:54.521 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:23:54.521 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
2024-09-13 07:23:54.862 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:23:54.863 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:23:54.863 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204
: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM,
prepend your python command with `srun` like so: srun python main.py ...
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.
2024-09-13 07:23:54.967 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:23:54.968 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-13 07:23:55.064 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
2024-09-13 07:24:05.079 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:24:05.093 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:05.105 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:24:05.106 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:24:05.106 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:24:05.106 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:24:05.106 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:24:05.106 | INFO     | __main__:main:1543 - hit the barrier before training
[rank: 0] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[2024-09-13 07:24:10,644] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-13 07:24:10,653] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-13 07:24:10,655] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-13 07:24:14.754 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:24:14.754 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:24:14.754 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:24:14.754 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:24:14.754 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:24:14.754 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:24:14.757 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:24:14.757 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:24:14.757 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:24:14.757 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:24:14.757 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:24:14.757 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:24:14.757 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:24:14.757 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:24:14.757 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:24:14.757 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:24:14.757 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:24:14.757 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:24:14.948 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:24:14.957 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:24:14.973 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:24:31.002 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:24:31.002 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:24:31.002 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:24:31.003 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:24:31.003 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:24:31.003 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:24:31.003 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 2] Seed set to 3407
2024-09-13 07:24:31.120 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:24:31.120 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:24:31.121 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:24:31.121 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:24:31.121 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:24:31.121 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:24:31.121 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 1] Seed set to 3407
2024-09-13 07:24:31.223 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:24:31.223 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:24:31.223 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:24:31.224 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:24:31.224 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:24:31.224 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:24:31.224 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 3] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
2024-09-13 07:24:33.541 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:24:33.542 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
2024-09-13 07:24:33.846 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:24:33.847 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
2024-09-13 07:24:33.847 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:24:33.847 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
2024-09-13 07:24:34.052 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:24:34.052 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:24:34.052 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
2024-09-13 07:24:34.158 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:24:34.159 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-13 07:24:34.258 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
2024-09-13 07:24:34.433 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:24:34.433 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:24:34.433 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
2024-09-13 07:24:34.446 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:24:34.446 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:24:34.446 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
2024-09-13 07:24:34.481 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:24:34.481 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
2024-09-13 07:24:34.489 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:24:34.489 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-13 07:24:34.575 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-13 07:24:34.604 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
2024-09-13 07:24:44.536 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:24:44.548 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:44.560 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:24:44.560 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:24:44.560 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:24:44.560 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:24:44.560 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:24:44.560 | INFO     | __main__:main:1543 - hit the barrier before training
[rank: 1] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
2024-09-13 07:24:45.507 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:24:45.520 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:45.532 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:24:45.532 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:24:45.532 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:24:45.532 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:24:45.532 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:24:45.533 | INFO     | __main__:main:1543 - hit the barrier before training
2024-09-13 07:24:45.608 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:24:45.620 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:45.632 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:24:45.632 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:24:45.632 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:24:45.632 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:24:45.633 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:24:45.633 | INFO     | __main__:main:1543 - hit the barrier before training
[rank: 2] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
[rank: 3] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
2024-09-13 07:24:47.358 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:24:47.448 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:47.462 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:65
3: Checkpoint directory /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc exists and is not empty.
2024-09-13 07:24:48.892 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:24:48.972 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:48.979 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
2024-09-13 07:24:48.988 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:24:49.033 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:24:49.073 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:49.089 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
Training dataset size: 149228
2024-09-13 07:24:49.124 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:24:49.139 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
Restoring states from the checkpoint path at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_
new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_val=70.07.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
2024-09-13 07:24:50.211 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:24:50.212 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:24:50.212 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:24:50.212 | INFO     | common:get_optimizers:449 - Optimizing with AdamW

  | Name    | Type           | Params
-------------------------------------------
0 | encoder | T5EncoderModel | 217 M
-------------------------------------------
217 M     Trainable params
0         Non-trainable params
217 M     Total params
870.630   Total estimated model params size (MB)
Restored all states from the checkpoint at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_ne
w_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_val=70.07.ckpt
`Trainer.fit` stopped: `max_epochs=2` reached.
2024-09-13 07:24:53.258 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:24:53.566 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:24:53.751 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:24:53.768 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:24:53.769 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:24:53.769 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:24:53.769 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:24:53.769 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:24:53.769 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:24:53.769 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:24:53.769 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:24:53.769 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:24:53.769 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:24:53.769 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:24:53.769 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:24:53.769 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:24:55.815 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:24:55.815 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:24:56.358 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:24:56.358 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:24:56.363 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:24:56.364 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:24:56.376 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:24:56.376 | INFO     | __main__:main:1629 - right before barrier fisher
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204
: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM,
prepend your python command with `srun` like so: srun python main.py ...
[rank: 3] Seed set to 3407
[rank: 1] Seed set to 3407
[rank: 2] Seed set to 3407
[rank: 0] Seed set to 3407
2024-09-13 07:24:59.807 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
2024-09-13 07:24:59.894 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
Training dataset size: 149228
2024-09-13 07:25:00.630 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:25:01.913 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connecto
r.py:232: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(de
vices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `Di
stributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
2024-09-13 07:25:02.750 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:25:02.784 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:25:02.794 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:25:02.824 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:25:02.860 | INFO     | retrieval.model:test_step:407 - Inside test_step
2024-09-13 07:25:02.893 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:25:02.875 | INFO     | retrieval.model:test_step:407 - Inside test_step
2024-09-13 07:25:02.919 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:25:02.960 | INFO     | retrieval.model:test_step:407 - Inside test_step
Testing: |                                                                                        | 0/? [00:00<?, ?it/s]
2024-09-13 07:25:03.025 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:25:03.040 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
Testing DataLoader 0:   0%|                                                                    | 0/9327 [00:00<?, ?it/s]
2024-09-13 07:25:03.096 | INFO     | retrieval.model:test_step:407 - Inside test_step
2024-09-13 07:25:03.378 | INFO     | retrieval.model:test_step:417 - Test loss before EWC: 0.0296
2024-09-13 07:25:03.461 | INFO     | retrieval.model:test_step:417 - Test loss before EWC: 0.0138
2024-09-13 07:25:03.512 | INFO     | retrieval.model:test_step:417 - Test loss before EWC: 0.0256
2024-09-13 07:25:03.731 | INFO     | retrieval.model:test_step:417 - Test loss before EWC: 0.0349
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 418, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:25:04.392 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:25:04.392 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:25:04.392 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:25:04.392 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:25:04.392 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 418, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:25:04.397 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:25:04.397 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:25:04.397 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:25:04.398 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:25:04.398 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 418, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:25:04.429 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:25:04.429 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:25:04.429 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:25:04.429 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:25:04.429 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 418, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:25:04.714 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:25:04.714 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:25:04.715 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:25:04.715 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:25:04.715 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
Testing DataLoader 0:   0%|                                                                    | 0/9327 [00:03<?, ?it/s]
[rank0]:[W913 07:25:08.009835750 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed befor
e we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that
 any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and bl
ock the progress of another member of the process group. This constraint has always been present,  but this warning has
only been added since PyTorch 2.4 (function operator())
(base) yingzi_ma@compute-permanent-node-352:~/lean_project/ReProver$ bash run_code.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834741.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834743.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834746.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834747.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_835354.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_GCS.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834744.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_RAYLET.log': Permission denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834742.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_833907.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_AUTOSCALER.log': Permission deni
ed
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834748.log': Permiss
ion denied
rm: cannot remove '/tmp/ray/session_2024-08-22_03-10-43_407834_833965/logs/events/event_CORE_WORKER_834745.log': Permiss
ion denied
Stopping ray
Could not terminate `/usr/bin/python3 /usr/local/bin/user_traffic_monitor.py` due to (pid=784996, name='python3')
Did not find any active Ray processes.
Running main.py
[2024-09-13 07:26:34,696] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-13 07:26:38.531 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:26:38.532 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:26:38.535 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:26:38.535 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:26:38.535 | INFO     | __main__:main:1210 - Starting the main process
2024-09-13 07:26:38.535 | INFO     | __main__:main:1218 - Loading database from /data/yingzi_ma/lean_project/dynamic_dat
abase_PT_single_repo_no_ewc.json
2024-09-13 07:27:01.198 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.
com/leanprover-community/mathlib4 (commit: 2b29e73438e240a427bcecc7c0fe19306beb1310)
2024-09-13 07:27:01.198 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/lean
prover-community/mathlib4 (commit: 2b29e73438e240a427bcecc7c0fe19306beb1310)
2024-09-13 07:27:05.536 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.
com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-13 07:27:05.536 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/leco
pivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-13 07:27:05.861 | INFO     | __main__:main:1220 - Loaded database from /data/yingzi_ma/lean_project/dynamic_data
base_PT_single_repo_no_ewc.json
2024-09-13 07:27:05.861 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:27:05.861 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:27:06.103 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:27:22.641 | INFO     | __main__:main:1347 - Finding compatible repositories...
2024-09-13 07:27:22.643 | INFO     | __main__:main:1350 - Finished finding compatible repositories
2024-09-13 07:27:22.643 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:27:22.644 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:27:22.644 | INFO     | __main__:main:1375 - Main process
2024-09-13 07:27:22.644 | INFO     | __main__:main:1376 - Using lambda = 0.1
2024-09-13 07:27:22.644 | INFO     | __main__:main:1377 - Processing https://github.com/lecopivo/SciLean
2024-09-13 07:27:22.644 | INFO     | __main__:main:1398 - Adding repo to repos_for_merged_dataset
2024-09-13 07:27:22.644 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:27:22.645 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:27:22.645 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:27:22.645 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:27:22.645 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 0] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
2024-09-13 07:27:24.712 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:27:24.713 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
2024-09-13 07:27:25.128 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:27:25.128 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:27:25.128 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204
: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM,
prepend your python command with `srun` like so: srun python main.py ...
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.
2024-09-13 07:27:25.236 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:27:25.236 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-13 07:27:25.331 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
2024-09-13 07:27:35.028 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:27:35.041 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:27:35.054 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:27:35.054 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:27:35.054 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:27:35.055 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:27:35.055 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:27:35.055 | INFO     | __main__:main:1543 - hit the barrier before training
[rank: 0] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[2024-09-13 07:27:40,593] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-13 07:27:40,596] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-13 07:27:40,597] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-13 07:27:44.646 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:27:44.646 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:27:44.646 | INFO     | __main__:main:1197 - Running progressive training
2024-09-13 07:27:44.646 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:27:44.646 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:27:44.646 | INFO     | __main__:main:1203 - Configuring LeanDojo...
2024-09-13 07:27:44.649 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:27:44.649 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:27:44.649 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:27:44.649 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/
yingzi_ma/lean_project/ReProver
2024-09-13 07:27:44.650 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:27:44.650 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:27:44.650 | INFO     | __main__:main:1205 - LeanDojo configured
2024-09-13 07:27:44.650 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:27:44.650 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:27:44.650 | INFO     | __main__:main:1227 - Found 15 repositories
2024-09-13 07:27:44.650 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:27:44.650 | INFO     | __main__:main:1318 - Starting without curriculum learning
2024-09-13 07:27:44.843 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:27:44.867 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:27:44.899 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for le
an4 v4.7.0
2024-09-13 07:28:00.985 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:28:00.985 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:28:00.985 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:28:00.986 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:28:00.986 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:28:00.986 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:28:00.986 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 3] Seed set to 3407
2024-09-13 07:28:01.029 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:28:01.029 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:28:01.029 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:28:01.030 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:28:01.030 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:28:01.030 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:28:01.030 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 1] Seed set to 3407
2024-09-13 07:28:01.101 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:28:01.101 | INFO     | __main__:main:1369 - i: 0
2024-09-13 07:28:01.101 | INFO     | __main__:main:1409 - All GPUs
2024-09-13 07:28:01.102 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:28:01.102 | INFO     | __main__:main:1416 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:28:01.102 | INFO     | __main__:main:1422 - Inside train_test_fisher
2024-09-13 07:28:01.102 | INFO     | __main__:main:1423 - Starting training at epoch 1
[rank: 2] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
2024-09-13 07:28:03.935 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:28:03.936 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
2024-09-13 07:28:03.957 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:28:03.957 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
2024-09-13 07:28:04.121 | INFO     | __main__:main:1447 - Loaded premise retriever at /data/yingzi_ma/lean_project/check
points_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@
10_val=70.07.ckpt
2024-09-13 07:28:04.122 | INFO     | __main__:find_latest_fisher:527 - Using the latest Fisher Information Matrix: /data
/yingzi_ma/lean_project/fisher_PT_single_repo_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_fishe
r_info.pkl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using
 `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It
 is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.
com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for
 `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary
 objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `to
rch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't
 have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental featur
e.
  return torch.load(io.BytesIO(b))
2024-09-13 07:28:04.868 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:28:04.868 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:28:04.869 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
2024-09-13 07:28:04.869 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:28:04.869 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:28:04.869 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
2024-09-13 07:28:04.973 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:28:04.973 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:28:04.974 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
2024-09-13 07:28:04.974 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
2024-09-13 07:28:04.986 | INFO     | __main__:load_fisher_information:503 - Fisher Information successfully loaded.
2024-09-13 07:28:04.986 | INFO     | retrieval.model:set_fisher_info:60 - Fisher Information has been updated in the mod
el.
2024-09-13 07:28:04.986 | INFO     | __main__:main:1454 - Fisher Information Matrix loaded.
2024-09-13 07:28:05.031 | INFO     | __main__:main:1507 - right before barrier for data module
2024-09-13 07:28:05.032 | INFO     | __main__:main:1522 - Data path: /data/yingzi_ma/lean_project/datasets_PT_single_rep
o_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-13 07:28:05.071 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
2024-09-13 07:28:05.071 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: Futu
reWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprac
ted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github
.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-13 07:28:05.258 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/dataset
s_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/corpus.jsonl
2024-09-13 07:28:15.948 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:28:15.960 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:28:15.972 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:28:15.972 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:28:15.973 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:28:15.973 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:28:15.973 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:28:15.973 | INFO     | __main__:main:1543 - hit the barrier before training
[rank: 2] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
2024-09-13 07:28:16.574 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:28:16.586 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:28:16.588 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:28:16.598 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:28:16.601 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:28:16.601 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:28:16.601 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:28:16.601 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:28:16.601 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:28:16.601 | INFO     | __main__:main:1543 - hit the barrier before training
2024-09-13 07:28:16.616 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:28:16.617 | INFO     | __main__:main:1536 - Training dataset size after load: 149228
2024-09-13 07:28:16.617 | INFO     | __main__:main:1537 - Validation dataset size after load: 2087
2024-09-13 07:28:16.617 | INFO     | __main__:main:1538 - Testing dataset size after load: 2298
2024-09-13 07:28:16.617 | INFO     | __main__:main:1540 - Starting progressive training from epoch 1 to 2
2024-09-13 07:28:16.617 | INFO     | __main__:main:1543 - hit the barrier before training
[rank: 1] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
[rank: 3] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
2024-09-13 07:28:18.581 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:28:18.688 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:28:18.710 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:65
3: Checkpoint directory /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc exists and is not empty.
2024-09-13 07:28:19.914 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
2024-09-13 07:28:19.937 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
2024-09-13 07:28:19.968 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:28:19.996 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
Training dataset size: 149228
2024-09-13 07:28:20.011 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
2024-09-13 07:28:20.018 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:28:20.032 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Training dataset size: 149228
Testing dataset size: 2298
2024-09-13 07:28:20.051 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_val/cached_data.pkl
Validation dataset size: 2087
2024-09-13 07:28:20.066 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_pred/cached_data.pkl
Testing dataset size: 2298
Restoring states from the checkpoint path at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_
new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_val=70.07.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are
 using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicit
ly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://g
ithub.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default val
ue for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arb
itrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user v
ia `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you
 don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental
feature.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
2024-09-13 07:28:21.319 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:28:21.321 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:28:21.322 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-13 07:28:21.322 | INFO     | common:get_optimizers:449 - Optimizing with AdamW

  | Name    | Type           | Params
-------------------------------------------
0 | encoder | T5EncoderModel | 217 M
-------------------------------------------
217 M     Trainable params
0         Non-trainable params
217 M     Total params
870.630   Total estimated model params size (MB)
Restored all states from the checkpoint at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_ne
w_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_val=70.07.ckpt
`Trainer.fit` stopped: `max_epochs=2` reached.
2024-09-13 07:28:24.541 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:28:24.646 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:28:24.754 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:28:24.866 | INFO     | __main__:main:1546 - hit the barrier after training
2024-09-13 07:28:24.866 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:28:24.866 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:28:24.866 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:28:24.867 | INFO     | __main__:main:1552 - Finished progressive training at epoch 2
2024-09-13 07:28:24.867 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:28:24.867 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:28:24.867 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:28:24.867 | INFO     | __main__:find_latest_checkpoint:517 - Using the latest checkpoint: /data/yingzi_ma/
lean_project/checkpoints_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0
.1_epoch=1-Recall@10_val=70.07.ckpt
2024-09-13 07:28:24.867 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:28:24.867 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:28:24.867 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:28:24.867 | INFO     | __main__:main:1559 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoi
nts_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744_lambda_0.1_epoch=1-Recall@10_
val=70.07.ckpt
2024-09-13 07:28:27.344 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:28:27.344 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:28:27.438 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:28:27.438 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:28:27.730 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:28:27.730 | INFO     | __main__:main:1629 - right before barrier fisher
2024-09-13 07:28:27.783 | INFO     | __main__:main:1625 - Calculating Fisher Information Matrix for EWC
2024-09-13 07:28:27.784 | INFO     | __main__:main:1629 - right before barrier fisher
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204
: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM,
prepend your python command with `srun` like so: srun python main.py ...
[rank: 1] Seed set to 3407
[rank: 2] Seed set to 3407
[rank: 3] Seed set to 3407
[rank: 0] Seed set to 3407
2024-09-13 07:28:30.973 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
2024-09-13 07:28:31.677 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
2024-09-13 07:28:31.685 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
Training dataset size: 149228
2024-09-13 07:28:33.133 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma
/lean_project/datasets_PT_single_repo_no_ewc/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e62655744/random/cac
he_train/cached_data.pkl
Training dataset size: 149228
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connecto
r.py:232: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(de
vices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `Di
stributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
2024-09-13 07:28:33.985 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:28:34.041 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:28:34.044 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:28:34.087 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:28:34.094 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
Testing: |                                                                                        | 0/? [00:00<?, ?it/s]
2024-09-13 07:28:34.148 | INFO     | retrieval.model:test_step:408 - Inside test_step
2024-09-13 07:28:34.148 | INFO     | retrieval.model:on_test_start:398 - Fisher info cleared
2024-09-13 07:28:34.166 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:28:34.171 | INFO     | retrieval.model:on_test_start:400 - Previous params saved
2024-09-13 07:28:34.194 | INFO     | retrieval.model:test_step:408 - Inside test_step
2024-09-13 07:28:34.258 | INFO     | retrieval.model:test_step:408 - Inside test_step
Testing DataLoader 0:   0%|                                                                    | 0/9327 [00:00<?, ?it/s]
2024-09-13 07:28:34.280 | INFO     | retrieval.model:test_step:408 - Inside test_step
2024-09-13 07:28:34.687 | INFO     | retrieval.model:test_step:418 - Test loss before EWC: 0.0245
2024-09-13 07:28:34.827 | INFO     | retrieval.model:test_step:418 - Test loss before EWC: 0.0286
2024-09-13 07:28:34.867 | INFO     | retrieval.model:test_step:418 - Test loss before EWC: 0.0356
2024-09-13 07:28:34.884 | INFO     | retrieval.model:test_step:418 - Test loss before EWC: 0.0133
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 419, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:28:35.407 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:28:35.407 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:28:35.407 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:28:35.407 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:28:35.408 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 419, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:28:35.736 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:28:35.736 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:28:35.737 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:28:35.737 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:28:35.737 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 419, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:28:35.784 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:28:35.785 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:28:35.785 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:28:35.785 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:28:35.785 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
An error occurred during fisher: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1631, in main
    trainer.test(model, datamodule=data_module)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 754, in test
    return call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 4
3, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/sub
process_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 987, in _run
    results = self._run_stage()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", lin
e 1026, in _run_stage
    return self._evaluation_loop.run()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", lin
e 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py
", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 3
09, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py",
 line 425, in test_step
    return self.lightning_module.test_step(*args, **kwargs)
  File "/data/yingzi_ma/lean_project/ReProver/retrieval/model.py", line 419, in test_step
    loss.backward()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in
backward
    _engine_run_backward(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _en
gine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

2024-09-13 07:28:35.827 | INFO     | __main__:main:1692 - Finished processing the repository
2024-09-13 07:28:35.827 | INFO     | __main__:main:1694 - current epoch: 2
2024-09-13 07:28:35.828 | INFO     | __main__:main:1368 - length of lean_git_repos: 1
2024-09-13 07:28:35.828 | INFO     | __main__:main:1369 - i: 1
2024-09-13 07:28:35.828 | INFO     | __main__:main:1696 - An error occurred: list index out of range
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main.py", line 1370, in main
    repo = lean_git_repos[i]
IndexError: list index out of range
Testing DataLoader 0:   0%|                                                                    | 0/9327 [00:03<?, ?it/s]
[rank0]:[W913 07:28:39.979622975 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed befor
e we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that
 any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and bl
ock the progress of another member of the process group. This constraint has always been present,  but this warning has
only been added since PyTorch 2.4 (function operator())

